<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.7.1">
<title>Using Strimzi</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Uncomment @import statement below to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
*:not(pre)>code.nobreak{word-wrap:normal}
*:not(pre)>code.nowrap{white-space:nowrap}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote::before{display:none}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{word-spacing:0;line-height:1.6}
.quoteblock.abstract blockquote::before,.quoteblock.abstract p::before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd){background:#f8f8f7}
table.stripes-none tr,table.stripes-odd tr:nth-of-type(even){background:none}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Using Strimzi</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#overview-str">1. Overview of Strimzi</a>
<ul class="sectlevel2">
<li><a href="#key-features-str">1.1. Kafka Key Features</a></li>
<li><a href="#document-conventions-str">1.2. Document Conventions</a></li>
</ul>
</li>
<li><a href="#getting-started-str">2. Getting started with Strimzi</a>
<ul class="sectlevel2">
<li><a href="#downloads-str">2.1. Installing Strimzi and deploying components</a></li>
<li><a href="#cluster-operator-str">2.2. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-whole-cluster-str">2.2.5. Deploying the Cluster Operator to watch all namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-str">2.2.6. Deploying the Cluster Operator using Helm Chart</a></li>
</ul>
</li>
<li><a href="#kafka-cluster-str">2.3. Kafka cluster</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</a></li>
<li><a href="#deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</a></li>
</ul>
</li>
<li><a href="#kafka-connect-str">2.4. Kafka Connect</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to your Kubernetes cluster</a></li>
<li><a href="#deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to your OpenShift cluster</a></li>
<li><a href="#using-kafka-connect-with-plug-ins-str">2.4.3. Extending Kafka Connect with plug-ins</a></li>
</ul>
</li>
<li><a href="#kafka-mirror-maker-str">2.5. Kafka Mirror Maker</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-mirror-maker-kubernetes-str">2.5.1. Deploying Kafka Mirror Maker to Kubernetes</a></li>
<li><a href="#deploying-kafka-mirror-maker-openshift-str">2.5.2. Deploying Kafka Mirror Maker to OpenShift</a></li>
</ul>
</li>
<li><a href="#deploying-example-clients-str">2.6. Deploying example clients</a></li>
<li><a href="#assembly-getting-started-topic-operator-str">2.7. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-str">2.7.1. Overview of the Topic Operator component</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-str">2.7.2. Deploying the Topic Operator using the Cluster Operator</a></li>
</ul>
</li>
<li><a href="#assembly-getting-started-user-operator-str">2.8. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-str">2.8.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">2.8.2. Deploying the User Operator using the Cluster Operator</a></li>
</ul>
</li>
<li><a href="#assembly-getting-started-strimzi-admin-str">2.9. Strimzi Administrators</a>
<ul class="sectlevel3">
<li><a href="#proc-adding-users-the-strimzi-admin-role-str">2.9.1. Designating Strimzi Administrators</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-str">3. Deployment configuration</a>
<ul class="sectlevel2">
<li><a href="#assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</a></li>
<li><a href="#assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Kafka broker replicas</a></li>
<li><a href="#assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</a></li>
<li><a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</a></li>
<li><a href="#assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</a></li>
<li><a href="#assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Zookeeper replicas</a></li>
<li><a href="#assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</a></li>
<li><a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka">3.1.10. Logging</a></li>
<li><a href="#assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</a></li>
<li><a href="#assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</a></li>
<li><a href="#proc-manual-rolling-update-kafka-deployment-configuration-kafka">3.1.18. Performing a rolling update of a Kafka cluster</a></li>
<li><a href="#proc-manual-rolling-update-zookeeper-deployment-configuration-kafka">3.1.19. Performing a rolling update of a Zookeeper cluster</a></li>
<li><a href="#scaling-clusters-deployment-configuration-kafka">3.1.20. Scaling clusters</a></li>
<li><a href="#proc-manual-delete-pod-pvc-kafka-deployment-configuration-kafka">3.1.21. Deleting Kafka nodes manually</a></li>
<li><a href="#proc-manual-delete-pod-pvc-zookeeper-deployment-configuration-kafka">3.1.22. Deleting Zookeeper nodes manually</a></li>
<li><a href="#assembly-maintenance-time-windows-deployment-configuration-kafka">3.1.23. Maintenance time windows for rolling updates</a></li>
<li><a href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.24. List of resources created as part of Kafka cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</a></li>
<li><a href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</a></li>
<li><a href="#assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect">3.2.13. Using external configuration and secrets</a></li>
<li><a href="#ref-list-of-kafka-connect-resources-deployment-configuration-kafka-connect">3.2.14. List of resources created as part of Kafka Connect cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</a></li>
<li><a href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</a></li>
<li><a href="#assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect-s2i">3.3.13. Using external configuration and secrets</a></li>
<li><a href="#ref-list-of-kafka-connect-s2i-resources-deployment-configuration-kafka-connect-s2i">3.3.14. List of resources created as part of Kafka Connect cluster with Source2Image support</a></li>
<li><a href="#using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.15. Creating a container image using OpenShift builds and Source-to-Image</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-mirror-maker-str">3.4. Kafka Mirror Maker configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">3.4.1. Replicas</a></li>
<li><a href="#assembly-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">3.4.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">3.4.3. Whitelist</a></li>
<li><a href="#assembly-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">3.4.4. Consumer group identifier</a></li>
<li><a href="#assembly-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">3.4.5. Number of consumer streams</a></li>
<li><a href="#assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">3.4.6. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-mirror-maker-authentication-deployment-configuration-kafka-mirror-maker">3.4.7. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">3.4.8. Kafka Mirror Maker configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">3.4.9. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-mirror-maker">3.4.10. Logging</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-mirror-maker">3.4.11. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-mirror-maker">3.4.12. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker">3.4.13. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-mirror-maker">3.4.14. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-mirror-maker-resources-deployment-configuration-kafka-mirror-maker">3.4.15. List of resources created as part of Kafka Mirror Maker</a></li>
</ul>
</li>
<li><a href="#assembly-customizing-deployments-str">3.5. Customizing deployments</a>
<ul class="sectlevel3">
<li><a href="#con-customizing-template-properties-str">3.5.1. Template properties</a></li>
<li><a href="#con-customizing-labels-and-annotations-str">3.5.2. Labels and Annotations</a></li>
<li><a href="#con-customizing-pods-str">3.5.3. Customizing Pods</a></li>
<li><a href="#con-customizing-image-pull-policy-str">3.5.4. Customizing the image pull policy</a></li>
<li><a href="#con-customizing-pod-disruption-budgets-str">3.5.5. Customizing Pod Disruption Budgets</a></li>
<li><a href="#proc-customizing-deployments-str">3.5.6. Customizing deployments</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-operators-str">4. Operators</a>
<ul class="sectlevel2">
<li><a href="#assembly-operators-cluster-operator-str">4.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-whole-cluster-deploying-co">4.1.5. Deploying the Cluster Operator to watch all namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-deploying-co">4.1.6. Deploying the Cluster Operator using Helm Chart</a></li>
<li><a href="#con-cluster-operator-reconciliation-deploying-co">4.1.7. Reconciliation</a></li>
<li><a href="#ref-operators-cluster-operator-configuration-deploying-co">4.1.8. Cluster Operator Configuration</a></li>
<li><a href="#con-cluster-operator-rbac-deploying-co">4.1.9. Role-Based Access Control (RBAC)</a></li>
</ul>
</li>
<li><a href="#deploying-the-topic-operator-str">4.2. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</a></li>
<li><a href="#how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</a></li>
<li><a href="#proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</a></li>
<li><a href="#deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</a></li>
<li><a href="#topic-operator-environment-deploying">4.2.6. Topic Operator environment</a></li>
</ul>
</li>
<li><a href="#assembly-user-operator-str">4.3. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</a></li>
<li><a href="#proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#using-the-topic-operator-str">5. Using the Topic Operator</a>
<ul class="sectlevel2">
<li><a href="#topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</a></li>
<li><a href="#creating-a-topic-str">5.2. Creating a topic</a></li>
<li><a href="#changing-a-topic-str">5.3. Changing a topic</a></li>
<li><a href="#deleting-a-topic-str">5.4. Deleting a topic</a></li>
</ul>
</li>
<li><a href="#assembly-using-the-user-operator-str">6. Using the User Operator</a>
<ul class="sectlevel2">
<li><a href="#con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</a></li>
<li><a href="#con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</a>
<ul class="sectlevel3">
<li><a href="#mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</a></li>
<li><a href="#when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</a></li>
<li><a href="#con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</a>
<ul class="sectlevel3">
<li><a href="#supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</a></li>
<li><a href="#when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</a></li>
<li><a href="#proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</a></li>
<li><a href="#deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</a></li>
<li><a href="#ref-kafka-user-using-uo">6.8. Kafka User resource</a>
<ul class="sectlevel3">
<li><a href="#authentication">6.8.1. Authentication</a></li>
<li><a href="#authorization">6.8.2. Authorization</a></li>
<li><a href="#additional_resources_5">6.8.3. Additional resources</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#security-str">7. Security</a>
<ul class="sectlevel2">
<li><a href="#certificate-authorities-str">7.1. Certificate Authorities</a>
<ul class="sectlevel3">
<li><a href="#ca_certificates">7.1.1. CA certificates</a></li>
</ul>
</li>
<li><a href="#certificates-and-secrets-str">7.2. Certificates and <code>Secrets</code></a>
<ul class="sectlevel3">
<li><a href="#cluster_ca_secrets">7.2.1. Cluster CA <code>Secrets</code></a></li>
<li><a href="#client_ca_secrets">7.2.2. Client CA <code>Secrets</code></a></li>
<li><a href="#user_secrets">7.2.3. User <code>Secrets</code></a></li>
</ul>
</li>
<li><a href="#installing-your-own-ca-certificates-str">7.3. Installing your own CA certificates</a></li>
<li><a href="#con-certificate-renewal-str">7.4. Certificate renewal</a>
<ul class="sectlevel3">
<li><a href="#renewal_process_with_generated_cas">7.4.1. Renewal process with generated CAs</a></li>
<li><a href="#client_applications">7.4.2. Client applications</a></li>
</ul>
</li>
<li><a href="#tls-connections-str">7.5. TLS connections</a>
<ul class="sectlevel3">
<li><a href="#zookeeper_communication">7.5.1. Zookeeper communication</a></li>
<li><a href="#kafka_interbroker_communication">7.5.2. Kafka interbroker communication</a></li>
<li><a href="#topic_and_user_operators">7.5.3. Topic and User Operators</a></li>
<li><a href="#kafka_client_connections">7.5.4. Kafka Client connections</a></li>
</ul>
</li>
<li><a href="#configuring-internal-clients-to-trust-cluster-ca-str">7.6. Configuring internal clients to trust the cluster CA</a></li>
<li><a href="#configuring-external-clients-to-trust-cluster-ca-str">7.7. Configuring external clients to trust the cluster CA</a></li>
</ul>
</li>
<li><a href="#assembly-upgrade-str">8. Strimzi and Kafka upgrades</a>
<ul class="sectlevel2">
<li><a href="#proc-upgrading-the-cluster-operator-0-10-0-to-0-11-0-str">8.1. Upgrading the Cluster Operator from 0.10.0 to 0.11.0</a></li>
<li><a href="#proc-upgrading-the-cluster-operator-str">8.2. Upgrading the Cluster Operator from 0.9.0 to 0.10.0</a></li>
<li><a href="#assembly-upgrading-kafka-versions-str">8.3. Upgrading and downgrading Kafka versions</a>
<ul class="sectlevel3">
<li><a href="#con-versions-and-images-str">8.3.1. Versions and images overview</a></li>
<li><a href="#con-kafka-upgrades-using-cluster-operator-str">8.3.2. Kafka upgrades using the Cluster Operator</a></li>
<li><a href="#proc-upgrading-brokers-newer-kafka-0-9-0-to-0-10-0-str">8.3.3. Upgrading brokers to a newer Kafka version</a></li>
<li><a href="#con-kafka-downgrades-using-cluster-operator-str">8.3.4. Kafka downgrades using the Cluster Operator</a></li>
<li><a href="#proc-downgrading-brokers-older-kafka-str">8.3.5. Downgrading brokers to an older Kafka version</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#frequently_asked_questions">Appendix A: Frequently Asked Questions</a>
<ul class="sectlevel2">
<li><a href="#cluster_operator">A.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#why_do_i_need_cluster_admin_privileges_to_install_strimzi">A.1.1. Why do I need cluster admin privileges to install Strimzi?</a></li>
<li><a href="#why_does_the_cluster_operator_require_the_ability_to_create_clusterrolebindings_is_that_not_a_security_risk">A.1.2. Why does the Cluster Operator require the ability to create <code>ClusterRoleBindings</code>? Is that not a security risk?</a></li>
<li><a href="#why_can_standard_openshift_or_kubernetes_users_not_create_the_custom_resource_kafka_kafkatopic_and_so_on">A.1.3. Why can standard OpenShift or Kubernetes users not create the custom resource (<code>Kafka</code>, <code>KafkaTopic</code>, and so on)?</a></li>
<li><a href="#log_contains_warnings_about_failing_to_acquire_lock">A.1.4. Log contains warnings about failing to acquire lock</a></li>
<li><a href="#hostname_verification_fails_when_connecting_to_nodeports_using_tls">A.1.5. Hostname verification fails when connecting to NodePorts using TLS</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</a>
<ul class="sectlevel2">
<li><a href="#kubernetes">B.1. Kubernetes</a></li>
<li><a href="#openshift">B.2. OpenShift</a></li>
</ul>
</li>
<li><a href="#metrics-str">Appendix C: Metrics</a>
<ul class="sectlevel2">
<li><a href="#kafka_metrics_configuration">C.1. Kafka Metrics Configuration</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift">C.1.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes">C.1.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#prometheus">C.2. Prometheus</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift_2">C.2.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes_2">C.2.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#grafana">C.3. Grafana</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift_3">C.3.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes_3">C.3.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#grafana_dashboard">C.4. Grafana dashboard</a>
<ul class="sectlevel3">
<li><a href="#kafka_dashboard">C.4.1. Kafka Dashboard</a></li>
<li><a href="#zookeeper_dashboard">C.4.2. ZooKeeper Dashboard</a></li>
<li><a href="#metrics_references">C.4.3. Metrics References</a></li>
</ul>
</li>
<li><a href="#prometheus_alerting">C.5. Prometheus alerting</a></li>
<li><a href="#prometheus_alert_manager">C.6. Prometheus alert manager</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift_4">C.6.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes_4">C.6.2. Deploying on Kubernetes</a></li>
<li><a href="#alerts_examples">C.6.3. Alerts examples</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#api_reference-str">Appendix D: Custom Resource API Reference</a>
<ul class="sectlevel2">
<li><a href="#type-Kafka-reference">D.1. <code>Kafka</code> schema reference</a></li>
<li><a href="#type-KafkaSpec-reference">D.2. <code>KafkaSpec</code> schema reference</a></li>
<li><a href="#type-KafkaClusterSpec-reference">D.3. <code>KafkaClusterSpec</code> schema reference</a></li>
<li><a href="#type-EphemeralStorage-reference">D.4. <code>EphemeralStorage</code> schema reference</a></li>
<li><a href="#type-PersistentClaimStorage-reference">D.5. <code>PersistentClaimStorage</code> schema reference</a></li>
<li><a href="#type-JbodStorage-reference">D.6. <code>JbodStorage</code> schema reference</a></li>
<li><a href="#type-KafkaListeners-reference">D.7. <code>KafkaListeners</code> schema reference</a></li>
<li><a href="#type-KafkaListenerPlain-reference">D.8. <code>KafkaListenerPlain</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationTls-reference">D.9. <code>KafkaListenerAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationScramSha512-reference">D.10. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-KafkaListenerTls-reference">D.11. <code>KafkaListenerTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalRoute-reference">D.12. <code>KafkaListenerExternalRoute</code> schema reference</a></li>
<li><a href="#type-RouteListenerOverride-reference">D.13. <code>RouteListenerOverride</code> schema reference</a></li>
<li><a href="#type-RouteListenerBootstrapOverride-reference">D.14. <code>RouteListenerBootstrapOverride</code> schema reference</a></li>
<li><a href="#type-RouteListenerBrokerOverride-reference">D.15. <code>RouteListenerBrokerOverride</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalLoadBalancer-reference">D.16. <code>KafkaListenerExternalLoadBalancer</code> schema reference</a></li>
<li><a href="#type-LoadBalancerListenerOverride-reference">D.17. <code>LoadBalancerListenerOverride</code> schema reference</a></li>
<li><a href="#type-LoadBalancerListenerBootstrapOverride-reference">D.18. <code>LoadBalancerListenerBootstrapOverride</code> schema reference</a></li>
<li><a href="#type-LoadBalancerListenerBrokerOverride-reference">D.19. <code>LoadBalancerListenerBrokerOverride</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalNodePort-reference">D.20. <code>KafkaListenerExternalNodePort</code> schema reference</a></li>
<li><a href="#type-NodePortListenerOverride-reference">D.21. <code>NodePortListenerOverride</code> schema reference</a></li>
<li><a href="#type-NodePortListenerBootstrapOverride-reference">D.22. <code>NodePortListenerBootstrapOverride</code> schema reference</a></li>
<li><a href="#type-NodePortListenerBrokerOverride-reference">D.23. <code>NodePortListenerBrokerOverride</code> schema reference</a></li>
<li><a href="#type-KafkaAuthorizationSimple-reference">D.24. <code>KafkaAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-Rack-reference">D.25. <code>Rack</code> schema reference</a></li>
<li><a href="#type-Probe-reference">D.26. <code>Probe</code> schema reference</a></li>
<li><a href="#type-JvmOptions-reference">D.27. <code>JvmOptions</code> schema reference</a></li>
<li><a href="#type-Resources-reference">D.28. <code>Resources</code> schema reference</a></li>
<li><a href="#type-CpuMemory-reference">D.29. <code>CpuMemory</code> schema reference</a></li>
<li><a href="#type-InlineLogging-reference">D.30. <code>InlineLogging</code> schema reference</a></li>
<li><a href="#type-ExternalLogging-reference">D.31. <code>ExternalLogging</code> schema reference</a></li>
<li><a href="#type-TlsSidecar-reference">D.32. <code>TlsSidecar</code> schema reference</a></li>
<li><a href="#type-KafkaClusterTemplate-reference">D.33. <code>KafkaClusterTemplate</code> schema reference</a></li>
<li><a href="#type-ResourceTemplate-reference">D.34. <code>ResourceTemplate</code> schema reference</a></li>
<li><a href="#type-MetadataTemplate-reference">D.35. <code>MetadataTemplate</code> schema reference</a></li>
<li><a href="#type-PodTemplate-reference">D.36. <code>PodTemplate</code> schema reference</a></li>
<li><a href="#type-PodDisruptionBudgetTemplate-reference">D.37. <code>PodDisruptionBudgetTemplate</code> schema reference</a></li>
<li><a href="#type-ZookeeperClusterSpec-reference">D.38. <code>ZookeeperClusterSpec</code> schema reference</a></li>
<li><a href="#type-ZookeeperClusterTemplate-reference">D.39. <code>ZookeeperClusterTemplate</code> schema reference</a></li>
<li><a href="#type-TopicOperatorSpec-reference">D.40. <code>TopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityOperatorJvmOptions-reference">D.41. <code>EntityOperatorJvmOptions</code> schema reference</a></li>
<li><a href="#type-EntityOperatorSpec-reference">D.42. <code>EntityOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityTopicOperatorSpec-reference">D.43. <code>EntityTopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityUserOperatorSpec-reference">D.44. <code>EntityUserOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityOperatorTemplate-reference">D.45. <code>EntityOperatorTemplate</code> schema reference</a></li>
<li><a href="#type-CertificateAuthority-reference">D.46. <code>CertificateAuthority</code> schema reference</a></li>
<li><a href="#type-KafkaConnect-reference">D.47. <code>KafkaConnect</code> schema reference</a></li>
<li><a href="#type-KafkaConnectSpec-reference">D.48. <code>KafkaConnectSpec</code> schema reference</a></li>
<li><a href="#type-KafkaConnectTemplate-reference">D.49. <code>KafkaConnectTemplate</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationTls-reference">D.50. <code>KafkaConnectAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-CertAndKeySecretSource-reference">D.51. <code>CertAndKeySecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationScramSha512-reference">D.52. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-PasswordSecretSource-reference">D.53. <code>PasswordSecretSource</code> schema reference</a></li>
<li><a href="#type-ExternalConfiguration-reference">D.54. <code>ExternalConfiguration</code> schema reference</a></li>
<li><a href="#type-ExternalConfigurationEnv-reference">D.55. <code>ExternalConfigurationEnv</code> schema reference</a></li>
<li><a href="#type-ExternalConfigurationEnvVarSource-reference">D.56. <code>ExternalConfigurationEnvVarSource</code> schema reference</a></li>
<li><a href="#type-ExternalConfigurationVolumeSource-reference">D.57. <code>ExternalConfigurationVolumeSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectTls-reference">D.58. <code>KafkaConnectTls</code> schema reference</a></li>
<li><a href="#type-CertSecretSource-reference">D.59. <code>CertSecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2I-reference">D.60. <code>KafkaConnectS2I</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2ISpec-reference">D.61. <code>KafkaConnectS2ISpec</code> schema reference</a></li>
<li><a href="#type-KafkaTopic-reference">D.62. <code>KafkaTopic</code> schema reference</a></li>
<li><a href="#type-KafkaTopicSpec-reference">D.63. <code>KafkaTopicSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUser-reference">D.64. <code>KafkaUser</code> schema reference</a></li>
<li><a href="#type-KafkaUserSpec-reference">D.65. <code>KafkaUserSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUserTlsClientAuthentication-reference">D.66. <code>KafkaUserTlsClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserScramSha512ClientAuthentication-reference">D.67. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserAuthorizationSimple-reference">D.68. <code>KafkaUserAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-AclRule-reference">D.69. <code>AclRule</code> schema reference</a></li>
<li><a href="#type-AclRuleTopicResource-reference">D.70. <code>AclRuleTopicResource</code> schema reference</a></li>
<li><a href="#type-AclRuleGroupResource-reference">D.71. <code>AclRuleGroupResource</code> schema reference</a></li>
<li><a href="#type-AclRuleClusterResource-reference">D.72. <code>AclRuleClusterResource</code> schema reference</a></li>
<li><a href="#type-AclRuleTransactionalIdResource-reference">D.73. <code>AclRuleTransactionalIdResource</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMaker-reference">D.74. <code>KafkaMirrorMaker</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerSpec-reference">D.75. <code>KafkaMirrorMakerSpec</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerConsumerSpec-reference">D.76. <code>KafkaMirrorMakerConsumerSpec</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerAuthenticationTls-reference">D.77. <code>KafkaMirrorMakerAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference">D.78. <code>KafkaMirrorMakerAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerTls-reference">D.79. <code>KafkaMirrorMakerTls</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerProducerSpec-reference">D.80. <code>KafkaMirrorMakerProducerSpec</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerTemplate-reference">D.81. <code>KafkaMirrorMakerTemplate</code> schema reference</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="overview-str"><a class="link" href="#overview-str">1. Overview of Strimzi</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi makes it easy to run Apache Kafka on OpenShift or Kubernetes. Apache Kafka is a popular platform for streaming data delivery and processing. For more information about Apache Kafka, see the <a href="http://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka website</a>.</p>
</div>
<div class="paragraph">
<p>Strimzi is based on Apache Kafka 2.0.1 and consists of three main components:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Cluster Operator</dt>
<dd>
<p>Responsible for deploying and managing Apache Kafka clusters within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">Topic Operator</dt>
<dd>
<p>Responsible for managing Kafka topics within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">User Operator</dt>
<dd>
<p>Responsible for managing Kafka users within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>This guide describes how to install and use Strimzi.</p>
</div>
<div class="sect2">
<h3 id="key-features-str"><a class="link" href="#key-features-str">1.1. Kafka Key Features</a></h3>
<div class="ulist">
<ul>
<li>
<p>Scalability and performance</p>
<div class="ulist">
<ul>
<li>
<p>Designed for horizontal scalability</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message ordering guarantee</p>
<div class="ulist">
<ul>
<li>
<p>At partition level</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message rewind/replay</p>
<div class="ulist">
<ul>
<li>
<p>"Long term" storage</p>
</li>
<li>
<p>Allows to reconstruct application state by replaying the messages</p>
</li>
<li>
<p>Combined with compacted topics allows to use Kafka as key-value store</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="document-conventions-str"><a class="link" href="#document-conventions-str">1.2. Document Conventions</a></h3>
<div class="paragraph">
<div class="title">Replaceables</div>
<p>In this document, replaceable text is styled in monospace and italics.</p>
</div>
<div class="paragraph">
<p>For example, in the following code, you will want to replace <code><em>my-namespace</em></code> with the name of your namespace:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="getting-started-str"><a class="link" href="#getting-started-str">2. Getting started with Strimzi</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi works on all types of clusters, from public and private clouds on to local deployments intended for development.
This guide expects that an OpenShift or Kubernetes cluster is available and the
<code>kubectl</code> and
<code>oc</code> command-line tools are installed and configured to connect to the running cluster.</p>
</div>
<div class="paragraph">
<p>When no existing OpenShift or Kubernetes cluster is available, <code>Minikube</code> or <code>Minishift</code> can be used to create a local
cluster. More details can be found in <a href="#installing_kubernetes_and_openshift_cluster">Installing Kubernetes and OpenShift clusters</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
To run the commands in this guide, your
Kubernetes and
OpenShift Origin user must have the rights to manage role-based access control (RBAC).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more information about OpenShift and setting up OpenShift cluster, see <a href="https://docs.openshift.com/container-platform/3.9/welcome/index.html">OpenShift documentation</a>.</p>
</div>
<div class="sect2">
<h3 id="downloads-str"><a class="link" href="#downloads-str">2.1. Installing Strimzi and deploying components</a></h3>
<div class="paragraph">
<p>To install Strimzi, download the release artefacts from <a href="https://github.com/strimzi/strimzi-kafka-operator/releases" target="_blank" rel="noopener">GitHub</a>.</p>
</div>
<div class="paragraph">
<p>The folder contains several YAML files to help you deploy the components of Strimzi to OpenShift or Kubernetes, perform common operations, and configure your Kafka cluster. The YAML files are referenced throughout this documentation.</p>
</div>
<div class="paragraph">
<p>Additionally, a Helm Chart is provided for deploying the Cluster Operator using <a href="https://helm.sh/" target="_blank" rel="noopener">Helm</a>. The container images are available through the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a>.</p>
</div>
<div class="paragraph">
<p>The remainder of this chapter provides an overview of each component and instructions for deploying the components to OpenShift or Kubernetes using the YAML files provided.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Although container images for Strimzi are available in the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a>, we recommend that you use the YAML files provided instead.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="cluster-operator-str"><a class="link" href="#cluster-operator-str">2.2. Cluster Operator</a></h3>
<div class="paragraph">
<p>Strimzi uses the Cluster Operator to deploy and manage Kafka (including Zookeeper) and Kafka Connect clusters.
The Cluster Operator is deployed inside of the
Kubernetes or
OpenShift cluster.
To deploy a Kafka cluster, a <code>Kafka</code> resource with the cluster configuration has to be created within the
Kubernetes or
OpenShift cluster.
Based on what is declared inside of the <code>Kafka</code> resource, the Cluster Operator deploys a corresponding Kafka cluster.
For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Strimzi contains example YAML files, which make deploying a Cluster Operator easier.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-str"><a class="link" href="#con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</a></h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 1. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka, Kafka Connect, or Kafka Mirror Maker cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
<li>
<p>A <code>KafkaMirrorMaker</code> resource for the Kafka Mirror Maker instance.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, <code>KafkaConnectS2I</code>, or <code>Kafka Mirror Maker</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka, Kafka Connect, or Kafka Mirror Maker cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka, Kafka Connect, or Kafka Mirror Maker cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka, Kafka Connect, or Kafka Mirror Maker cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-str"><a class="link" href="#deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f install/cluster-operator -n _my-namespace_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-str"><a class="link" href="#deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f install/cluster-operator -n _my-project_
oc apply -f examples/templates/cluster-operator -n _my-project_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr"><a class="link" href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>my-namespace</em></code> or <code><em>my-project</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-project</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-whole-cluster-str"><a class="link" href="#deploying-cluster-operator-kubernetes-to-watch-whole-cluster-str">2.2.5. Deploying the Cluster Operator to watch all namespaces</a></h4>
<div class="paragraph">
<p>You can configure the Cluster Operator to watch Strimzi resources across all OpenShift projects or Kubernetes namespaces in your OpenShift or Kubernetes cluster. When running in this mode, the Cluster Operator automatically manages clusters in any new projects or namespaces that are created.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Your OpenShift or Kubernetes cluster is running.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Configure the Cluster Operator to watch all namespaces:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Edit the <code>050-Deployment-strimzi-cluster-operator.yaml</code> file.</p>
</li>
<li>
<p>Set the value of the <code>STRIMZI_NAMESPACE</code> environment variable to <code>*</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      # ...
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: "*"
        # ...</code></pre>
</div>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>Create <code>ClusterRoleBindings</code> that grant cluster-wide access to all OpenShift projects or Kubernetes namespaces to the Cluster Operator.</p>
<div class="paragraph">
<p>On OpenShift, use the <code>oc adm policy</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm policy add-cluster-role-to-user strimzi-cluster-operator-namespaced --serviceaccount strimzi-cluster-operator -n <em>my-project</em>
oc adm policy add-cluster-role-to-user strimzi-entity-operator --serviceaccount strimzi-cluster-operator -n <em>my-project</em>
oc adm policy add-cluster-role-to-user strimzi-topic-operator --serviceaccount strimzi-cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>Replace <code><em>my-project</em></code> with the project in which you want to install the Cluster Operator.</p>
</div>
<div class="paragraph">
<p>On Kubernetes, use the <code>kubectl create</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create clusterrolebinding strimzi-cluster-operator-namespaced --clusterrole=strimzi-cluster-operator-namespaced --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator
kubectl create clusterrolebinding strimzi-cluster-operator-entity-operator-delegation --clusterrole=strimzi-entity-operator --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator
kubectl create clusterrolebinding strimzi-cluster-operator-topic-operator-delegation --clusterrole=strimzi-topic-operator --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>Replace <code><em>my-namespace</em></code> with the namespace in which you want to install the Cluster Operator.</p>
</div>
</li>
<li>
<p>Deploy the Cluster Operator to your OpenShift or Kubernetes cluster.</p>
<div class="paragraph">
<p>On OpenShift, use the <code>oc apply</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On Kubernetes, use the <code>kubectl apply</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-str"><a class="link" href="#deploying-cluster-operator-helm-chart-str">2.2.6. Deploying the Cluster Operator using Helm Chart</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi http://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-cluster-str"><a class="link" href="#kafka-cluster-str">2.3. Kafka cluster</a></h3>
<div class="paragraph">
<p>You can use Strimzi to deploy an ephemeral or persistent Kafka cluster to OpenShift or Kubernetes. When installing Kafka, Strimzi also installs a Zookeeper cluster and adds the necessary configuration to connect Kafka with Zookeeper.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Ephemeral cluster</dt>
<dd>
<p>In general, an ephemeral (that is, temporary) Kafka cluster is suitable for development and testing purposes, not for production. This deployment uses <code>emptyDir</code> volumes for storing broker information (for Zookeeper) and topics or partitions (for Kafka). Using an <code>emptyDir</code> volume means that its content is strictly related to the pod life cycle and is deleted when the pod goes down.</p>
</dd>
<dt class="hdlist1">Persistent cluster</dt>
<dd>
<p>A persistent Kafka cluster uses <code>PersistentVolumes</code> to store Zookeeper and Kafka data. The <code>PersistentVolume</code> is
acquired using a <code>PersistentVolumeClaim</code> to make it independent of the actual type of the <code>PersistentVolume</code>. For example, it can use
HostPath volumes on Minikube or
Amazon EBS volumes in Amazon AWS deployments without any changes in the YAML files. The <code>PersistentVolumeClaim</code> can use a <code>StorageClass</code> to trigger automatic volume provisioning.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Strimzi includes two templates for deploying a Kafka cluster:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>kafka-ephemeral.yaml</code> deploys an ephemeral cluster, named <code>my-cluster</code> by default.</p>
</li>
<li>
<p><code>kafka-persistent.yaml</code> deploys a persistent cluster, named <code>my-cluster</code> by default.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The cluster name is defined by the name of the resource and cannot be changed after the cluster has been deployed. To change the cluster name before you deploy the cluster, edit the <code>Kafka.metadata.name</code> property of the resource in the relevant YAML file.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
# ...</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-kubernetes-str"><a class="link" href="#deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</a></h4>
<div class="paragraph">
<p>The following procedure describes how to deploy an ephemeral or persistent Kafka cluster to Kubernetes on the command line.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you plan to use the cluster for development or testing purposes, you can create and deploy an ephemeral cluster using <code>kubectl apply</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you plan to use the cluster in production, create and deploy a persistent cluster using <code>kubectl apply</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information on deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information on the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-openshift-str"><a class="link" href="#deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</a></h4>
<div class="paragraph">
<p>The following procedure describes how to deploy an ephemeral or persistent Kafka cluster to OpenShift on the command line. You can also deploy clusters in the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you plan to use the cluster for development or testing purposes, create and deploy an ephemeral cluster using <code>oc apply</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you plan to use the cluster in production, create and deploy a persistent cluster using <code>oc apply</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information on deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.
For more information on the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-connect-str"><a class="link" href="#kafka-connect-str">2.4. Kafka Connect</a></h3>
<div class="paragraph">
<p><a href="https://kafka.apache.org/documentation/#connect" target="_blank" rel="noopener">Kafka Connect</a> is a tool for streaming data between Apache Kafka and external systems. It provides a framework for moving large amounts of data into and out of your Kafka cluster while maintaining scalability and reliability. Kafka Connect is typically used to integrate Kafka with external databases and storage and messaging systems.</p>
</div>
<div class="paragraph">
<p>You can use Kafka Connect to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Build connector plug-ins (as JAR files) for your Kafka cluster</p>
</li>
<li>
<p>Run connectors</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Kafka Connect includes the following built-in connectors for moving file-based data into and out of your Kafka cluster.</p>
</div>
<table class="tableblock frame-all grid-all stripes-none stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">File Connector</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>FileStreamSourceConnector</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Transfers data to your Kafka cluster from a file (the source).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>FileStreamSinkConnector</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Transfers data from your Kafka cluster to a file (the sink).</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>In Strimzi, you can use the Cluster Operator to deploy a Kafka Connect or Kafka Connect Source-2-Image (S2I) cluster to your OpenShift or Kubernetes cluster.</p>
</div>
<div class="paragraph">
<p>A Kafka Connect cluster is implemented as a <code>Deployment</code> with a configurable number of workers. The Kafka Connect REST API is available on port 8083, as the <code>&lt;connect-cluster-name&gt;-connect-api</code> service.</p>
</div>
<div class="paragraph">
<p>For more information on deploying a Kafka Connect S2I cluster, see <a href="#using-openshift-s2i-create-image-str">Creating a container image using OpenShift builds and Source-to-Image</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-kubernetes-str"><a class="link" href="#deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to your Kubernetes cluster</a></h4>
<div class="paragraph">
<p>You can deploy a Kafka Connect cluster to your Kubernetes cluster by using the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p><a href="#deploying-cluster-operator-kubernetes-str">Deploying the Cluster Operator to Kubernetes</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Use the <code>kubectl apply</code> command to create a <code>KafkaConnect</code> resource based on the <code>kafka-connect.yaml</code> file:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p><a href="#assembly-deployment-configuration-kafka-connect-str">Kafka Connect cluster configuration</a></p>
</li>
<li>
<p><a href="#assembly-deployment-configuration-kafka-connect-s2i-str">Kafka Connect cluster with Source2Image support</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-openshift-str"><a class="link" href="#deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to your OpenShift cluster</a></h4>
<div class="paragraph">
<p>You can deploy a Kafka Connect cluster to your OpenShift cluster by using the Cluster Operator. Kafka Connect is provided as an OpenShift template that you can deploy from the command line or the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p><a href="#deploying-cluster-operator-openshift-str">Deploying the Cluster Operator to OpenShift</a></p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Use the <code>oc apply</code> command to create a <code>KafkaConnect</code> resource based on the <code>kafka-connect.yaml</code> file:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p><a href="#assembly-deployment-configuration-kafka-connect-str">Kafka Connect cluster configuration</a></p>
</li>
<li>
<p><a href="#assembly-deployment-configuration-kafka-connect-s2i-str">Kafka Connect cluster with Source2Image support</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="using-kafka-connect-with-plug-ins-str"><a class="link" href="#using-kafka-connect-with-plug-ins-str">2.4.3. Extending Kafka Connect with plug-ins</a></h4>
<div class="paragraph">
<p>The Strimzi container images for Kafka Connect include the two built-in file connectors: <code>FileStreamSourceConnector</code> and <code>FileStreamSinkConnector</code>. You can add your own connectors by using one of the following methods:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Create a Docker image from the Kafka Connect base image.</p>
</li>
<li>
<p>Create a container image using OpenShift builds and Source-to-Image (S2I).</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="creating-new-image-from-base-str"><a class="link" href="#creating-new-image-from-base-str">Creating a Docker image from the Kafka Connect base image</a></h5>
<div class="paragraph">
<p>A container image for running Kafka Connect using Strimzi is available on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect:0.11.1-kafka-2.1.0</code>. You can use this as a base image for creating your own custom image with additional connector plug-ins.</p>
</div>
<div class="paragraph">
<p>The following procedure explains how to create your custom image and add it to the <code>/opt/kafka/plugins</code> directory. At startup, the AMQ Streams version of Kafka Connect loads any third-party connector plug-ins contained in the <code>/opt/kafka/plugins</code> directory.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p><a href="#deploying-cluster-operator-kubernetes-str">Deploying the Cluster Operator to Kubernetes</a></p>
</li>
<li>
<p><a href="#deploying-cluster-operator-openshift-str">Deploying the Cluster Operator to OpenShift</a></p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a new <code>Dockerfile</code> using <code>strimzi/kafka-connect:0.11.1-kafka-2.1.0</code> as the base image:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>FROM strimzi/kafka-connect:0.11.1-kafka-2.1.0
USER root:root
COPY ./<em>my-plugins</em>/ /opt/kafka/plugins/
USER kafka:kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Build the container image.</p>
</li>
<li>
<p>Push your custom image to your container registry.</p>
</li>
<li>
<p>Edit the <code>KafkaConnect.spec.image</code> property of the <code>KafkaConnect</code> custom resource to point to the new container image. If set, this property overrides the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable referred to in the next step.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect-cluster
spec:
  #...
  image: my-new-container-image</code></pre>
</div>
</div>
</li>
<li>
<p>In the <code>install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> file, edit the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable to point to the new container image.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information on the <code>KafkaConnect.spec.image property</code>, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">Container images</a>.</p>
</li>
<li>
<p>For more information on the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable, see <a href="#ref-operators-cluster-operator-configuration-deploying-co">Cluster Operator Configuration</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="using-openshift-s2i-create-image-str"><a class="link" href="#using-openshift-s2i-create-image-str">Creating a container image using OpenShift builds and Source-to-Image</a></h5>
<div class="paragraph">
<p>You can use OpenShift <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a> and the  <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images. An OpenShift build takes a builder image with S2I support, together with source code and binaries provided by the user, and uses them to build a new container image. Once built, container images are stored in OpenShift&#8217;s local container image repository and are available for use in deployments.</p>
</div>
<div class="paragraph">
<p>A Kafka Connect builder image with S2I support is provided by Strimzi on the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.11.1-kafka-2.1.0</code>. This S2I image takes your binaries (with plug-ins and connectors) and stores them in the <code>/tmp/kafka-plugins/s2i</code> directory. It creates a new Kafka Connect image from this directory, which can then be used with the Kafka Connect deployment. When started using the enhanced image, Kafka Connect loads any third-party plug-ins from the <code>/tmp/kafka-plugins/s2i</code> directory.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>On the command line, use the <code>oc apply</code> command to create and deploy a Kafka Connect S2I cluster:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Create a directory with Kafka Connect plug-ins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>my-plugins</em>/
./<em>my-plugins</em>/
 debezium-connector-mongodb
  bson-3.4.2.jar
  CHANGELOG.md
  CONTRIBUTE.md
  COPYRIGHT.txt
  debezium-connector-mongodb-0.7.1.jar
  debezium-core-0.7.1.jar
  LICENSE.txt
  mongodb-driver-3.4.2.jar
  mongodb-driver-core-3.4.2.jar
  README.md
 debezium-connector-mysql
  CHANGELOG.md
  CONTRIBUTE.md
  COPYRIGHT.txt
  debezium-connector-mysql-0.7.1.jar
  debezium-core-0.7.1.jar
  LICENSE.txt
  mysql-binlog-connector-java-0.13.0.jar
  mysql-connector-java-5.1.40.jar
  README.md
  wkb-1.0.2.jar
 debezium-connector-postgres
     CHANGELOG.md
     CONTRIBUTE.md
     COPYRIGHT.txt
     debezium-connector-postgres-0.7.1.jar
     debezium-core-0.7.1.jar
     LICENSE.txt
     postgresql-42.0.0.jar
     protobuf-java-2.6.1.jar
     README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Use the <code>oc start-build</code> command to start a new build of the image using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>my-connect-cluster-connect</em> --from-dir ./<em>my-plugins</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build is the same as the name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build has finished, the new image is used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-mirror-maker-str"><a class="link" href="#kafka-mirror-maker-str">2.5. Kafka Mirror Maker</a></h3>
<div class="paragraph">
<p>The Cluster Operator deploys one or more Kafka Mirror Maker replicas to replicate data between Kafka clusters.
This process is called mirroring to avoid confusion with the Kafka partitions replication concept.
The Mirror Maker consumes messages from the source cluster and republishes those messages to the target cluster.</p>
</div>
<div class="paragraph">
<p>For information about example resources and the format for deploying Kafka Mirror Maker, see <a href="#assembly-deployment-configuration-kafka-mirror-maker-str">Kafka Mirror Maker configuration</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying-kafka-mirror-maker-kubernetes-str"><a class="link" href="#deploying-kafka-mirror-maker-kubernetes-str">2.5.1. Deploying Kafka Mirror Maker to Kubernetes</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Mirror Maker, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Deploy Kafka Mirror Maker on Kubernetes by creating the corresponding <code>KafkaMirrorMaker</code> resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka-mirror-maker/kafka-mirror-maker.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-mirror-maker-openshift-str"><a class="link" href="#deploying-kafka-mirror-maker-openshift-str">2.5.2. Deploying Kafka Mirror Maker to OpenShift</a></h4>
<div class="paragraph">
<p>On OpenShift, Kafka Mirror Maker is provided in the form of a template. It can be deployed from the template using the command-line or through the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Mirror Maker, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Create a Kafka Mirror Maker cluster from the command-line:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka-mirror-maker/kafka-mirror-maker.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-example-clients-str"><a class="link" href="#deploying-example-clients-str">2.6. Deploying example clients</a></h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the client to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the producer.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl run</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl run kafka-producer -ti --image=strimzi/kafka:0.11.1-kafka-2.1.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc run</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc run kafka-producer -ti --image=strimzi/kafka:0.11.1-kafka-2.1.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em></code></pre>
</div>
</div>
</li>
<li>
<p>Type your message into the console where the producer is running.</p>
</li>
<li>
<p>Press Enter to send the message.</p>
</li>
<li>
<p>Deploy the consumer.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl run</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl run kafka-consumer -ti --image=strimzi/kafka:0.11.1-kafka-2.1.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em> --from-beginning</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc run</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc run kafka-consumer -ti --image=strimzi/kafka:0.11.1-kafka-2.1.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em> --from-beginning</code></pre>
</div>
</div>
</li>
<li>
<p>Confirm that you see the incoming messages in the consumer console.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-topic-operator-str"><a class="link" href="#assembly-getting-started-topic-operator-str">2.7. Topic Operator</a></h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-str"><a class="link" href="#what-the-topic-operator-does-str">2.7.1. Overview of the Topic Operator component</a></h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will delete the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-str"><a class="link" href="#deploying-the-topic-operator-using-the-cluster-operator-str">2.7.2. Deploying the Topic Operator using the Cluster Operator</a></h4>
<div class="paragraph">
<p>This procedure describes how to deploy the Topic Operator using the Cluster Operator.
If you want to use the Topic Operator with a Kafka cluster that is not managed by Strimzi, you must deploy the Topic Operator as a standalone component. For more information, see <a href="#deploying-the-topic-operator-standalone-deploying">Deploying the standalone Topic Operator</a>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Ensure that the <code>Kafka.spec.entityOperator</code> object exists in the <code>Kafka</code> resource. This configures the Entity Operator.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  #...
  entityOperator:
    <strong>topicOperator: {}</strong>
    userOperator: {}</code></pre>
</div>
</div>
</li>
<li>
<p>Configure the Topic Operator using the fields described in <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code> schema reference</a>.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-user-operator-str"><a class="link" href="#assembly-getting-started-user-operator-str">2.8. User Operator</a></h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-str"><a class="link" href="#con-what-the-user-operator-does-str">2.8.1. Overview of the User Operator component</a></h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-str"><a class="link" href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">2.8.2. Deploying the User Operator using the Cluster Operator</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-strimzi-admin-str"><a class="link" href="#assembly-getting-started-strimzi-admin-str">2.9. Strimzi Administrators</a></h3>
<div class="paragraph">
<p>Strimzi includes several custom resources.
By default, permission to create, edit, and delete these resources is limited to OpenShift or Kubernetes cluster administrators.
If you want to allow non-cluster administators to manage Strimzi resources, you must assign them the Strimzi Administrator role.</p>
</div>
<div class="sect3">
<h4 id="proc-adding-users-the-strimzi-admin-role-str"><a class="link" href="#proc-adding-users-the-strimzi-admin-role-str">2.9.1. Designating Strimzi Administrators</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Strimzi <code>CustomResourceDefinitions</code> are installed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create the <code>strimzi-admin</code> cluster role in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/strimzi-admin</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/strimzi-admin</code></pre>
</div>
</div>
</li>
<li>
<p>Assign the <code>strimzi-admin</code> <code>ClusterRole</code> to one or more existing users in the OpenShift or Kubernetes cluster.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create clusterrolebinding strimzi-admin --clusterrole=strimzi-admin --user=<em>user1</em> --user=<em>user2</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc adm</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm policy add-cluster-role-to-user strimzi-admin <em>user1</em> <em>user2</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-deployment-configuration-str"><a class="link" href="#assembly-deployment-configuration-str">3. Deployment configuration</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>This chapter describes how to configure different aspects of the supported deployments:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka clusters</p>
</li>
<li>
<p>Kafka Connect clusters</p>
</li>
<li>
<p>Kafka Connect clusters with <em>Source2Image</em> support</p>
</li>
<li>
<p>Kafka Mirror Maker</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-str"><a class="link" href="#assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</a></h3>
<div class="paragraph">
<p>The full schema of the <code>Kafka</code> resource is described in the <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.
All labels that are applied to the desired <code>Kafka</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-storage-deployment-configuration-kafka"><a class="link" href="#assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</a></h4>
<div class="paragraph">
<p>As stateful applications, Kafka and Zookeeper need to store data on disk. Strimzi supports three different types of storage for this data: ephemeral, persistent, and JBOD (Just a Bunch of Disks) storage.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
JBOD storage is only supported for Kafka, not for Zookeeper.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When configuring a <code>Kafka</code> resource, you can specify the type of storage used by the Kafka broker and its corresponding Zookeeper node. You configure the storage type using the <code>storage</code> property in the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The storage type is configured in the <code>type</code> field.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
The storage type cannot be changed after a Kafka cluster is deployed.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="ref-ephemeral-storage-deployment-configuration-kafka"><a class="link" href="#ref-ephemeral-storage-deployment-configuration-kafka">Ephemeral storage</a></h5>
<div class="paragraph">
<p>Ephemeral storage uses the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir" target="_blank" rel="noopener">`emptyDir` volumes</a> to store data.
To use ephemeral storage, the <code>type</code> field should be set to <code>ephemeral</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<code>EmptyDir</code> volumes are not persistent and the data stored in them will be lost when the Pod is restarted.
After the new pod is started, it has to recover all data from other nodes of the cluster.
Ephemeral storage is not suitable for use with single node Zookeeper clusters and for Kafka topics with replication factor 1, because it will lead to data loss.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example of Ephemeral storage</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: ephemeral
    # ...
  zookeeper:
    # ...
    storage:
      type: ephemeral
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="ref-persistent-storage-deployment-configuration-kafka"><a class="link" href="#ref-persistent-storage-deployment-configuration-kafka">Persistent storage</a></h5>
<div class="paragraph">
<p>Persistent storage uses <a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/" target="_blank" rel="noopener">Persistent Volume Claims</a> to provision persistent volumes for storing data.
Persistent Volume Claims can be used to provision volumes of many different types, depending on the <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> which will provision the volume.
The data types which can be used with persistent volume claims include many types of SAN storage as well as <a href="https://kubernetes.io/docs/concepts/storage/volumes/#local" target="_blank" rel="noopener">Local persistent volumes</a>.</p>
</div>
<div class="paragraph">
<p>To use persistent storage, the <code>type</code> has to be set to <code>persistent-claim</code>.
Persistent storage supports additional configuration options:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>id</code> (optional)</dt>
<dd>
<p>Storage identification number. This option is mandatory for storage volumes defined in a JBOD storage declaration.
Default is <code>0</code>.</p>
</dd>
<dt class="hdlist1"><code>size</code> (required)</dt>
<dd>
<p>Defines the size of the persistent volume claim, for example, "1000Gi".</p>
</dd>
<dt class="hdlist1"><code>class</code> (optional)</dt>
<dd>
<p>The OpenShift or Kubernetes <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> to use for dynamic volume provisioning.</p>
</dd>
<dt class="hdlist1"><code>selector</code> (optional)</dt>
<dd>
<p>Allows selecting a specific persistent volume to use.
It contains key:value pairs representing labels for selecting such a volume.</p>
</dd>
<dt class="hdlist1"><code>deleteClaim</code> (optional)</dt>
<dd>
<p>Boolean value which specifies if the Persistent Volume Claim has to be deleted when the cluster is undeployed.
Default is <code>false</code>.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Resizing persistent storage for existing Strimzi clusters is not currently supported.
You must decide the necessary storage size before deploying the cluster.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with 1000Gi <code>size</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1000Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following example demonstrates the use of a storage class.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with specific Storage Class</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  class: my-storage-class
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, a <code>selector</code> can be used to select a specific labeled persistent volume to provide needed features such as an SSD.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with selector</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  selector:
    hdd-type: ssd
  deleteClaim: true
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">Persistent Volume Claim naming</div>
<p>When the persistent storage is used, it will create Persistent Volume Claims with the following names:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code><em>idx</em></code>.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-zookeeper-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code><em>idx</em></code>.</p>
</dd>
</dl>
</div>
</div>
<div class="sect4">
<h5 id="ref-jbod-storage-deployment-configuration-kafka"><a class="link" href="#ref-jbod-storage-deployment-configuration-kafka">JBOD storage overview</a></h5>
<div class="paragraph">
<p>You can configure Strimzi to use JBOD, a data storage configuration in which multiple disks are combined to create a single logical disk, or volume. JBOD is one approach to providing increased data storage for Kafka brokers. It can also improve performance.</p>
</div>
<div class="paragraph">
<p>A JBOD configuration is described by one or more volumes, each of which can be either <a href="#ref-ephemeral-storage-deployment-configuration-kafka">ephemeral</a> or <a href="#ref-persistent-storage-deployment-configuration-kafka">persistent</a>. The rules and constraints for JBOD volume declarations are the same as those for ephemeral and persistent storage. For example, you cannot change the size of a persistent storage volume after it has been provisioned.</p>
</div>
<div class="sect5">
<h6 id="jbod_configuration"><a class="link" href="#jbod_configuration">JBOD configuration</a></h6>
<div class="paragraph">
<p>To use JBOD with Strimzi, the storage <code>type</code> must be set to <code>jbod</code>. The <code>volumes</code> property allows you to describe the disks that make up your JBOD storage array or configuration. The following fragment shows an example JBOD configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: jbod
  volumes:
  - id: 0
    type: persistent-claim
    size: 100Gi
    deleteClaim: false
  - id: 1
    type: persistent-claim
    size: 100Gi
    deleteClaim: false
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The ids cannot be changed once the JBOD volumes are created.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Adding and removing volumes from a JBOD configuration is not currently supported.
</td>
</tr>
</table>
</div>
</div>
<div class="sect5">
<h6 id="jbod_and_persistent_volume_claims"><a class="link" href="#jbod_and_persistent_volume_claims">JBOD and Persistent Volume Claims</a></h6>
<div class="paragraph">
<p>When persistent storage is used to declare JBOD volumes, the naming scheme of the resulting Persistent Volume Claims is as follows:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>data-<em>id</em>-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Where <code><em>id</em></code> is the ID of the volume used for storing data for Kafka broker pod <code><em>idx</em></code>.</p>
</dd>
</dl>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about ephemeral storage, see <a href="#type-EphemeralStorage-reference">ephemeral storage schema reference</a>.</p>
</li>
<li>
<p>For more information about persistent storage, see <a href="#type-PersistentClaimStorage-reference">persistent storage schema reference</a>.</p>
</li>
<li>
<p>For more information about JBOD storage, see <a href="#type-JbodStorage-reference">JBOD schema reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-replicas-deployment-configuration-kafka"><a class="link" href="#assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Kafka broker replicas</a></h4>
<div class="paragraph">
<p>A Kafka cluster can run with many brokers.
You can configure the number of brokers used for the Kafka cluster in <code>Kafka.spec.kafka.replicas</code>.
The best number of brokers for your cluster has to be determined based on your specific use case.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-broker-replicas-deployment-configuration-kafka"><a class="link" href="#proc-configuring-kafka-broker-replicas-deployment-configuration-kafka">Configuring the number of broker nodes</a></h5>
<div class="paragraph">
<p>This procedure describes how to configure the number of Kafka broker nodes in a new cluster.
It only applies to new clusters, with no partitions.
If your cluster already has topics defined you should see
<a href="#scaling-clusters-deployment-configuration-kafka">Scaling clusters</a>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A Kafka cluster with no topics defined yet</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    replicas: 3
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">Additional resources</div>
<p>If your cluster already has topics defined see
<a href="#scaling-clusters-deployment-configuration-kafka">Scaling clusters</a>.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-configuration-deployment-configuration-kafka"><a class="link" href="#assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka brokers.
You can specify and configure most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Broker ID configuration</p>
</li>
<li>
<p>Configuration of log data directories</p>
</li>
<li>
<p>Inter-broker communication</p>
</li>
<li>
<p>Zookeeper connectivity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-broker-configuration-deployment-configuration-kafka"><a class="link" href="#ref-kafka-broker-configuration-deployment-configuration-kafka">Kafka broker configuration</a></h5>
<div class="paragraph">
<p>Kafka broker can be configured using the <code>config</code> property in <code>Kafka.spec.kafka</code>.</p>
</div>
<div class="paragraph">
<p>This property should contain the Kafka broker configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://kafka.apache.org/20/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>advertised.</code></p>
</li>
<li>
<p><code>broker.</code></p>
</li>
<li>
<p><code>listener.</code></p>
</li>
<li>
<p><code>host.name</code></p>
</li>
<li>
<p><code>port</code></p>
</li>
<li>
<p><code>inter.broker.listener.name</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>password.</code></p>
</li>
<li>
<p><code>principal.builder.class</code></p>
</li>
<li>
<p><code>log.dir</code></p>
</li>
<li>
<p><code>zookeeper.connect</code></p>
</li>
<li>
<p><code>zookeeper.set.acl</code></p>
</li>
<li>
<p><code>authorizer.</code></p>
</li>
<li>
<p><code>super.user</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Cluster Operator log file.
All other options will be passed to Kafka.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Kafka cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.kafka.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka brokers.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka broker configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    config:
      num.partitions: 1
      num.recovery.threads.per.data.dir: 1
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      num.network.threads: 3
      num.io.threads: 8
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      group.initial.rebalance.delay.ms: 0
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-brokers-deployment-configuration-kafka"><a class="link" href="#proc-configuring-kafka-brokers-deployment-configuration-kafka">Configuring Kafka brokers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    config:
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka"><a class="link" href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</a></h4>
<div class="paragraph">
<p>Strimzi allows users to configure the listeners which will be enabled in Kafka brokers.
Two types of listeners are supported:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Plain listener on port 9092 (without encryption)</p>
</li>
<li>
<p>TLS listener on port 9093 (with encryption)</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="con-mutual-tls-authentication-deployment-configuration-kafka"><a class="link" href="#con-mutual-tls-authentication-deployment-configuration-kafka">Mutual TLS authentication for clients</a></h5>
<div class="sect5">
<h6 id="mutual_tls_authentication"><a class="link" href="#mutual_tls_authentication">Mutual TLS authentication</a></h6>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_mutual_tls_authentication_for_clients"><a class="link" href="#when_to_use_mutual_tls_authentication_for_clients">When to use mutual TLS authentication for clients</a></h6>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-scram-sha-authentication-deployment-configuration-kafka"><a class="link" href="#con-scram-sha-authentication-deployment-configuration-kafka">SCRAM-SHA authentication</a></h5>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRAM-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="supported_scram_credentials"><a class="link" href="#supported_scram_credentials">Supported SCRAM credentials</a></h6>
<div class="paragraph">
<p>Strimzi supports SCRAM-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_scram_sha_authentication_for_clients"><a class="link" href="#when_to_use_scram_sha_authentication_for_clients">When to use SCRAM-SHA authentication for clients</a></h6>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-kafka-listeners-deployment-configuration-kafka"><a class="link" href="#con-kafka-listeners-deployment-configuration-kafka">Kafka listeners</a></h5>
<div class="paragraph">
<p>You can configure Kafka broker listeners using the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
The <code>listeners</code> property contains three sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>plain</code></p>
</li>
<li>
<p><code>tls</code></p>
</li>
<li>
<p><code>external</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When none of these properties are defined, the listener will be disabled.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with all listeners enabled</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
  tls: {}
# ...</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with only the plain listener enabled</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
# ...</code></pre>
</div>
</div>
<div class="sect5">
<h6 id="external_listener"><a class="link" href="#external_listener">External listener</a></h6>
<div class="paragraph">
<p>The external listener is used to connect to a Kafka cluster from outside of an OpenShift or Kubernetes environment.
Strimzi supports three types of external listeners:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>route</code></p>
</li>
<li>
<p><code>loadbalancer</code></p>
</li>
<li>
<p><code>nodeport</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using OpenShift Routes</div>
<p>An external listener of type <code>route</code> exposes Kafka by using OpenShift <code>Routes</code> and the HAProxy router.
A dedicated <code>Route</code> is created for every Kafka broker pod.
An additional <code>Route</code> is created to serve as a Kafka bootstrap address.
Kafka clients can use these <code>Routes</code> to connect to Kafka on port 443.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code>Routes</code> are available only on OpenShift. External listeners of type <code>route</code> cannot be used on Kubernetes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When exposing Kafka using OpenShift <code>Routes</code>, TLS encryption is always used.</p>
</div>
<div class="paragraph">
<p>By default, the route hosts are automatically assigned by OpenShift.
However, you can override the assigned route hosts by specifying the requested hosts in the <code>overrides</code> property.
Strimzi will not perform any validation that the requested hosts are available; you must ensure that they are free and can be used.</p>
</div>
<div class="listingblock">
<div class="title">Example of an external listener of type <code>routes</code> configured with overrides for OpenShift route hosts</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  external:
    type: route
    authentication:
      type: tls
    overrides:
      bootstrap:
        host: bootstrap.myrouter.com
      brokers:
      - broker: 0
        host: broker-0.myrouter.com
      - broker: 1
        host: broker-1.myrouter.com
      - broker: 2
        host: broker-2.myrouter.com
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more information on using <code>Routes</code> to access Kafka, see <a href="#proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using loadbalancers</div>
<p>External listeners of type <code>loadbalancer</code> expose Kafka by using <code>Loadbalancer</code> type <code>Services</code>.
A new loadbalancer service is created for every Kafka broker pod.
An additional loadbalancer is created to serve as a Kafka <em>bootstrap</em> address.
Loadbalancers listen to connections on port 9094.</p>
</div>
<div class="paragraph">
<p>By default, TLS encryption is enabled.
To disable it, set the <code>tls</code> field to <code>false</code>.</p>
</div>
<div class="paragraph">
<p>For more information on using loadbalancers to access Kafka, see <a href="#proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using node ports</div>
<p>External listeners of type <code>nodeport</code> expose Kafka by using <code>NodePort</code> type <code>Services</code>.
When exposing Kafka in this way, Kafka clients connect directly to the nodes of OpenShift or Kubernetes.
You must enable access to the ports on the OpenShift or Kubernetes nodes for each client (for example, in firewalls or security groups).
Each Kafka broker pod is then accessible on a separate port.
Additional <code>NodePort</code> type <code>Service</code> is created to serve as a Kafka bootstrap address.</p>
</div>
<div class="paragraph">
<p>When configuring the advertised addresses for the Kafka broker pods, Strimzi uses the address of the node on which the given pod is running.
When selecting the node address, the different address types are used with the following priority:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>By default, TLS encryption is enabled.
To disable it, set the <code>tls</code> field to <code>false</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS hostname verification is not currently supported when exposing Kafka clusters using node ports.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By default, the port numbers used for the bootstrap and broker services are automatically assigned by OpenShift or Kubernetes.
However, you can override the assigned node ports by specifying the requested port numbers in the <code>overrides</code> property.
Strimzi does not perform any validation on the requested ports; you must ensure that they are free and available for use.</p>
</div>
<div class="listingblock">
<div class="title">Example of an external listener configured with overrides for node ports</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  external:
    type: nodeport
    tls: true
    authentication:
      type: tls
    overrides:
      bootstrap:
        nodePort: 32100
      brokers:
      - broker: 0
        nodePort: 32000
      - broker: 1
        nodePort: 32001
      - broker: 2
        nodePort: 32002
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more information on using node ports to access Kafka, see <a href="#proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Customizing advertised addresses on external listeners</div>
<p>By default, Strimzi tries to automatically determine the hostnames and ports that your Kafka cluster advertises to its clients.
This is not sufficient in all situations, because the infrastructure on which Strimzi is running might not provide the right hostname or port through which Kafka can be accessed.
You can customize the advertised hostname and port in the <code>overrides</code> property of the external listener.
Strimzi will then automatically configure the advertised address in the Kafka brokers and add it to the broker certificates so it can be used for TLS hostname verification.
Overriding the advertised host and ports is available for all types of external listeners.</p>
</div>
<div class="listingblock">
<div class="title">Example of an external listener configured with overrides for advertised addresses</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  external:
    type: route
    authentication:
      type: tls
    overrides:
      brokers:
      - broker: 0
        advertisedHost: example.hostname.0
        advertisedPort: 12340
      - broker: 1
        advertisedHost: example.hostname.1
        advertisedPort: 12341
      - broker: 2
        advertisedHost: example.hostname.2
        advertisedPort: 12342
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Additionally, you can specify the name of the bootstrap service.
This name will be added to the broker certificates and can be used for TLS hostname verification.
Adding the additional bootstrap address is available for all types of external listeners.</p>
</div>
<div class="listingblock">
<div class="title">Example of an external listener configured with an additional bootstrap address</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  external:
    type: route
    authentication:
      type: tls
    overrides:
      bootstrap:
        address: example.hostname
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="listener_authentication"><a class="link" href="#listener_authentication">Listener authentication</a></h6>
<div class="paragraph">
<p>The listener sub-properties can also contain additional configuration.
Both listeners support the <code>authentication</code> property. This is used to specify an authentication mechanism specific to that listener:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>mutual TLS authentication (only on the listeners with TLS encryption)</p>
</li>
<li>
<p>SCRAM-SHA authentication</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If no <code>authentication</code> property is specified then the listener does not authenticate clients which connect though that listener.</p>
</div>
<div class="listingblock">
<div class="title">An example where the plain listener is configured for SCRAM-SHA authentication and the <code>tls</code> listener with mutual TLS authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain:
    authentication:
      type: scram-sha-512
  tls:
    authentication:
      type: tls
  external:
    type: loadbalancer
    tls: true
    authentication:
      type: tls
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Authentication must be configured when using the User Operator to manage <code>KafkaUsers</code>.</p>
</div>
</div>
<div class="sect5">
<h6 id="network_policies"><a class="link" href="#network_policies">Network policies</a></h6>
<div class="paragraph">
<p>Strimzi automatically creates a <code>NetworkPolicy</code> resource for every listener that is enabled on a Kafka broker.
By default, a <code>NetworkPolicy</code> grants access to a listener to all applications and namespaces.
If you want to restrict access to a listener to only selected applications or namespaces, use the <code>networkPolicyPeers</code> field.
Each listener can have a different <code>networkPolicyPeers</code> configuration.</p>
</div>
<div class="paragraph">
<p>The following example shows a <code>networkPolicyPeers</code> configuration for a <code>plain</code> and a <code>tls</code> listener:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
      plain:
        authentication:
          type: scram-sha-512
        networkPolicyPeers:
          - podSelector:
              matchLabels:
                app: kafka-sasl-consumer
          - podSelector:
              matchLabels:
                app: kafka-sasl-producer
      tls:
        authentication:
          type: tls
        networkPolicyPeers:
          - namespaceSelector:
              matchLabels:
                project: myproject
          - namespaceSelector:
              matchLabels:
                project: myproject2
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Only application pods matching the labels <code>app: kafka-sasl-consumer</code> and <code>app: kafka-sasl-producer</code> can connect to the <code>plain</code> listener.
The application pods must be running in the same namespace as the Kafka broker.</p>
</li>
<li>
<p>Only application pods running in namespaces matching the labels <code>project: myproject</code> and <code>project: myproject2</code> can connect to the <code>tls</code> listener.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The syntax of the <code>networkPolicyPeers</code> field is the same as the <code>from</code> field in the <code>NetworkPolicy</code> resource in Kubernetes.
For more information about the schema, see <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking" target="_blank" rel="noopener">NetworkPolicyPeer API reference</a> and the <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Your configuration of OpenShift or Kubernetes must support Ingress NetworkPolicies in order to use network policies in Strimzi.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-listeners-deployment-configuration-kafka"><a class="link" href="#proc-configuring-kafka-listeners-deployment-configuration-kafka">Configuring Kafka listeners</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>An example configuration of the plain (unencrypted) listener without authentication:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      plain: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-routes-deployment-configuration-kafka"><a class="link" href="#proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>route</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use <code>Routes</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: route
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the address of the bootstrap <code>Route</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get routes _cluster-name_-kafka-bootstrap -o=jsonpath='{.status.ingress[0].host}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the address together with port 443 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Extract the public certificate of the broker certification authority</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/_cluster-name_-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka"><a class="link" href="#proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>loadbalancer</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use loadbalancers:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: loadbalancer
        tls: true
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the hostname of the bootstrap loadbalancer.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If no hostname was found (nothing was returned by the command), use the loadbalancer IP address.</p>
</div>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the hostname or IP address together with port 9094 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Unless TLS encryption was disabled, extract the public certificate of the broker certification authority.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>cluster-name</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>cluster-name</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-nodeports-deployment-configuration-kafka"><a class="link" href="#proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>nodeport</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use node ports:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: nodeport
        tls: true
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the port number of the bootstrap service.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>The port should be used in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Find the address of the OpenShift or Kubernetes node.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get node <em>node-name</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get node <em>node-name</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If several different addresses are returned, select the address type you want based on the following order:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
<div class="paragraph">
<p>Use the address with the port found in the previous step in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>Unless TLS encryption was disabled, extract the public certificate of the broker certification authority.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>cluster-name</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>cluster-name</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-restricting-access-to-listeners-using-network-policies-deployment-configuration-kafka"><a class="link" href="#proc-restricting-access-to-listeners-using-network-policies-deployment-configuration-kafka">Restricting access to Kafka listeners using <code>networkPolicyPeers</code></a></h5>
<div class="paragraph">
<p>You can restrict access to a listener to only selected applications by using the <code>networkPolicyPeers</code> field.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster with support for Ingress NetworkPolicies.</p>
</li>
<li>
<p>The Cluster Operator is running.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Open the <code>Kafka</code> resource.</p>
</li>
<li>
<p>In the <code>networkPolicyPeers</code> field, define the application pods or namespaces that will be allowed to access the Kafka cluster.</p>
<div class="paragraph">
<p>For example, to configure a <code>tls</code> listener to allow connections only from application pods with the label <code>app</code> set to <code>kafka-client</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      tls:
        networkPolicyPeers:
          - podSelector:
              matchLabels:
                app: kafka-client
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking" target="_blank" rel="noopener">NetworkPolicyPeer API reference</a> and the <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-authentication-and-authorization-deployment-configuration-kafka"><a class="link" href="#assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</a></h4>
<div class="paragraph">
<p>Strimzi supports authentication and authorization.
Authentication can be configured independently for each <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener</a>.
Authorization is always configured for the whole Kafka cluster.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-authentication-deployment-configuration-kafka"><a class="link" href="#ref-kafka-authentication-deployment-configuration-kafka">Authentication</a></h5>
<div class="paragraph">
<p>Authentication is configured as part of the <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener configuration</a> in the <code>authentication</code> property.
When the <code>authentication</code> property is missing, no authentication will be enabled on given listener.
The authentication mechanism which will be used is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>The supported authentication mechanisms are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL SCRAM-SHA-512</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication"><a class="link" href="#tls_client_authentication">TLS client authentication</a></h6>
<div class="paragraph">
<p>TLS Client authentication can be enabled by specifying the <code>type</code> as <code>tls</code>.
The TLS client authentication is supported only on the <code>tls</code> listener.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>authentication</code> with type <code>tls</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authentication:
  type: tls
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authentication-deployment-configuration-kafka"><a class="link" href="#proc-kafka-authentication-deployment-configuration-kafka">Configuring authentication in Kafka brokers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
Add the <code>authentication</code> field to the listeners where you want to enable authentication.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      tls:
        authentication:
          type: tls
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authentication mechanisms, see <a href="#ref-kafka-authentication-deployment-configuration-kafka">authentication reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="ref-kafka-authorization-deployment-configuration-kafka"><a class="link" href="#ref-kafka-authorization-deployment-configuration-kafka">Authorization</a></h5>
<div class="paragraph">
<p>Authorization can be configured using the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
When the <code>authorization</code> property is missing, no authorization will be enabled.
When authorization is enabled it will be applied for all enabled <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listeners</a>.
The authorization method is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>Currently, the only supported authorization method is the Simple authorization.</p>
</div>
<div class="sect5">
<h6 id="simple_authorization"><a class="link" href="#simple_authorization">Simple authorization</a></h6>
<div class="paragraph">
<p>Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
To enable simple authorization, the <code>type</code> field should be set to <code>simple</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of Simple authorization</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authorization:
  type: simple
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authorization-deployment-configuration-kafka"><a class="link" href="#proc-kafka-authorization-deployment-configuration-kafka">Configuring authorization in Kafka brokers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add or edit the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    authorization:
      type: simple
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authorization methods, see <a href="#ref-kafka-authorization-deployment-configuration-kafka">authorization reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-replicas-deployment-configuration-kafka"><a class="link" href="#assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Zookeeper replicas</a></h4>
<div class="paragraph">
<p>Zookeeper clusters or ensembles usually run with an odd number of nodes and always requires the majority of the nodes to be available in order to maintain a quorum.
Maintaining a quorum is important because when the Zookeeper cluster loses a quorum, it will stop responding to clients.
As a result, a Zookeeper cluster without a quorum will cause the Kafka brokers to stop working as well.
This is why having a stable and highly available Zookeeper cluster is very important for Strimzi.</p>
</div>
<div class="paragraph">
<p>A Zookeeper cluster is usually deployed with three, five, or seven nodes.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Three nodes</dt>
<dd>
<p>Zookeeper cluster consisting of three nodes requires at least two nodes to be up and running in order to maintain the quorum.
It can tolerate only one node being unavailable.</p>
</dd>
<dt class="hdlist1">Five nodes</dt>
<dd>
<p>Zookeeper cluster consisting of five nodes requires at least three nodes to be up and running in order to maintain the quorum.
It can tolerate two nodes being unavailable.</p>
</dd>
<dt class="hdlist1">Seven nodes</dt>
<dd>
<p>Zookeeper cluster consisting of seven nodes requires at least four nodes to be up and running in order to maintain the quorum.
It can tolerate three nodes being unavailable.</p>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For development purposes, it is also possible to run Zookeeper with a single node.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Having more nodes does not necessarily mean better performance, as the costs to maintain the quorum will rise with the number of nodes in the cluster.
Depending on your availability requirements, you can decide for the number of nodes to use.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-replicas-deployment-configuration-kafka"><a class="link" href="#ref-zookeeper-replicas-deployment-configuration-kafka">Number of Zookeeper nodes</a></h5>
<div class="paragraph">
<p>The number of Zookeeper nodes can be configured using the <code>replicas</code> property in <code>Kafka.spec.zookeeper</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing replicas configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-replicas-deployment-configuration-kafka"><a class="link" href="#proc-configuring-zookeeper-replicas-deployment-configuration-kafka">Changing number of replicas</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-node-configuration-deployment-configuration-kafka"><a class="link" href="#assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Zookeeper nodes.
You can specify and configure most of the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Configuration of data directories</p>
</li>
<li>
<p>Zookeeper cluster composition</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-node-configuration-deployment-configuration-kafka"><a class="link" href="#ref-zookeeper-node-configuration-deployment-configuration-kafka">Zookeeper configuration</a></h5>
<div class="paragraph">
<p>Zookeeper nodes can be configured using the <code>config</code> property in <code>Kafka.spec.zookeeper</code>.
This property should contain the Zookeeper configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>server.</code></p>
</li>
<li>
<p><code>dataDir</code></p>
</li>
<li>
<p><code>dataLogDir</code></p>
</li>
<li>
<p><code>clientPort</code></p>
</li>
<li>
<p><code>authProvider</code></p>
</li>
<li>
<p><code>quorum.auth</code></p>
</li>
<li>
<p><code>requireClientAuthScheme</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Zookeeper.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Zookeeper cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.zookeeper.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Zookeeper nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>timeTick</code> with default value <code>2000</code></p>
</li>
<li>
<p><code>initLimit</code> with default value <code>5</code></p>
</li>
<li>
<p><code>syncLimit</code> with default value <code>2</code></p>
</li>
<li>
<p><code>autopurge.purgeInterval</code> with default value <code>1</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured when they are not present in the <code>Kafka.spec.zookeeper.config</code> property.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Zookeeper configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-nodes-deployment-configuration-kafka"><a class="link" href="#proc-configuring-zookeeper-nodes-deployment-configuration-kafka">Configuring Zookeeper</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-entity-operator-deployment-configuration-kafka"><a class="link" href="#assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</a></h4>
<div class="paragraph">
<p>The Entity Operator is responsible for managing different entities in a running Kafka cluster.
The currently supported entities are:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Kafka topics</dt>
<dd>
<p>managed by the Topic Operator.</p>
</dd>
<dt class="hdlist1">Kafka users</dt>
<dd>
<p>managed by the User Operator</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Both Topic and User Operators can be deployed on their own.
But the easiest way to deploy them is together with the Kafka cluster as part of the Entity Operator.
The Entity Operator can include either one or both of them depending on the configuration.
They will be automatically configured to manage the topics and users of the Kafka cluster with which they are deployed.</p>
</div>
<div class="paragraph">
<p>For more information about Topic Operator, see <a href="#deploying-the-topic-operator-str">Topic Operator</a>.
For more information about how to use Topic Operator to create or delete topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-entity-operator-deployment-configuration-kafka"><a class="link" href="#ref-kafka-entity-operator-deployment-configuration-kafka">Configuration</a></h5>
<div class="paragraph">
<p>The Entity Operator can be configured using the <code>entityOperator</code> property in <code>Kafka.spec</code></p>
</div>
<div class="paragraph">
<p>The <code>entityOperator</code> property supports several sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tlsSidecar</code></p>
</li>
<li>
<p><code>affinity</code></p>
</li>
<li>
<p><code>tolerations</code></p>
</li>
<li>
<p><code>topicOperator</code></p>
</li>
<li>
<p><code>userOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>tlsSidecar</code> property can be used to configure the TLS sidecar container which is used to communicate with Zookeeper.
For more details about configuring the TLS sidecar, see <a href="#assembly-tls-sidecar-deployment-configuration-kafka">TLS sidecar</a>.</p>
</div>
<div class="paragraph">
<p>The <code>affinity</code> and <code>tolerations</code> properties can be used to configure how OpenShift or Kubernetes schedules the Entity Operator pod.
For more details about pod scheduling, see <a href="#assembly-scheduling-deployment-configuration-kafka">Configuring pod scheduling</a>.</p>
</div>
<div class="paragraph">
<p>The <code>topicOperator</code> property contains the configuration of the Topic Operator.
When this option is missing, the Entity Operator will be deployed without the Topic Operator.</p>
</div>
<div class="paragraph">
<p>The <code>userOperator</code> property contains the configuration of the User Operator.
When this option is missing, the Entity Operator will be deployed without the User Operator.</p>
</div>
<div class="listingblock">
<div class="title">Example of basic configuration enabling both operators</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator: {}
    userOperator: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>When both <code>topicOperator</code> and <code>userOperator</code> properties are missing, the Entity Operator will be not deployed.</p>
</div>
<div class="sect5">
<h6 id="topic_operator"><a class="link" href="#topic_operator">Topic Operator</a></h6>
<div class="paragraph">
<p>Topic Operator deployment can be configured using additional options inside the <code>topicOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaTopics</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 90.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 20 seconds.</p>
</dd>
<dt class="hdlist1"><code>topicMetadataMaxAttempts</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its many partitions or replicas. Default is <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the Topic Operator
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the Topic Operator
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="user_operator"><a class="link" href="#user_operator">User Operator</a></h6>
<div class="paragraph">
<p>User Operator deployment can be configured using additional options inside the <code>userOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaUsers</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 120.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 6 seconds.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the User Operator.
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the User Operator.
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-entity-operator-deployment-configuration-kafka"><a class="link" href="#proc-configuring-kafka-entity-operator-deployment-configuration-kafka">Configuring Entity Operator</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>entityOperator</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka"><a class="link" href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</a></h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka"><a class="link" href="#ref-resource-limits-and-requests-deployment-configuration-kafka">Resource limits and requests</a></h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests"><a class="link" href="#resource_requests">Resource requests</a></h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits"><a class="link" href="#resource_limits">Resource limits</a></h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats"><a class="link" href="#supported_cpu_formats">Supported CPU formats</a></h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats"><a class="link" href="#supported_memory_formats">Supported memory formats</a></h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources"><a class="link" href="#additional_resources">Additional resources</a></h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka"><a class="link" href="#proc-configuring-resource-limits-and-requests-deployment-configuration-kafka">Configuring resource requests and limits</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka"><a class="link" href="#assembly-logging-deployment-configuration-kafka">3.1.10. Logging</a></h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka"><a class="link" href="#kafka-inline-logging-deployment-configuration-kafka">Using inline logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka"><a class="link" href="#kafka-external-logging-deployment-configuration-kafka">Using external ConfigMap for logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka"><a class="link" href="#kafka-logging-loggers-deployment-configuration-kafka">Loggers</a></h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-rack-deployment-configuration-kafka"><a class="link" href="#assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</a></h4>
<div class="paragraph">
<p>The rack awareness feature in Strimzi helps to spread the Kafka broker pods and Kafka topic replicas across different racks.
Enabling rack awareness helps to improve availability of Kafka brokers and the topics they are hosting.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
"Rack" might represent an availability zone, data center, or an actual rack in your data center.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-rack-awareness-deployment-configuration-kafka"><a class="link" href="#proc-configuring-kafka-rack-awareness-deployment-configuration-kafka">Configuring rack awareness in Kafka brokers</a></h5>
<div class="paragraph">
<p>Kafka rack awareness can be configured in the <code>rack</code> property of <code>Kafka.spec.kafka</code>.
The <code>rack</code> object has one mandatory field named <code>topologyKey</code>.
This key needs to match one of the labels assigned to the OpenShift or Kubernetes cluster nodes.
The label is used by OpenShift or Kubernetes when scheduling the Kafka broker pods to nodes.
If the OpenShift or Kubernetes cluster is running on a cloud provider platform, that label should represent the availability zone where the node is running.
Usually, the nodes are labeled with <code>failure-domain.beta.kubernetes.io/zone</code> that can be easily used as the <code>topologyKey</code> value.
This has the effect of spreading the broker pods across zones, and also setting the brokers' <code>broker.rack</code> configuration parameter inside Kafka broker.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Consult your OpenShift or Kubernetes administrator regarding the node label that represent the zone / rack into which the node is deployed.</p>
</li>
<li>
<p>Edit the <code>rack</code> property in the <code>Kafka</code> resource using the label as the topology key.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    rack:
      topologyKey: failure-domain.beta.kubernetes.io/zone
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional Resources</div>
<ul>
<li>
<p>For information about Configuring init container image for Kafka rack awareness, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka"><a class="link" href="#assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</a></h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka"><a class="link" href="#ref-healthchecks-deployment-configuration-kafka">Healthcheck configurations</a></h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka"><a class="link" href="#proc-configuring-healthchecks-deployment-configuration-kafka">Configuring healthchecks</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka"><a class="link" href="#assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</a></h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka"><a class="link" href="#ref-metrics-deployment-configuration-kafka">Metrics configuration</a></h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka"><a class="link" href="#proc-configuring-metrics-deployment-configuration-kafka">Configuring Prometheus metrics</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka"><a class="link" href="#assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</a></h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka"><a class="link" href="#ref-jvm-options-deployment-configuration-kafka">JVM configuration</a></h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4  the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5  the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka"><a class="link" href="#proc-configuring-jvm-options-deployment-configuration-kafka">Configuring JVM options</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka"><a class="link" href="#assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</a></h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka"><a class="link" href="#ref-configuring-container-images-deployment-configuration-kafka">Container image configurations</a></h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="configuring_the_kafka_spec_kafka_image_property"><a class="link" href="#configuring_the_kafka_spec_kafka_image_property">Configuring the <code>Kafka.spec.kafka.image</code> property</a></h6>
<div class="paragraph">
<p>The <code>Kafka.spec.kafka.image</code> property functions differently from the others, because Strimzi supports multiple versions of Kafka, each requiring the own image.
The <code>STRIMZI_KAFKA_IMAGES</code> environment variable of the Cluster Operator configuration is used to provide a mapping between Kafka versions and the corresponding images.
This is used in combination with the <code>Kafka.spec.kafka.image</code> and <code>Kafka.spec.kafka.version</code> properties as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If neither <code>Kafka.spec.kafka.image</code> nor <code>Kafka.spec.kafka.version</code> are given in the custom resource then the <code>version</code> will default to the  Cluster Operator&#8217;s default Kafka version, and the image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.image</code> is given but <code>Kafka.spec.kafka.version</code> is not then the given image will be used and the <code>version</code> will be assumed to be the  Cluster Operator&#8217;s default Kafka version.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.version</code> is given but <code>Kafka.spec.kafka.image</code> is not then image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>Both <code>Kafka.spec.kafka.version</code> and <code>Kafka.spec.kafka.image</code> are given the given image will be used, and it will be assumed to contain a Kafka broker with the given version.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
It is best to provide just <code>Kafka.spec.kafka.version</code> and leave the <code>Kafka.spec.kafka.image</code> property unspecified.
This reduces the chances of making a mistake in configuring the <code>Kafka</code> resource. If you need to change the images used for different versions of Kafka, it is better to configure the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> environment variable.
</td>
</tr>
</table>
</div>
</div>
<div class="sect5">
<h6 id="configuring_the_image_property_in_other_resources"><a class="link" href="#configuring_the_image_property_in_other_resources">Configuring the <code>image</code> property in other resources</a></h6>
<div class="paragraph">
<p>For the <code>image</code> property in the other custom resources, the given value will be used during deployment.
If the <code>image</code> property is missing, the <code>image</code> specified in the Cluster Operator configuration will be used.
If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka"><a class="link" href="#proc-configuring-container-images-deployment-configuration-kafka">Configuring container images</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-tls-sidecar-deployment-configuration-kafka"><a class="link" href="#assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</a></h4>
<div class="paragraph">
<p>A sidecar is a container that runs in a pod but serves a supporting purpose.
In Strimzi, the TLS sidecar uses TLS to encrypt and decrypt all communication between the various components and Zookeeper.
Zookeeper does not have native TLS support.</p>
</div>
<div class="paragraph">
<p>The TLS sidecar is used in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka brokers</p>
</li>
<li>
<p>Zookeeper nodes</p>
</li>
<li>
<p>Entity Operator</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="ref-tls-sidecar-deployment-configuration-kafka"><a class="link" href="#ref-tls-sidecar-deployment-configuration-kafka">TLS sidecar configuration</a></h5>
<div class="paragraph">
<p>The TLS sidecar can be configured using the <code>tlsSidecar</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The TLS sidecar supports the following additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>image</code></p>
</li>
<li>
<p><code>resources</code></p>
</li>
<li>
<p><code>logLevel</code></p>
</li>
<li>
<p><code>readinessProbe</code></p>
</li>
<li>
<p><code>livenessProbe</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>resources</code> property can be used to specify the <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory and CPU resources</a> allocated for the TLS sidecar.</p>
</div>
<div class="paragraph">
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</div>
<div class="paragraph">
<p>The <code>logLevel</code> property is used to specify the logging level.
Following logging levels are supported:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>emerg</p>
</li>
<li>
<p>alert</p>
</li>
<li>
<p>crit</p>
</li>
<li>
<p>err</p>
</li>
<li>
<p>warning</p>
</li>
<li>
<p>notice</p>
</li>
<li>
<p>info</p>
</li>
<li>
<p>debug</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The default value is <em>notice</em>.</p>
</div>
<div class="paragraph">
<p>For more information about configuring the <code>readinessProbe</code> and <code>livenessProbe</code> properties for the healthchecks, see <a href="#ref-healthchecks-deployment-configuration-kafka">Healthcheck configurations</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      image: my-org/my-image:latest
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
      logLevel: debug
      readinessProbe:
        initialDelaySeconds: 15
        timeoutSeconds: 5
      livenessProbe:
        initialDelaySeconds: 15
        timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-tls-sidecar-deployment-configuration-kafka"><a class="link" href="#proc-configuring-tls-sidecar-deployment-configuration-kafka">Configuring TLS sidecar</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>tlsSidecar</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka"><a class="link" href="#assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</a></h4>
<div id="con-scheduling-deployment-configuration-kafka" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-scheduling-based-on-pods"><a class="link" href="#assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-scheduling-based-on-pods">Scheduling pods based on other applications</a></h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-scheduling-based-on-pods"><a class="link" href="#con-scheduling-based-on-other-pods-deployment-configuration-kafka-scheduling-based-on-pods">Avoid critical applications to share the node</a></h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-scheduling-based-on-pods"><a class="link" href="#affinity-deployment-configuration-kafka-scheduling-based-on-pods">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-scheduling-based-on-pods"><a class="link" href="#configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-node-scheduling"><a class="link" href="#assembly-node-scheduling-deployment-configuration-kafka-node-scheduling">Scheduling pods to specific nodes</a></h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-node-scheduling"><a class="link" href="#con-scheduling-to-specific-nodes-deployment-configuration-kafka-node-scheduling">Node scheduling</a></h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-node-scheduling"><a class="link" href="#affinity-deployment-configuration-kafka-node-scheduling">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-node-scheduling"><a class="link" href="#proc-configuring-node-affinity-deployment-configuration-kafka-node-scheduling">Configuring node affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-dedicated-nodes"><a class="link" href="#assembly-dedidcated-nodes-deployment-configuration-kafka-dedicated-nodes">Using dedicated nodes</a></h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes"><a class="link" href="#con-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Dedicated nodes</a></h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-dedicated-nodes"><a class="link" href="#affinity-deployment-configuration-kafka-dedicated-nodes">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-dedicated-nodes"><a class="link" href="#tolerations-deployment-configuration-kafka-dedicated-nodes">Tolerations</a></h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes"><a class="link" href="#proc-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-rolling-update-kafka-deployment-configuration-kafka"><a class="link" href="#proc-manual-rolling-update-kafka-deployment-configuration-kafka">3.1.18. Performing a rolling update of a Kafka cluster</a></h4>
<div class="paragraph">
<p>This procedure describes how to manually trigger a rolling update of an existing Kafka cluster by using an OpenShift or Kubernetes annotation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>StatefulSet</code> that controls the Kafka pods you want to manually update.</p>
<div class="paragraph">
<p>For example, if your Kafka cluster is named <em>my-cluster</em>, the corresponding <code>StatefulSet</code> is named <em>my-cluster-kafka</em>.</p>
</div>
</li>
<li>
<p>Annotate a <code>StatefulSet</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate statefulset <em>cluster-name</em>-kafka strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate statefulset <em>cluster-name</em>-kafka strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation to occur (every two minutes by default).
A rolling update of all pods within the annotated <code>StatefulSet</code> is triggered, as long as the annotation was detected by the reconciliation process.
Once the rolling update of all the pods is complete, the annotation is removed from the <code>StatefulSet</code>.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster on OpenShift, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster on Kubernetes, see <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-rolling-update-zookeeper-deployment-configuration-kafka"><a class="link" href="#proc-manual-rolling-update-zookeeper-deployment-configuration-kafka">3.1.19. Performing a rolling update of a Zookeeper cluster</a></h4>
<div class="paragraph">
<p>This procedure describes how to manually trigger a rolling update of an existing Zookeeper cluster by using an OpenShift or Kubernetes annotation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Zookeeper cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>StatefulSet</code> that controls the Zookeeper pods you want to manually update.</p>
<div class="paragraph">
<p>For example, if your Kafka cluster is named <em>my-cluster</em>, the corresponding <code>StatefulSet</code> is named <em>my-cluster-zookeeper</em>.</p>
</div>
</li>
<li>
<p>Annotate a <code>StatefulSet</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate statefulset <em>cluster-name</em>-zookeeper strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate statefulset <em>cluster-name</em>-zookeeper strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation to occur (every two minutes by default).
A rolling update of all pods within the annotated <code>StatefulSet</code> is triggered, as long as the annotation was detected by the reconciliation process.
Once the rolling update of all the pods is complete, the annotation is removed from the <code>StatefulSet</code>.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Zookeeper cluster, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="scaling-clusters-deployment-configuration-kafka"><a class="link" href="#scaling-clusters-deployment-configuration-kafka">3.1.20. Scaling clusters</a></h4>
<div class="sect4">
<h5 id="con-scaling-kafka-clusters-deployment-configuration-kafka"><a class="link" href="#con-scaling-kafka-clusters-deployment-configuration-kafka">Scaling Kafka clusters</a></h5>
<div class="sect5">
<h6 id="adding_brokers_to_a_cluster"><a class="link" href="#adding_brokers_to_a_cluster">Adding brokers to a cluster</a></h6>
<div class="paragraph">
<p>The primary way of increasing throughput for a topic is to increase the number of partitions for that topic.
That works because the extra partitions allow the load of the topic to be shared between the different brokers in the cluster.
However, in situations where every broker is constrained by a particular resource (typically I/O) using more partitions will not result in increased throughput.
Instead, you need to add brokers to the cluster.</p>
</div>
<div class="paragraph">
<p>When you add an extra broker to the cluster, Kafka does not assign any partitions to it automatically.
You must decide which partitions to move from the existing brokers to the new broker.</p>
</div>
<div class="paragraph">
<p>Once the partitions have been redistributed between all the brokers, the resource utilization of each broker should be reduced.</p>
</div>
</div>
<div class="sect5">
<h6 id="removing_brokers_from_a_cluster"><a class="link" href="#removing_brokers_from_a_cluster">Removing brokers from a cluster</a></h6>
<div class="paragraph">
<p>Because Strimzi uses <code>StatefulSets</code> to manage broker pods, you cannot remove <em>any</em> pod from the cluster.
You can only remove one or more of the highest numbered pods from the cluster.
For example, in a cluster of 12 brokers the pods are named <code><em>cluster-name</em>-kafka-0</code> up to <code><em>cluster-name</em>-kafka-11</code>.
If you decide to scale down by one broker, the <code><em>cluster-name</em>-kafka-11</code> will be removed.</p>
</div>
<div class="paragraph">
<p>Before you remove a broker from a cluster, ensure that it is not assigned to any partitions.
You should also decide which of the remaining brokers will be responsible for each of the partitions on the broker being decommissioned.
Once the broker has no assigned partitions, you can scale the cluster down safely.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-partition-reassignment-deployment-configuration-kafka"><a class="link" href="#con-partition-reassignment-deployment-configuration-kafka">Partition reassignment</a></h5>
<div class="paragraph">
<p>The Topic Operator does not currently support reassigning replicas to different brokers, so it is necessary to connect directly to broker pods to reassign replicas to brokers.</p>
</div>
<div class="paragraph">
<p>Within a broker pod, the <code>kafka-reassign-partitions.sh</code> utility allows you to reassign partitions to different brokers.</p>
</div>
<div class="paragraph">
<p>It has three different modes:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>--generate</code></dt>
<dd>
<p>Takes a set of topics and brokers and generates a <em>reassignment JSON file</em> which will result in the partitions of those topics being assigned to those brokers.
Because this operates on whole topics, it cannot be used when you just need to reassign some of the partitions of some topics.</p>
</dd>
<dt class="hdlist1"><code>--execute</code></dt>
<dd>
<p>Takes a <em>reassignment JSON file</em> and applies it to the partitions and brokers in the cluster.
Brokers that gain partitions as a result become followers of the partition leader.
For a given partition, once the new broker has caught up and joined the ISR (in-sync replicas) the old broker will stop being a follower and will delete its replica.</p>
</dd>
<dt class="hdlist1"><code>--verify</code></dt>
<dd>
<p>Using the same <em>reassignment JSON file</em> as the <code>--execute</code> step, <code>--verify</code> checks whether all of the partitions in the file have been moved to their intended brokers.
If the reassignment is complete, --verify also removes any <a href="#con-reassignment-throttles-deployment-configuration-kafka">throttles</a> that are in effect.
Unless removed, throttles will continue to affect the cluster even after the reassignment has finished.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>It is only possible to have one reassignment running in a cluster at any given time, and it is not possible to cancel a running reassignment.
If you need to cancel a reassignment, wait for it to complete and then perform another reassignment to revert the effects of the first reassignment.
The <code>kafka-reassign-partitions.sh</code> will print the reassignment JSON for this reversion as part of its output.
Very large reassignments should be broken down into a number of smaller reassignments in case there is a need to stop in-progress reassignment.</p>
</div>
<div class="sect5">
<h6 id="reassignment_json_file"><a class="link" href="#reassignment_json_file">Reassignment JSON file</a></h6>
<div class="paragraph">
<p>The <em>reassignment JSON file</em> has a specific structure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>{
  "version": 1,
  "partitions": [
    <em>&lt;PartitionObjects&gt;</em>
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Where <em>&lt;PartitionObjects&gt;</em> is a comma-separated list of objects like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>{
  "topic": <em>&lt;TopicName&gt;</em>,
  "partition": <em>&lt;Partition&gt;</em>,
  "replicas": [ <em>&lt;AssignedBrokerIds&gt;</em> ]
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Although Kafka also supports a <code>"log_dirs"</code> property this should not be used in Strimzi.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The following is an example reassignment JSON file that assigns topic <code>topic-a</code>, partition <code>4</code> to brokers <code>2</code>, <code>4</code> and <code>7</code>, and topic <code>topic-b</code> partition <code>2</code> to brokers <code>1</code>, <code>5</code> and <code>7</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
  "version": 1,
  "partitions": [
    {
      "topic": "topic-a",
      "partition": 4,
      "replicas": [2,4,7]
    },
    {
      "topic": "topic-b",
      "partition": 2,
      "replicas": [1,5,7]
    }
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Partitions not included in the JSON are not changed.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-generating-reassignment-json-files-deployment-configuration-kafka"><a class="link" href="#proc-generating-reassignment-json-files-deployment-configuration-kafka">Generating reassignment JSON files</a></h5>
<div class="paragraph">
<p>This procedure describes how to generate a reassignment JSON file that reassigns all the partitions for a given set of topics using the <code>kafka-reassign-partitions.sh</code> tool.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource</p>
</li>
<li>
<p>A set of topics to reassign the partitions of</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a JSON file named <code><em>topics.json</em></code> that lists the topics to move.
It must have the following structure:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>{
  "version": 1,
  "topics": [
    <em>&lt;TopicObjects&gt;</em>
  ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <em>&lt;TopicObjects&gt;</em> is a comma-separated list of objects like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>{
  "topic": <em>&lt;TopicName&gt;</em>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example if you want to reassign all the partitions of <code>topic-a</code> and <code>topic-b</code>, you would need to prepare a <code><em>topics.json</em></code> file like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
  "version": 1,
  "topics": [
    { "topic": "topic-a"},
    { "topic": "topic-b"}
  ]
}</code></pre>
</div>
</div>
</li>
<li>
<p>Copy the <code><em>topics.json</em></code> file to one of the broker pods:</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>cat <em>topics.json</em> | kubectl exec -c kafka <em>&lt;BrokerPod&gt;</em> -i -- \
  /bin/bash -c \
  'cat &gt; /tmp/topics.json'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>cat <em>topics.json</em> | oc rsh -c kafka <em>&lt;BrokerPod&gt;</em> /bin/bash -c \
  'cat &gt; /tmp/topics.json'</code></pre>
</div>
</div>
</li>
<li>
<p>Use the <code>kafka-reassign-partitions.sh`</code> command to generate the reassignment JSON.</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl exec <em>&lt;BrokerPod&gt;</em> -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --topics-to-move-json-file /tmp/topics.json \
  --broker-list <em>&lt;BrokerList&gt;</em> \
  --generate</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc rsh -c kafka <em>&lt;BrokerPod&gt;</em> \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --topics-to-move-json-file /tmp/topics.json \
  --broker-list <em>&lt;BrokerList&gt;</em> \
  --generate</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, to move all the partitions of <code>topic-a</code> and <code>topic-b</code> to brokers <code>4</code> and <code>7</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka _&lt;BrokerPod&gt;_ \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --topics-to-move-json-file /tmp/topics.json \
  --broker-list 4,7 \
  --generate</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="creating_reassignment_json_files_manually"><a class="link" href="#creating_reassignment_json_files_manually">Creating reassignment JSON files manually</a></h5>
<div class="paragraph">
<p>You can manually create the reassignment JSON file if you want to move specific partitions.</p>
</div>
</div>
<div class="sect4">
<h5 id="con-reassignment-throttles-deployment-configuration-kafka"><a class="link" href="#con-reassignment-throttles-deployment-configuration-kafka">Reassignment throttles</a></h5>
<div class="paragraph">
<p>Partition reassignment can be a slow process because it involves transferring large amounts of data between brokers.
To avoid a detrimental impact on clients, you can throttle the reassignment process.
This might cause the reassignment to take longer to complete.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If the throttle is too low then the newly assigned brokers will not be able to keep up with records being published and the reassignment will never complete.</p>
</li>
<li>
<p>If the throttle is too high then clients will be impacted.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, for producers, this could manifest as higher than normal latency waiting for acknowledgement. For consumers, this could manifest as a drop in throughput caused by higher latency between polls.</p>
</div>
</div>
<div class="sect4">
<h5 id="proc-scaling-up-a-kafka-cluster-deployment-configuration-kafka"><a class="link" href="#proc-scaling-up-a-kafka-cluster-deployment-configuration-kafka">Scaling up a Kafka cluster</a></h5>
<div class="paragraph">
<p>This procedure describes how to increase the number of brokers in a Kafka cluster.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster.</p>
</li>
<li>
<p>A <em>reassignment JSON file</em> named <code><em>reassignment.json</em></code> that describes how partitions should be reassigned to brokers in the enlarged cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add as many new brokers as you need by increasing the <code>Kafka.spec.kafka.replicas</code> configuration option.</p>
</li>
<li>
<p>Verify that the new broker pods have started.</p>
</li>
<li>
<p>Copy the <code><em>reassignment.json</em></code> file to the broker pod on which you will later execute the commands:</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat <em>reassignment.json</em> | \
  kubectl exec <em>broker-pod</em> -c kafka -i -- /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat <em>reassignment.json</em> | \
  oc rsh -c kafka <em>broker-pod</em> /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat reassignment.json | \
  oc rsh -c kafka my-cluster-kafka-0 /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
</li>
<li>
<p>Execute the partition reassignment using the <code>kafka-reassign-partitions.sh</code> command line tool from the same broker pod.</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec <em>broker-pod</em> -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka <em>broker-pod</em> \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you are going to throttle replication you can also pass the <code>--throttle</code> option with an inter-broker throttled rate in bytes per second. For example:</p>
</div>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 5000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 5000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will print out two reassignment JSON objects.
The first records the current assignment for the partitions being moved.
You should save this to a local file (not a file in the pod) in case you need to revert the reassignment later on.
The second JSON object is the target reassignment you have passed in your reassignment JSON file.</p>
</div>
</li>
<li>
<p>If you need to change the throttle during reassignment you can use the same command line with a different throttled rate. For example:</p>
<div class="paragraph">
<p>On Kubernetes,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 10000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 10000000 \
  --execute</code></pre>
</div>
</div>
</li>
<li>
<p>Periodically verify whether the reassignment has completed using the <code>kafka-reassign-partitions.sh</code> command line tool from any of the broker pods. This is the same command as the previous step but with the <code>--verify</code> option instead of the <code>--execute</code> option.</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec <em>broker-pod</em> -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka <em>broker-pod</em> \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, on Kubernetes,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, on {OpenShift},</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
</li>
<li>
<p>The reassignment has finished when the <code>--verify</code> command reports each of  the partitions being moved as completed successfully.
This final <code>--verify</code> will also have the effect of removing any reassignment throttles.
You can now delete the revert file if you saved the JSON for reverting the assignment to their original brokers.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-scaling-down-a-kafka-cluster-deployment-configuration-kafka"><a class="link" href="#proc-scaling-down-a-kafka-cluster-deployment-configuration-kafka">Scaling down a Kafka cluster</a></h5>
<div class="paragraph">
<div class="title">Additional resources</div>
<p>This procedure describes how to decrease the number of brokers in a Kafka cluster.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster.</p>
</li>
<li>
<p>A <em>reassignment JSON file</em> named <code><em>reassignment.json</em></code> describing how partitions should be reassigned to brokers in the cluster once the broker(s) in the highest numbered <code>Pod(s)</code> have been removed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Copy the <code><em>reassignment.json</em></code> file to the broker pod on which you will later execute the commands:</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat <em>reassignment.json</em> | \
  kubectl exec <em>broker-pod</em> -c kafka -i -- /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat <em>reassignment.json</em> | \
  oc rsh -c kafka <em>broker-pod</em> /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cat reassignment.json | \
  oc rsh -c kafka my-cluster-kafka-0 /bin/bash -c \
  'cat &gt; /tmp/reassignment.json'</code></pre>
</div>
</div>
</li>
<li>
<p>Execute the partition reassignment using the <code>kafka-reassign-partitions.sh</code> command line tool from the same broker pod.</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec <em>broker-pod</em> -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka <em>broker-pod</em> \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you are going to throttle replication you can also pass the <code>--throttle</code> option with an inter-broker throttled rate in bytes per second. For example:</p>
</div>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 5000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 5000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will print out two reassignment JSON objects.
The first records the current assignment for the partitions being moved.
You should save this to a local file (not a file in the pod) in case you need to revert the reassignment later on.
The second JSON object is the target reassignment you have passed in your reassignment JSON file.</p>
</div>
</li>
<li>
<p>If you need to change the throttle during reassignment you can use the same command line with a different throttled rate. For example:</p>
<div class="paragraph">
<p>On Kubernetes,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 10000000 \
  --execute</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --throttle 10000000 \
  --execute</code></pre>
</div>
</div>
</li>
<li>
<p>Periodically verify whether the reassignment has completed using the <code>kafka-reassign-partitions.sh</code> command line tool from any of the broker pods. This is the same command as the previous step but with the <code>--verify</code> option instead of the <code>--execute</code> option.</p>
<div class="paragraph">
<p>On Kubernetes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec <em>broker-pod</em> -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka <em>broker-pod</em> \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, on Kubernetes,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl exec my-cluster-kafka-0 -c kafka -it -- \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, on {OpenShift},</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh -c kafka my-cluster-kafka-0 \
  bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 \
  --reassignment-json-file /tmp/reassignment.json \
  --verify</code></pre>
</div>
</div>
</li>
<li>
<p>The reassignment has finished when the <code>--verify</code> command reports each of  the partitions being moved as completed successfully.
This final <code>--verify</code> will also have the effect of removing any reassignment throttles.
You can now delete the revert file if you saved the JSON for reverting the assignment to their original brokers.</p>
</li>
<li>
<p>Once all the partition reassignments have finished, the broker(s) being removed should not have responsibility for any of the partitions in the cluster.
You can verify this by checking that the broker&#8217;s data log directory does not contain any live partition logs.
If the log directory on the broker contains a directory that does not match the extended regular expression <code>[a-zA-Z0-9.-]+\.[a-z0-9]+-delete$</code> then the broker still has live partitions and it should not be stopped.</p>
<div class="paragraph">
<p>You can check this by executing the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc rsh <em>&lt;BrokerN&gt;</em> -c kafka /bin/bash -c \
  "ls -l /var/lib/kafka/kafka-log_&lt;N&gt;_ | grep -E '^d' | grep -vE '[a-zA-Z0-9.-]+\.[a-z0-9]+-delete$'"</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <em>N</em> is the number of the <code>Pod(s)</code> being deleted.</p>
</div>
<div class="paragraph">
<p>If the above command prints any output then the broker still has live partitions.
In this case, either the reassignment has not finished, or the reassignment JSON file was incorrect.</p>
</div>
</li>
<li>
<p>Once you have confirmed that the broker has no live partitions you can edit the <code>Kafka.spec.kafka.replicas</code> of your <code>Kafka</code> resource, which will scale down the <code>StatefulSet</code>, deleting the highest numbered broker <code>Pod(s)</code>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-delete-pod-pvc-kafka-deployment-configuration-kafka"><a class="link" href="#proc-manual-delete-pod-pvc-kafka-deployment-configuration-kafka">3.1.21. Deleting Kafka nodes manually</a></h4>
<div class="paragraph">
<div class="title">Additional resources</div>
<p>This procedure describes how to delete an existing Kafka node by using an OpenShift or Kubernetes annotation.
Deleting a Kafka node consists of deleting both the <code>Pod</code> on which the Kafka broker is running and the related <code>PersistentVolumeClaim</code> (if the cluster was deployed with persistent storage).
After deletion, the <code>Pod</code> and its related <code>PersistentVolumeClaim</code> are recreated automatically.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Deleting a <code>PersistentVolumeClaim</code> can cause permanent data loss. The following procedure should only be performed if you have encountered storage issues.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>Pod</code> that you want to delete.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, if the cluster is named <em>cluster-name</em>, the pods are named <em>cluster-name</em>-kafka-<em>index</em>, where <em>index</em> starts at zero and ends at the total number of replicas.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Annotate the <code>Pod</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate pod <em>cluster-name</em>-kafka-<em>index</em> strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate pod <em>cluster-name</em>-kafka-<em>index</em> strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation, when the annotated pod with the underlying persistent volume claim will be deleted and then recreated.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster on OpenShift, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster on Kubernetes, see <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-delete-pod-pvc-zookeeper-deployment-configuration-kafka"><a class="link" href="#proc-manual-delete-pod-pvc-zookeeper-deployment-configuration-kafka">3.1.22. Deleting Zookeeper nodes manually</a></h4>
<div class="paragraph">
<p>This procedure describes how to delete an existing Zookeeper node by using an OpenShift or Kubernetes annotation.
Deleting a Zookeeper node consists of deleting both the <code>Pod</code> on which Zookeeper is running and the related <code>PersistentVolumeClaim</code> (if the cluster was deployed with persistent storage).
After deletion, the <code>Pod</code> and its related <code>PersistentVolumeClaim</code> are recreated automatically.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Deleting a <code>PersistentVolumeClaim</code> can cause permanent data loss. The following procedure should only be performed if you have encountered storage issues.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Zookeeper cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>Pod</code> that you want to delete.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, if the cluster is named <em>cluster-name</em>, the pods are named <em>cluster-name</em>-zookeeper-<em>index</em>, where <em>index</em> starts at zero and ends at the total number of replicas.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Annotate the <code>Pod</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate pod <em>cluster-name</em>-zookeeper-<em>index</em> strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate pod <em>cluster-name</em>-zookeeper-<em>index</em> strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation, when the annotated pod with the underlying persistent volume claim will be deleted and then recreated.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Zookeeper cluster on OpenShift, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a>.</p>
</li>
<li>
<p>For more information about deploying the Zookeeper cluster on Kubernetes, see <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="assembly-maintenance-time-windows-deployment-configuration-kafka"><a class="link" href="#assembly-maintenance-time-windows-deployment-configuration-kafka">3.1.23. Maintenance time windows for rolling updates</a></h4>
<div class="paragraph">
<p>Maintenance time windows allow you to schedule certain rolling updates of your Kafka and Zookeeper clusters to start at a convenient time.</p>
</div>
<div class="sect4">
<h5 id="con-maintenance-time-windows-overview-deployment-configuration-kafka"><a class="link" href="#con-maintenance-time-windows-overview-deployment-configuration-kafka">Maintenance time windows overview</a></h5>
<div class="paragraph">
<p>In most cases, the Cluster Operator only updates your Kafka or Zookeeper clusters in response to changes to the corresponding <code>Kafka</code> resource.
This enables you to plan when to apply changes to a <code>Kafka</code> resource to minimize the impact on Kafka client applications.</p>
</div>
<div class="paragraph">
<p>However, some updates to your Kafka and Zookeeper clusters can happen without any corresponding change to the <code>Kafka</code> resource.
For example, the Cluster Operator will need to perform a rolling restart if a CA (Certificate Authority) certificate that it manages is close to expiry.</p>
</div>
<div class="paragraph">
<p>While a rolling restart of the pods should not affect <em>availability</em> of the service (assuming correct broker and topic configurations), it could affect <em>performance</em> of the Kafka client applications.
Maintenance time windows allow you to schedule such spontaneous rolling updates of your Kafka and Zookeeper clusters to start at a convenient time.
If maintenance time windows are not configured for a cluster then it is possible that such spontaneous rolling updates will happen at an inconvenient time, such as during a predictable period of high load.</p>
</div>
</div>
<div class="sect4">
<h5 id="con-maintenance-time-window-definition-deployment-configuration-kafka"><a class="link" href="#con-maintenance-time-window-definition-deployment-configuration-kafka">Maintenance time window definition</a></h5>
<div class="paragraph">
<p>You configure maintenance time windows by entering an array of strings in the <code>Kafka.spec.maintenanceTimeWindows</code> property.
Each string is a <a href="http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/tutorial-lesson-06.html" target="_blank" rel="noopener">cron expression</a> interpreted as being in UTC (Coordinated Universal Time, which for practical purposes is the same as Greenwich Mean Time).</p>
</div>
<div class="paragraph">
<p>The following example configures a single maintenance time window that starts at midnight and ends at 01:59am (UTC), on Sundays, Mondays, Tuesdays, Wednesdays, and Thursdays:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
maintenanceTimeWindows:
  - "* * 0-1 ? * SUN,MON,TUE,WED,THU *"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In practice, maintenance windows should be set in conjunction with the <code>Kafka.spec.clusterCa.renewalDays</code> and <code>Kafka.spec.clientsCa.renewalDays</code> properties of the <code>Kafka</code> resource, to ensure that the necessary CA certificate renewal can be completed in the configured maintenance time windows.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Strimzi does not schedule maintenance operations exactly according to the given windows. Instead, for each reconciliation, it checks whether a maintenance window is currently "open".
This means that the start of maintenance operations within a given time window can be delayed by up to the Cluster Operator reconciliation interval.
Maintenance time windows must therefore be at least this long.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the Cluster Operator configuration, see <a href="#ref-operators-cluster-operator-configuration-deploying-co">Cluster Operator Configuration</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-maintenance-time-windows-deployment-configuration-kafka"><a class="link" href="#proc-configuring-maintenance-time-windows-deployment-configuration-kafka">Configuring a maintenance time window</a></h5>
<div class="paragraph">
<p>You can configure a maintenance time window for rolling updates triggered by supported processes.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>The Cluster Operator is running.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add or edit the <code>maintenanceTimeWindows</code> property in the <code>Kafka</code> resource.
For example to allow maintenance between 0800 and 1059 and between 1400 and 1559 you would set the <code>maintenanceTimeWindows</code> as shown below:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  maintenanceTimeWindows:
    - "* * 8-10 * * ?"
    - "* * 14-15 * * ?"</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>Performing a rolling update of a Kafka cluster, see <a href="#proc-manual-rolling-update-kafka-deployment-configuration-kafka">Performing a rolling update of a Kafka cluster</a></p>
</li>
<li>
<p>Performing a rolling update of a Zookeeper cluster, see <a href="#proc-manual-rolling-update-zookeeper-deployment-configuration-kafka">Performing a rolling update of a Zookeeper cluster</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-cluster-resources-deployment-configuration-kafka"><a class="link" href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.24. List of resources created as part of Kafka cluster</a></h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-brokers</code></dt>
<dd>
<p>Service needed to have DNS resolve the Kafka broker pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-bootstrap</code></dt>
<dd>
<p>Service can be used as bootstrap servers for Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap service for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-<em>pod-id</em></code></dt>
<dd>
<p>Service used to route traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap route for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-<em>pod-id</em></code></dt>
<dd>
<p>Route for traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-config</code></dt>
<dd>
<p>ConfigMap which contains the Kafka ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-brokers</code></dt>
<dd>
<p>Secret with Kafka broker keys.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka</code></dt>
<dd>
<p>Service account used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka</code></dt>
<dd>
<p>Pod Disruption Budget configured for the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>namespace-name</em>-<em>cluster-name</em>-kafka-init</code></dt>
<dd>
<p>Cluster role binding used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-nodes</code></dt>
<dd>
<p>Service needed to have DNS resolve the Zookeeper pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-client</code></dt>
<dd>
<p>Service used by Kafka brokers to connect to Zookeeper nodes as clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-config</code></dt>
<dd>
<p>ConfigMap which contains the Zookeeper ancillary configuration and is mounted as a volume by the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-nodes</code></dt>
<dd>
<p>Secret with Zookeeper node keys.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper</code></dt>
<dd>
<p>Pod Disruption Budget configured for the Zookeeper nodes.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator</code></dt>
<dd>
<p>Deployment with Topic and User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-topic-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for Topic Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-user-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator-certs</code></dt>
<dd>
<p>Secret with Entitiy operators keys for communication with Kafka and Zookeeper. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator</code></dt>
<dd>
<p>Service account used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>cluster-name</em>-topic-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>cluster-name</em>-user-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-cluster-ca</code></dt>
<dd>
<p>Secret with the Cluster CA used to encrypt the cluster communication.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-cluster-ca-cert</code></dt>
<dd>
<p>Secret with the Cluster CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-clients-ca</code></dt>
<dd>
<p>Secret with the Clients CA used to encrypt the communication between Kafka brokers and Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-clients-ca-cert</code></dt>
<dd>
<p>Secret with the Clients CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-cluster-operator-certs</code></dt>
<dd>
<p>Secret with Cluster operators keys for communication with Kafka and Zookeeper.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code><em>idx</em></code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
<dt class="hdlist1"><code>data-<em>id</em>-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume <code><em>id</em></code> used for storing data for the Kafka broker pod <code><em>idx</em></code>. This resource is only created if persistent storage is selected for JBOD volumes when provisioning persistent volumes to store data.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-zookeeper-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code><em>idx</em></code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-str"><a class="link" href="#assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</a></h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnect</code> resource is described in the <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnect</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</a></h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect">Configuring the number of nodes</a></h5>
<div class="paragraph">
<p>Number of Kafka Connect nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</a></h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>cluster-name</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code><em>hostname</em>:_port_</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">Configuring bootstrap servers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</a></h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect"><a class="link" href="#ref-kafka-connect-tls-deployment-configuration-kafka-connect">TLS support in Kafka Connect</a></h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect">Configuring TLS in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</a></h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect"><a class="link" href="#con-kafka-connect-authenticationdeployment-configuration-kafka-connect">Authentication support in Kafka Connect</a></h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_2"><a class="link" href="#tls_client_authentication_2">TLS Client Authentication</a></h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication"><a class="link" href="#scram_sha_512_authentication">SCRAM-SHA-512 authentication</a></h6>
<div class="paragraph">
<p>To configure Kafka Connect to use SCRAM-SHA-512 authentication, set the <code>type</code> property to <code>scram-sha-512</code>.
This authentication mechanism requires a username and password.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Specify the username in the <code>username</code> property.</p>
</li>
<li>
<p>In the <code>passwordSecret</code> property, specify a link to a <code>Secret</code> containing the password. The <code>secretName</code> property contains the name of such a <code>Secret</code> and the <code>password</code> property contains the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Do not specify the actual password in the <code>password</code> field.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: my-connect-password-key
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect">Configuring TLS client authentication in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect">Configuring SCRAM-SHA-512 authentication in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password&gt;.txt</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _&lt;my-username&gt;_
    passwordSecret:
      secretName: _&lt;my-secret&gt;_
      password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect"><a class="link" href="#ref-kafka-connect-configuration-deployment-configuration-kafka-connect">Kafka Connect configuration</a></h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-kafka-connect-deployment-configuration-kafka-connect">Configuring Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect"><a class="link" href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</a></h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect"><a class="link" href="#ref-resource-limits-and-requests-deployment-configuration-kafka-connect">Resource limits and requests</a></h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_2"><a class="link" href="#resource_requests_2">Resource requests</a></h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_2"><a class="link" href="#resource_limits_2">Resource limits</a></h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_2"><a class="link" href="#supported_cpu_formats_2">Supported CPU formats</a></h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_2"><a class="link" href="#supported_memory_formats_2">Supported memory formats</a></h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_2"><a class="link" href="#additional_resources_2">Additional resources</a></h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect">Configuring resource requests and limits</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect"><a class="link" href="#assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</a></h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect"><a class="link" href="#kafka-inline-logging-deployment-configuration-kafka-connect">Using inline logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect"><a class="link" href="#kafka-external-logging-deployment-configuration-kafka-connect">Using external ConfigMap for logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect"><a class="link" href="#kafka-logging-loggers-deployment-configuration-kafka-connect">Loggers</a></h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect"><a class="link" href="#assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</a></h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect"><a class="link" href="#ref-healthchecks-deployment-configuration-kafka-connect">Healthcheck configurations</a></h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-healthchecks-deployment-configuration-kafka-connect">Configuring healthchecks</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect"><a class="link" href="#assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</a></h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect"><a class="link" href="#ref-metrics-deployment-configuration-kafka-connect">Metrics configuration</a></h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-metrics-deployment-configuration-kafka-connect">Configuring Prometheus metrics</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect"><a class="link" href="#assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</a></h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect"><a class="link" href="#ref-jvm-options-deployment-configuration-kafka-connect">JVM configuration</a></h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4  the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5  the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-jvm-options-deployment-configuration-kafka-connect">Configuring JVM options</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect"><a class="link" href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</a></h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect"><a class="link" href="#ref-configuring-container-images-deployment-configuration-kafka-connect">Container image configurations</a></h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="configuring_the_kafka_spec_kafka_image_property_2"><a class="link" href="#configuring_the_kafka_spec_kafka_image_property_2">Configuring the <code>Kafka.spec.kafka.image</code> property</a></h6>
<div class="paragraph">
<p>The <code>Kafka.spec.kafka.image</code> property functions differently from the others, because Strimzi supports multiple versions of Kafka, each requiring the own image.
The <code>STRIMZI_KAFKA_IMAGES</code> environment variable of the Cluster Operator configuration is used to provide a mapping between Kafka versions and the corresponding images.
This is used in combination with the <code>Kafka.spec.kafka.image</code> and <code>Kafka.spec.kafka.version</code> properties as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If neither <code>Kafka.spec.kafka.image</code> nor <code>Kafka.spec.kafka.version</code> are given in the custom resource then the <code>version</code> will default to the  Cluster Operator&#8217;s default Kafka version, and the image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.image</code> is given but <code>Kafka.spec.kafka.version</code> is not then the given image will be used and the <code>version</code> will be assumed to be the  Cluster Operator&#8217;s default Kafka version.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.version</code> is given but <code>Kafka.spec.kafka.image</code> is not then image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>Both <code>Kafka.spec.kafka.version</code> and <code>Kafka.spec.kafka.image</code> are given the given image will be used, and it will be assumed to contain a Kafka broker with the given version.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
It is best to provide just <code>Kafka.spec.kafka.version</code> and leave the <code>Kafka.spec.kafka.image</code> property unspecified.
This reduces the chances of making a mistake in configuring the <code>Kafka</code> resource. If you need to change the images used for different versions of Kafka, it is better to configure the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> environment variable.
</td>
</tr>
</table>
</div>
</div>
<div class="sect5">
<h6 id="configuring_the_image_property_in_other_resources_2"><a class="link" href="#configuring_the_image_property_in_other_resources_2">Configuring the <code>image</code> property in other resources</a></h6>
<div class="paragraph">
<p>For the <code>image</code> property in the other custom resources, the given value will be used during deployment.
If the <code>image</code> property is missing, the <code>image</code> specified in the Cluster Operator configuration will be used.
If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect"><a class="link" href="#proc-configuring-container-images-deployment-configuration-kafka-connect">Configuring container images</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect"><a class="link" href="#assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</a></h4>
<div id="con-scheduling-deployment-configuration-kafka-connect" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-scheduling-based-on-pods"><a class="link" href="#assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-scheduling-based-on-pods">Scheduling pods based on other applications</a></h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-scheduling-based-on-pods"><a class="link" href="#con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-scheduling-based-on-pods">Avoid critical applications to share the node</a></h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-scheduling-based-on-pods"><a class="link" href="#affinity-deployment-configuration-kafka-connect-scheduling-based-on-pods">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-scheduling-based-on-pods"><a class="link" href="#configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-node-scheduling"><a class="link" href="#assembly-node-scheduling-deployment-configuration-kafka-connect-node-scheduling">Scheduling pods to specific nodes</a></h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-node-scheduling"><a class="link" href="#con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-node-scheduling">Node scheduling</a></h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-node-scheduling"><a class="link" href="#affinity-deployment-configuration-kafka-connect-node-scheduling">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-node-scheduling"><a class="link" href="#proc-configuring-node-affinity-deployment-configuration-kafka-connect-node-scheduling">Configuring node affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-dedicated-nodes"><a class="link" href="#assembly-dedidcated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Using dedicated nodes</a></h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes"><a class="link" href="#con-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Dedicated nodes</a></h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-dedicated-nodes"><a class="link" href="#affinity-deployment-configuration-kafka-connect-dedicated-nodes">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-dedicated-nodes"><a class="link" href="#tolerations-deployment-configuration-kafka-connect-dedicated-nodes">Tolerations</a></h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes"><a class="link" href="#proc-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect"><a class="link" href="#assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect">3.2.13. Using external configuration and secrets</a></h4>
<div class="paragraph">
<p>Kafka Connect connectors are configured using an HTTP REST interface.
The connector configuration is passed to Kafka Connect as part of an HTTP request and stored within Kafka itself.</p>
</div>
<div class="paragraph">
<p>Some parts of the configuration of a Kafka Connect connector can be externalized using ConfigMaps or Secrets.
You can then reference the configuration values in HTTP REST commands (this keeps the configuration separate and more secure, if needed).
This method applies especially to confidential data, such as usernames, passwords, or certificates.</p>
</div>
<div class="paragraph">
<p>ConfigMaps and Secrets are standard OpenShift or Kubernetes resources used for storing of configurations and confidential data.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-external-configuration-deployment-configuration-kafka-connect"><a class="link" href="#con-kafka-connect-external-configuration-deployment-configuration-kafka-connect">Storing connector configurations externally</a></h5>
<div class="paragraph">
<p>You can mount ConfigMaps or Secrets into a Kafka Connect pod as volumes or environment variables.
Volumes and environment variables are configured in the <code>externalConfiguration</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="sect5">
<h6 id="external_configuration_as_environment_variables"><a class="link" href="#external_configuration_as_environment_variables">External configuration as environment variables</a></h6>
<div class="paragraph">
<p>The <code>env</code> property is used to specify one or more environment variables.
These variables can contain a value from either a ConfigMap or a Secret.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The names of user-defined environment variables cannot start with <code>KAFKA_</code> or <code>STRIMZI_</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To mount a value from a Secret to an environment variable, use the <code>valueFrom</code> property and the <code>secretKeyRef</code> as shown in the following example.</p>
</div>
<div class="listingblock">
<div class="title">Example of an environment variable set to a value from a Secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: MY_ENVIRONMENT_VARIABLE
        valueFrom:
          secretKeyRef:
            name: my-secret
            key: my-key</code></pre>
</div>
</div>
<div class="paragraph">
<p>A common use case for mounting Secrets to environment variables is when your connector needs to communicate with Amazon AWS and needs to read the <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> environment variables with credentials.</p>
</div>
<div class="paragraph">
<p>To mount a value from a ConfigMap to an environment variable, use <code>configMapKeyRef</code> in the <code>valueFrom</code> property as shown in the following example.</p>
</div>
<div class="listingblock">
<div class="title">Example of an environment variable set to a value from a ConfigMap</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: MY_ENVIRONMENT_VARIABLE
        valueFrom:
          configMapKeyRef:
            name: my-config-map
            key: my-key</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="external_configuration_as_volumes"><a class="link" href="#external_configuration_as_volumes">External configuration as volumes</a></h6>
<div class="paragraph">
<p>You can also mount ConfigMaps or Secrets to a Kafka Connect pod as volumes.
Using volumes instead of environment variables is useful in the following scenarios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Mounting truststores or keystores with TLS certificates</p>
</li>
<li>
<p>Mounting a properties file that is used to configure Kafka Connect connectors</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the <code>volumes</code> property of the <code>externalConfiguration</code> resource, list the ConfigMaps or Secrets that will be mounted as volumes.
Each volume must specify a name in the <code>name</code> property and a reference to ConfigMap or Secret.</p>
</div>
<div class="listingblock">
<div class="title">Example of volumes with external configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    volumes:
      - name: connector1
        configMap:
          name: connector1-configuration
    - name: connector1-certificates
      secret:
        secretName: connector1-certificates</code></pre>
</div>
</div>
<div class="paragraph">
<p>The volumes will be mounted inside the Kafka Connect containers in the path <code>/opt/kafka/external-configuration/<em>&lt;volume-name&gt;</em></code>.
For example, the files from a volume named <code>connector1</code> would appear in the directory <code>/opt/kafka/external-configuration/connector1</code>.</p>
</div>
<div class="paragraph">
<p>The <code>FileConfigProvider</code> has to be used to read the values from the mounted properties files in connector configurations.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-connect-mounting-secrets-as-environment-variables-deployment-configuration-kafka-connect"><a class="link" href="#proc-kafka-connect-mounting-secrets-as-environment-variables-deployment-configuration-kafka-connect">Mounting Secrets as environment variables</a></h5>
<div class="paragraph">
<p>You can create an OpenShift or Kubernetes Secret and mount it to Kafka Connect as an environment variable.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a secret containing the information that will be mounted as an environment variable.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: aws-creds
type: Opaque
data:
  awsAccessKey: QUtJQVhYWFhYWFhYWFhYWFg=
  awsSecretAccessKey: Ylhsd1lYTnpkMjl5WkE=</code></pre>
</div>
</div>
</li>
<li>
<p>Create or edit the Kafka Connect resource.
Configure the <code>externalConfiguration</code> section of the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> custom resource to reference the secret.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: aws-creds
            key: awsAccessKey
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: aws-creds
            key: awsSecretAccessKey</code></pre>
</div>
</div>
</li>
<li>
<p>Apply the changes to your Kafka Connect deployment.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>The environment variables are now available for use when developing your connectors.</p>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about external configuration in Kafka Connect, see <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-connect-mounting-volumes-deployment-configuration-kafka-connect"><a class="link" href="#proc-kafka-connect-mounting-volumes-deployment-configuration-kafka-connect">Mounting Secrets as volumes</a></h5>
<div class="paragraph">
<p>You can create an OpenShift or Kubernetes Secret, mount it as a volume to Kafka Connect, and then use it to configure a Kafka Connect connector.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a secret containing a properties file that defines the configuration options for your connector configuration.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
stringData:
  connector.properties: |-
    dbUsername: my-user
    dbPassword: my-password</code></pre>
</div>
</div>
</li>
<li>
<p>Create or edit the Kafka Connect resource.
Configure the <code>FileConfigProvider</code> in the <code>config</code> section and the <code>externalConfiguration</code> section of the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> custom resource to reference the secret.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    config.providers: file
    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider
  #...
  externalConfiguration:
    volumes:
      - name: connector-config
        secret:
          secretName: mysecret</code></pre>
</div>
</div>
</li>
<li>
<p>Apply the changes to your Kafka Connect deployment.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the values from the mounted properties file in your JSON payload with connector configuration.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
   "name":"my-connector",
   "config":{
      "connector.class":"MyDbConnector",
      "tasks.max":"3",
      "database": "my-postgresql:5432"
      "username":"${file:/opt/kafka/external-configuration/connector-config/connector.properties:dbUsername}",
      "password":"${file:/opt/kafka/external-configuration/connector-config/connector.properties:dbPassword}",
      # ...
   }
}</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about external configuration in Kafka Connect, see <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-connect-resources-deployment-configuration-kafka-connect"><a class="link" href="#ref-list-of-kafka-connect-resources-deployment-configuration-kafka-connect">3.2.14. List of resources created as part of Kafka Connect cluster</a></h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>Deployment which is in charge to create the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>Pod Disruption Budget configured for the Kafka Connect worker nodes.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-s2i-str"><a class="link" href="#assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</a></h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnectS2I</code> resource is described in the <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnectS2I</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster with Source2Image support.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</a></h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">Configuring the number of nodes</a></h5>
<div class="paragraph">
<p>Number of Kafka Connect nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</a></h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>cluster-name</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code><em>hostname</em>:_port_</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">Configuring bootstrap servers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</a></h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">TLS support in Kafka Connect</a></h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</a></h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect-s2i"><a class="link" href="#con-kafka-connect-authenticationdeployment-configuration-kafka-connect-s2i">Authentication support in Kafka Connect</a></h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_3"><a class="link" href="#tls_client_authentication_3">TLS Client Authentication</a></h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication_2"><a class="link" href="#scram_sha_512_authentication_2">SCRAM-SHA-512 authentication</a></h6>
<div class="paragraph">
<p>To configure Kafka Connect to use SCRAM-SHA-512 authentication, set the <code>type</code> property to <code>scram-sha-512</code>.
This authentication mechanism requires a username and password.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Specify the username in the <code>username</code> property.</p>
</li>
<li>
<p>In the <code>passwordSecret</code> property, specify a link to a <code>Secret</code> containing the password. The <code>secretName</code> property contains the name of such a <code>Secret</code> and the <code>password</code> property contains the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Do not specify the actual password in the <code>password</code> field.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: my-connect-password-key
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS client authentication in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect-s2i">Configuring SCRAM-SHA-512 authentication in Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password&gt;.txt</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _&lt;my-username&gt;_
    passwordSecret:
      secretName: _&lt;my-secret&gt;_
      password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">Kafka Connect configuration</a></h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-kafka-connect-deployment-configuration-kafka-connect-s2i">Configuring Kafka Connect</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</a></h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Resource limits and requests</a></h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_3"><a class="link" href="#resource_requests_3">Resource requests</a></h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_3"><a class="link" href="#resource_limits_3">Resource limits</a></h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_3"><a class="link" href="#supported_cpu_formats_3">Supported CPU formats</a></h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_3"><a class="link" href="#supported_memory_formats_3">Supported memory formats</a></h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_3"><a class="link" href="#additional_resources_3">Additional resources</a></h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Configuring resource requests and limits</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</a></h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect-s2i"><a class="link" href="#kafka-inline-logging-deployment-configuration-kafka-connect-s2i">Using inline logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect-s2i"><a class="link" href="#kafka-external-logging-deployment-configuration-kafka-connect-s2i">Using external ConfigMap for logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect-s2i"><a class="link" href="#kafka-logging-loggers-deployment-configuration-kafka-connect-s2i">Loggers</a></h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</a></h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-healthchecks-deployment-configuration-kafka-connect-s2i">Healthcheck configurations</a></h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-healthchecks-deployment-configuration-kafka-connect-s2i">Configuring healthchecks</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</a></h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-metrics-deployment-configuration-kafka-connect-s2i">Metrics configuration</a></h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-metrics-deployment-configuration-kafka-connect-s2i">Configuring Prometheus metrics</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</a></h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-jvm-options-deployment-configuration-kafka-connect-s2i">JVM configuration</a></h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4  the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5  the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-jvm-options-deployment-configuration-kafka-connect-s2i">Configuring JVM options</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</a></h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-configuring-container-images-deployment-configuration-kafka-connect-s2i">Container image configurations</a></h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="configuring_the_kafka_spec_kafka_image_property_3"><a class="link" href="#configuring_the_kafka_spec_kafka_image_property_3">Configuring the <code>Kafka.spec.kafka.image</code> property</a></h6>
<div class="paragraph">
<p>The <code>Kafka.spec.kafka.image</code> property functions differently from the others, because Strimzi supports multiple versions of Kafka, each requiring the own image.
The <code>STRIMZI_KAFKA_IMAGES</code> environment variable of the Cluster Operator configuration is used to provide a mapping between Kafka versions and the corresponding images.
This is used in combination with the <code>Kafka.spec.kafka.image</code> and <code>Kafka.spec.kafka.version</code> properties as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If neither <code>Kafka.spec.kafka.image</code> nor <code>Kafka.spec.kafka.version</code> are given in the custom resource then the <code>version</code> will default to the  Cluster Operator&#8217;s default Kafka version, and the image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.image</code> is given but <code>Kafka.spec.kafka.version</code> is not then the given image will be used and the <code>version</code> will be assumed to be the  Cluster Operator&#8217;s default Kafka version.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.version</code> is given but <code>Kafka.spec.kafka.image</code> is not then image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>Both <code>Kafka.spec.kafka.version</code> and <code>Kafka.spec.kafka.image</code> are given the given image will be used, and it will be assumed to contain a Kafka broker with the given version.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
It is best to provide just <code>Kafka.spec.kafka.version</code> and leave the <code>Kafka.spec.kafka.image</code> property unspecified.
This reduces the chances of making a mistake in configuring the <code>Kafka</code> resource. If you need to change the images used for different versions of Kafka, it is better to configure the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> environment variable.
</td>
</tr>
</table>
</div>
</div>
<div class="sect5">
<h6 id="configuring_the_image_property_in_other_resources_3"><a class="link" href="#configuring_the_image_property_in_other_resources_3">Configuring the <code>image</code> property in other resources</a></h6>
<div class="paragraph">
<p>For the <code>image</code> property in the other custom resources, the given value will be used during deployment.
If the <code>image</code> property is missing, the <code>image</code> specified in the Cluster Operator configuration will be used.
If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-configuring-container-images-deployment-configuration-kafka-connect-s2i">Configuring container images</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</a></h4>
<div id="con-scheduling-deployment-configuration-kafka-connect-s2i" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods"><a class="link" href="#assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Scheduling pods based on other applications</a></h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods"><a class="link" href="#con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Avoid critical applications to share the node</a></h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods"><a class="link" href="#affinity-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods"><a class="link" href="#configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-s2i-node-scheduling"><a class="link" href="#assembly-node-scheduling-deployment-configuration-kafka-connect-s2i-node-scheduling">Scheduling pods to specific nodes</a></h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-s2i-node-scheduling"><a class="link" href="#con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-s2i-node-scheduling">Node scheduling</a></h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-node-scheduling"><a class="link" href="#affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-s2i-node-scheduling"><a class="link" href="#proc-configuring-node-affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Configuring node affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes"><a class="link" href="#assembly-dedidcated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Using dedicated nodes</a></h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes"><a class="link" href="#con-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Dedicated nodes</a></h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes"><a class="link" href="#affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes"><a class="link" href="#tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Tolerations</a></h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes"><a class="link" href="#proc-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect-s2i"><a class="link" href="#assembly-kafka-connect-external-configuration-deployment-configuration-kafka-connect-s2i">3.3.13. Using external configuration and secrets</a></h4>
<div class="paragraph">
<p>Kafka Connect connectors are configured using an HTTP REST interface.
The connector configuration is passed to Kafka Connect as part of an HTTP request and stored within Kafka itself.</p>
</div>
<div class="paragraph">
<p>Some parts of the configuration of a Kafka Connect connector can be externalized using ConfigMaps or Secrets.
You can then reference the configuration values in HTTP REST commands (this keeps the configuration separate and more secure, if needed).
This method applies especially to confidential data, such as usernames, passwords, or certificates.</p>
</div>
<div class="paragraph">
<p>ConfigMaps and Secrets are standard OpenShift or Kubernetes resources used for storing of configurations and confidential data.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-external-configuration-deployment-configuration-kafka-connect-s2i"><a class="link" href="#con-kafka-connect-external-configuration-deployment-configuration-kafka-connect-s2i">Storing connector configurations externally</a></h5>
<div class="paragraph">
<p>You can mount ConfigMaps or Secrets into a Kafka Connect pod as volumes or environment variables.
Volumes and environment variables are configured in the <code>externalConfiguration</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="sect5">
<h6 id="external_configuration_as_environment_variables_2"><a class="link" href="#external_configuration_as_environment_variables_2">External configuration as environment variables</a></h6>
<div class="paragraph">
<p>The <code>env</code> property is used to specify one or more environment variables.
These variables can contain a value from either a ConfigMap or a Secret.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The names of user-defined environment variables cannot start with <code>KAFKA_</code> or <code>STRIMZI_</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To mount a value from a Secret to an environment variable, use the <code>valueFrom</code> property and the <code>secretKeyRef</code> as shown in the following example.</p>
</div>
<div class="listingblock">
<div class="title">Example of an environment variable set to a value from a Secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: MY_ENVIRONMENT_VARIABLE
        valueFrom:
          secretKeyRef:
            name: my-secret
            key: my-key</code></pre>
</div>
</div>
<div class="paragraph">
<p>A common use case for mounting Secrets to environment variables is when your connector needs to communicate with Amazon AWS and needs to read the <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> environment variables with credentials.</p>
</div>
<div class="paragraph">
<p>To mount a value from a ConfigMap to an environment variable, use <code>configMapKeyRef</code> in the <code>valueFrom</code> property as shown in the following example.</p>
</div>
<div class="listingblock">
<div class="title">Example of an environment variable set to a value from a ConfigMap</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: MY_ENVIRONMENT_VARIABLE
        valueFrom:
          configMapKeyRef:
            name: my-config-map
            key: my-key</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="external_configuration_as_volumes_2"><a class="link" href="#external_configuration_as_volumes_2">External configuration as volumes</a></h6>
<div class="paragraph">
<p>You can also mount ConfigMaps or Secrets to a Kafka Connect pod as volumes.
Using volumes instead of environment variables is useful in the following scenarios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Mounting truststores or keystores with TLS certificates</p>
</li>
<li>
<p>Mounting a properties file that is used to configure Kafka Connect connectors</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the <code>volumes</code> property of the <code>externalConfiguration</code> resource, list the ConfigMaps or Secrets that will be mounted as volumes.
Each volume must specify a name in the <code>name</code> property and a reference to ConfigMap or Secret.</p>
</div>
<div class="listingblock">
<div class="title">Example of volumes with external configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    volumes:
      - name: connector1
        configMap:
          name: connector1-configuration
    - name: connector1-certificates
      secret:
        secretName: connector1-certificates</code></pre>
</div>
</div>
<div class="paragraph">
<p>The volumes will be mounted inside the Kafka Connect containers in the path <code>/opt/kafka/external-configuration/<em>&lt;volume-name&gt;</em></code>.
For example, the files from a volume named <code>connector1</code> would appear in the directory <code>/opt/kafka/external-configuration/connector1</code>.</p>
</div>
<div class="paragraph">
<p>The <code>FileConfigProvider</code> has to be used to read the values from the mounted properties files in connector configurations.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-connect-mounting-secrets-as-environment-variables-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-kafka-connect-mounting-secrets-as-environment-variables-deployment-configuration-kafka-connect-s2i">Mounting Secrets as environment variables</a></h5>
<div class="paragraph">
<p>You can create an OpenShift or Kubernetes Secret and mount it to Kafka Connect as an environment variable.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a secret containing the information that will be mounted as an environment variable.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: aws-creds
type: Opaque
data:
  awsAccessKey: QUtJQVhYWFhYWFhYWFhYWFg=
  awsSecretAccessKey: Ylhsd1lYTnpkMjl5WkE=</code></pre>
</div>
</div>
</li>
<li>
<p>Create or edit the Kafka Connect resource.
Configure the <code>externalConfiguration</code> section of the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> custom resource to reference the secret.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  externalConfiguration:
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: aws-creds
            key: awsAccessKey
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: aws-creds
            key: awsSecretAccessKey</code></pre>
</div>
</div>
</li>
<li>
<p>Apply the changes to your Kafka Connect deployment.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>The environment variables are now available for use when developing your connectors.</p>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about external configuration in Kafka Connect, see <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-connect-mounting-volumes-deployment-configuration-kafka-connect-s2i"><a class="link" href="#proc-kafka-connect-mounting-volumes-deployment-configuration-kafka-connect-s2i">Mounting Secrets as volumes</a></h5>
<div class="paragraph">
<p>You can create an OpenShift or Kubernetes Secret, mount it as a volume to Kafka Connect, and then use it to configure a Kafka Connect connector.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a secret containing a properties file that defines the configuration options for your connector configuration.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
stringData:
  connector.properties: |-
    dbUsername: my-user
    dbPassword: my-password</code></pre>
</div>
</div>
</li>
<li>
<p>Create or edit the Kafka Connect resource.
Configure the <code>FileConfigProvider</code> in the <code>config</code> section and the <code>externalConfiguration</code> section of the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> custom resource to reference the secret.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    config.providers: file
    config.providers.file.class: org.apache.kafka.common.config.provider.FileConfigProvider
  #...
  externalConfiguration:
    volumes:
      - name: connector-config
        secret:
          secretName: mysecret</code></pre>
</div>
</div>
</li>
<li>
<p>Apply the changes to your Kafka Connect deployment.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the values from the mounted properties file in your JSON payload with connector configuration.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
   "name":"my-connector",
   "config":{
      "connector.class":"MyDbConnector",
      "tasks.max":"3",
      "database": "my-postgresql:5432"
      "username":"${file:/opt/kafka/external-configuration/connector-config/connector.properties:dbUsername}",
      "password":"${file:/opt/kafka/external-configuration/connector-config/connector.properties:dbPassword}",
      # ...
   }
}</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about external configuration in Kafka Connect, see <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-connect-s2i-resources-deployment-configuration-kafka-connect-s2i"><a class="link" href="#ref-list-of-kafka-connect-s2i-resources-deployment-configuration-kafka-connect-s2i">3.3.14. List of resources created as part of Kafka Connect cluster with Source2Image support</a></h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-source</dt>
<dd>
<p>ImageStream which is used as the base image for the newly-built Docker images.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>BuildConfig which is responsible for building the new Kafka Connect Docker images.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>ImageStream where the newly built Docker images will be pushed.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>DeploymentConfig which is in charge of creating the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>Pod Disruption Budget configured for the Kafka Connect worker nodes.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i"><a class="link" href="#using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.15. Creating a container image using OpenShift builds and Source-to-Image</a></h4>
<div class="paragraph">
<p>You can use OpenShift <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a> and the  <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images. An OpenShift build takes a builder image with S2I support, together with source code and binaries provided by the user, and uses them to build a new container image. Once built, container images are stored in OpenShift&#8217;s local container image repository and are available for use in deployments.</p>
</div>
<div class="paragraph">
<p>A Kafka Connect builder image with S2I support is provided by Strimzi on the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.11.1-kafka-2.1.0</code>. This S2I image takes your binaries (with plug-ins and connectors) and stores them in the <code>/tmp/kafka-plugins/s2i</code> directory. It creates a new Kafka Connect image from this directory, which can then be used with the Kafka Connect deployment. When started using the enhanced image, Kafka Connect loads any third-party plug-ins from the <code>/tmp/kafka-plugins/s2i</code> directory.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>On the command line, use the <code>oc apply</code> command to create and deploy a Kafka Connect S2I cluster:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Create a directory with Kafka Connect plug-ins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>my-plugins</em>/
./<em>my-plugins</em>/
 debezium-connector-mongodb
  bson-3.4.2.jar
  CHANGELOG.md
  CONTRIBUTE.md
  COPYRIGHT.txt
  debezium-connector-mongodb-0.7.1.jar
  debezium-core-0.7.1.jar
  LICENSE.txt
  mongodb-driver-3.4.2.jar
  mongodb-driver-core-3.4.2.jar
  README.md
 debezium-connector-mysql
  CHANGELOG.md
  CONTRIBUTE.md
  COPYRIGHT.txt
  debezium-connector-mysql-0.7.1.jar
  debezium-core-0.7.1.jar
  LICENSE.txt
  mysql-binlog-connector-java-0.13.0.jar
  mysql-connector-java-5.1.40.jar
  README.md
  wkb-1.0.2.jar
 debezium-connector-postgres
     CHANGELOG.md
     CONTRIBUTE.md
     COPYRIGHT.txt
     debezium-connector-postgres-0.7.1.jar
     debezium-core-0.7.1.jar
     LICENSE.txt
     postgresql-42.0.0.jar
     protobuf-java-2.6.1.jar
     README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Use the <code>oc start-build</code> command to start a new build of the image using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>my-connect-cluster-connect</em> --from-dir ./<em>my-plugins</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build is the same as the name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build has finished, the new image is used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-mirror-maker-str"><a class="link" href="#assembly-deployment-configuration-kafka-mirror-maker-str">3.4. Kafka Mirror Maker configuration</a></h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaMirrorMaker</code> resource is described in the <a href="#type-KafkaMirrorMaker-reference"><code>KafkaMirrorMaker</code> schema reference</a>.
All labels that apply to the desired <code>KafkaMirrorMaker</code> resource will also be applied to the OpenShift or Kubernetes resources making up Mirror Maker.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">3.4.1. Replicas</a></h4>
<div class="paragraph">
<p>It is possible to run multiple Mirror Maker replicas.
The number of replicas is defined in the <code>KafkaMirrorMaker</code> resource.
You can run multiple Mirror Maker replicas to provide better availability and scalability.
However, when running Kafka Mirror Maker on OpenShift or Kubernetes it is not absolutely necessary to run multiple replicas of the Kafka Mirror Maker for high availability.
When the node where the Kafka Mirror Maker has deployed crashes, OpenShift or Kubernetes will automatically reschedule the Kafka Mirror Maker pod to a different node.
However, running Kafka Mirror Maker with multiple replicas can provide faster failover times as the other nodes will be up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">Configuring the number of replicas</a></h5>
<div class="paragraph">
<p>The number of Kafka Mirror Maker replicas can be configured using the <code>replicas</code> property in <code>KafkaMirrorMaker.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaMirrorMaker</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">3.4.2. Bootstrap servers</a></h4>
<div class="paragraph">
<p>Kafka Mirror Maker always works together with two Kafka clusters (source and target).
The source and the target Kafka clusters are specified in the form of two lists of comma-separated list of <code><em>&lt;hostname&gt;</em>:<em>&lt;port&gt;</em></code> pairs.
The bootstrap server lists can refer to Kafka clusters which do not need to be deployed in the same OpenShift or Kubernetes cluster.
They can even refer to any Kafka cluster not deployed by Strimzi or even deployed by Strimzi but on a different OpenShift or Kubernetes cluster and accessible from outside.</p>
</div>
<div class="paragraph">
<p>If on the same OpenShift or Kubernetes cluster, each list must ideally contain the Kafka cluster bootstrap service which is named <code><em>&lt;cluster-name&gt;</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.
If deployed by Strimzi but on different OpenShift or Kubernetes clusters, the list content depends on the way used for exposing the clusters (routes, nodeports or loadbalancers).</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>KafkaMirrorMaker.spec.consumer.bootstrapServers</code> and <code>KafkaMirrorMaker.spec.producer.bootstrapServers</code> properties. The servers should be a comma-separated list containing one or more Kafka brokers or a <code>Service</code> pointing to Kafka brokers specified as a <code>&lt;hostname&gt;:&lt;port&gt;</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Mirror Maker with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of the given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">Configuring bootstrap servers</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.bootstrapServers</code> and <code>KafkaMirrorMaker.spec.producer.bootstrapServers</code> properties.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    bootstrapServers: my-source-cluster-kafka-bootstrap:9092
  # ...
  producer:
    bootstrapServers: my-target-cluster-kafka-bootstrap:9092</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">3.4.3. Whitelist</a></h4>
<div class="paragraph">
<p>You specify the list topics that the Kafka Mirror Maker has to mirror from the source to the target Kafka cluster in the KafkaMirrorMaker resource using the <em>whitelist</em> option.
It allows any regular expression from the simplest case with a single topic name to complex patterns.
For example, you can mirror topics A and B using "A|B" or all topics using "*".
You can also pass multiple regular expressions separated by commas to the Kafka Mirror Maker.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">Configuring the topics whitelist</a></h5>
<div class="paragraph">
<p>Specify the list topics that have to be mirrored by the Kafka Mirror Maker from source to target Kafka cluster using the <code>whitelist</code> property in <code>KafkaMirrorMaker.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>whitelist</code> property in the <code>KafkaMirrorMaker</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  whitelist: "my-topic|other-topic"
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">3.4.4. Consumer group identifier</a></h4>
<div class="paragraph">
<p>The Kafka Mirror Maker uses Kafka consumer to consume messages and it behaves like any other Kafka consumer client.
It is in charge to consume the messages from the source Kafka cluster which will be mirrored to the target Kafka cluster.
The consumer needs to be part of a <em>consumer group</em> for being assigned partitions.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">Configuring the consumer group identifier</a></h5>
<div class="paragraph">
<p>The consumer group identifier can be configured in the <code>KafkaMirrorMaker.spec.consumer.groupId</code> property.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.groupId</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    groupId: "my-group"
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">3.4.5. Number of consumer streams</a></h4>
<div class="paragraph">
<p>You can increase the throughput in mirroring topics by increase the number of consumer threads.
More consumer threads will belong to the same configured <em>consumer group</em>.
The topic partitions will be assigned across these consumer threads which will consume messages in parallel.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">Configuring the number of consumer streams</a></h5>
<div class="paragraph">
<p>The number of consumer streams can be configured using the <code>KafkaMirrorMaker.spec.consumer.numStreams</code> property.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.numStreams</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    numStreams: 2
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">3.4.6. Connecting to Kafka brokers using TLS</a></h4>
<div class="paragraph">
<p>By default, Kafka Mirror Maker will try to connect to Kafka brokers, in the source and target clusters, using a plain text connection.
You must make additional configurations to use TLS.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">TLS support in Kafka Mirror Maker</a></h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> sub-property of <code>consumer</code> and <code>producer</code> properties in <code>KafkaMirrorMaker.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X.509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-source-secret
          certificate: ca.crt
        - secretName: my-other-source-secret
          certificate: certificate.crt
  # ...
  producer:
    tls:
      trustedCertificates:
        - secretName: my-target-secret
          certificate: ca.crt
        - secretName: my-other-target-secret
          certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-source-secret
          certificate: ca.crt
        - secretName: my-source-secret
          certificate: ca2.crt
  # ...
  producer:
    tls:
      trustedCertificates:
        - secretName: my-target-secret
          certificate: ca.crt
        - secretName: my-target-secret
          certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">Configuring TLS encryption in Kafka Mirror Maker</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure TLS for one or both the clusters.
The following steps describe how to configure TLS on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.tls</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-cluster-cluster-cert
          certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring TLS on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.tls</code> property.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-authentication-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-authentication-deployment-configuration-kafka-mirror-maker">3.4.7. Connecting to Kafka brokers with Authentication</a></h4>
<div class="paragraph">
<p>By default, Kafka Mirror Maker will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaMirrorMaker</code> resource.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-mirror-maker-authenticationdeployment-configuration-kafka-mirror-maker"><a class="link" href="#con-kafka-mirror-maker-authenticationdeployment-configuration-kafka-mirror-maker">Authentication support in Kafka Mirror Maker</a></h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>KafkaMirrorMaker.spec.consumer.authentication</code> and <code>KafkaMirrorMaker.spec.producer.authentication</code> properties.
The <code>authentication</code> property specifies the type of the authentication method which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_4"><a class="link" href="#tls_client_authentication_4">TLS Client Authentication</a></h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
The TLS client authentication uses TLS certificate to authenticate.
The certificate has to be specified in the certificateAndKey property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X.509 format separately as public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Mirror Maker see <a href="#assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-source-secret
        certificate: public.crt
        key: private.key
  # ...
  producer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-target-secret
        certificate: public.crt
        key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication_3"><a class="link" href="#scram_sha_512_authentication_3">SCRAM-SHA-512 authentication</a></h6>
<div class="paragraph">
<p>To configure Kafka Mirror Maker to use SCRAM-SHA-512 authentication, set the <code>type</code> property to <code>scram-sha-512</code>.
The broker listener to which clients are connecting must also be configured to use SCRAM-SHA-512 SASL authentication.
This authentication mechanism requires a username and password.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Specify the username in the <code>username</code> property.</p>
</li>
<li>
<p>In the <code>passwordSecret</code> property, specify a link to a <code>Secret</code> containing the password. The <code>secretName</code> property contains the name of such a <code>Secret</code> and the <code>password</code> property contains the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Do not specify the actual password in the <code>password</code> field.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: scram-sha-512
      username: my-source-user
      passwordSecret:
        secretName: my-source-user
        password: my-source-password-key
  # ...
  producer:
    authentication:
      type: scram-sha-512
      username: my-producer-user
      passwordSecret:
        secretName: my-producer-user
        password: my-producer-password-key
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-authentication-tls-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-authentication-tls-deployment-configuration-kafka-mirror-maker">Configuring TLS client authentication in Kafka Mirror Maker</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator with a <code>tls</code> listener with <code>tls</code> authentication enabled</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure TLS client authentication for one or both the clusters.
The following steps describe how to configure TLS client authentication on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.authentication</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-secret
        certificate: my-public.crt
        key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring TLS client authentication on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.authentication</code> property.</p>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-authentication-scram-sha-512-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-authentication-scram-sha-512-deployment-configuration-kafka-mirror-maker">Configuring SCRAM-SHA-512 authentication in Kafka Mirror Maker</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator with a <code>listener</code> configured for SCRAM-SHA-512 authentication</p>
</li>
<li>
<p>Username to be used for authentication</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure SCRAM-SHA-512 authentication for one or both the clusters.
The following steps describe how to configure SCRAM-SHA-512 authentication on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password.txt&gt;</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.authentication</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: scram-sha-512
      username: _&lt;my-username&gt;_
      passwordSecret:
        secretName: _&lt;my-secret&gt;_
        password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring SCRAM-SHA-512 authentication on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.authentication</code> property.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">3.4.8. Kafka Mirror Maker configuration</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of the Kafka Mirror Maker by editing most of the options for the related consumer and producer.
Producer options are listed in <a href="http://kafka.apache.org/20/documentation.html#producerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.
Consumer options are listed in <a href="http://kafka.apache.org/20/documentation.html#newconsumerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Consumer group identifier</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">Kafka Mirror Maker configuration</a></h5>
<div class="paragraph">
<p>Kafka Mirror Maker can be configured using the <code>config</code> sub-property in <code>KafkaMirrorMaker.spec.consumer</code> and <code>KafkaMirrorMaker.spec.producer</code>.
This property should contain the Kafka Mirror Maker consumer and producer configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#producerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> and <a href="http://kafka.apache.org/20/documentation.html#newconsumerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
<li>
<p><code>group.id</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Mirror Maker.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Mirror Maker might not start or might become unstable.
In such cases, the configuration in the <code>KafkaMirrorMaker.spec.consumer.config</code> or <code>KafkaMirrorMaker.spec.producer.config</code> object should be fixed and the cluster operator will roll out the new configuration for Kafka Mirror Maker.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Mirror Maker configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirroMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    config:
      max.poll.records: 100
      receive.buffer.bytes: 32768
  producer:
    config:
      compression.type: gzip
      batch.size: 8192
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-kafka-mirror-maker-deployment-configuration-kafka-mirror-maker">Configuring Kafka Mirror Maker</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Two running Kafka clusters (source and target)</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.config</code> and <code>KafkaMirrorMaker.spec.producer.config</code> properties.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirroMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    config:
      max.poll.records: 100
      receive.buffer.bytes: 32768
  producer:
    config:
      compression.type: gzip
      batch.size: 8192
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">3.4.9. CPU and memory resources</a></h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">Resource limits and requests</a></h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_4"><a class="link" href="#resource_requests_4">Resource requests</a></h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_4"><a class="link" href="#resource_limits_4">Resource limits</a></h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_4"><a class="link" href="#supported_cpu_formats_4">Supported CPU formats</a></h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_4"><a class="link" href="#supported_memory_formats_4">Supported memory formats</a></h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_4"><a class="link" href="#additional_resources_4">Additional resources</a></h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">Configuring resource requests and limits</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-logging-deployment-configuration-kafka-mirror-maker">3.4.10. Logging</a></h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-mirror-maker"><a class="link" href="#kafka-inline-logging-deployment-configuration-kafka-mirror-maker">Using inline logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-mirror-maker"><a class="link" href="#kafka-external-logging-deployment-configuration-kafka-mirror-maker">Using external ConfigMap for logging setting</a></h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-mirror-maker"><a class="link" href="#kafka-logging-loggers-deployment-configuration-kafka-mirror-maker">Loggers</a></h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-metrics-deployment-configuration-kafka-mirror-maker">3.4.11. Prometheus metrics</a></h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-metrics-deployment-configuration-kafka-mirror-maker">Metrics configuration</a></h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-metrics-deployment-configuration-kafka-mirror-maker">Configuring Prometheus metrics</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-jvm-options-deployment-configuration-kafka-mirror-maker">3.4.12. JVM Options</a></h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-jvm-options-deployment-configuration-kafka-mirror-maker">JVM configuration</a></h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4  the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5  the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-jvm-options-deployment-configuration-kafka-mirror-maker">Configuring JVM options</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker">3.4.13. Container images</a></h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-configuring-container-images-deployment-configuration-kafka-mirror-maker">Container image configurations</a></h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="configuring_the_kafka_spec_kafka_image_property_4"><a class="link" href="#configuring_the_kafka_spec_kafka_image_property_4">Configuring the <code>Kafka.spec.kafka.image</code> property</a></h6>
<div class="paragraph">
<p>The <code>Kafka.spec.kafka.image</code> property functions differently from the others, because Strimzi supports multiple versions of Kafka, each requiring the own image.
The <code>STRIMZI_KAFKA_IMAGES</code> environment variable of the Cluster Operator configuration is used to provide a mapping between Kafka versions and the corresponding images.
This is used in combination with the <code>Kafka.spec.kafka.image</code> and <code>Kafka.spec.kafka.version</code> properties as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If neither <code>Kafka.spec.kafka.image</code> nor <code>Kafka.spec.kafka.version</code> are given in the custom resource then the <code>version</code> will default to the  Cluster Operator&#8217;s default Kafka version, and the image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.image</code> is given but <code>Kafka.spec.kafka.version</code> is not then the given image will be used and the <code>version</code> will be assumed to be the  Cluster Operator&#8217;s default Kafka version.</p>
</li>
<li>
<p>If <code>Kafka.spec.kafka.version</code> is given but <code>Kafka.spec.kafka.image</code> is not then image will be the one corresponding to this version in the <code>STRIMZI_KAFKA_IMAGES</code>.</p>
</li>
<li>
<p>Both <code>Kafka.spec.kafka.version</code> and <code>Kafka.spec.kafka.image</code> are given the given image will be used, and it will be assumed to contain a Kafka broker with the given version.</p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
It is best to provide just <code>Kafka.spec.kafka.version</code> and leave the <code>Kafka.spec.kafka.image</code> property unspecified.
This reduces the chances of making a mistake in configuring the <code>Kafka</code> resource. If you need to change the images used for different versions of Kafka, it is better to configure the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> environment variable.
</td>
</tr>
</table>
</div>
</div>
<div class="sect5">
<h6 id="configuring_the_image_property_in_other_resources_4"><a class="link" href="#configuring_the_image_property_in_other_resources_4">Configuring the <code>image</code> property in other resources</a></h6>
<div class="paragraph">
<p>For the <code>image</code> property in the other custom resources, the given value will be used during deployment.
If the <code>image</code> property is missing, the <code>image</code> specified in the Cluster Operator configuration will be used.
If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-mirror-maker"><a class="link" href="#proc-configuring-container-images-deployment-configuration-kafka-mirror-maker">Configuring container images</a></h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-mirror-maker"><a class="link" href="#assembly-scheduling-deployment-configuration-kafka-mirror-maker">3.4.14. Configuring pod scheduling</a></h4>
<div id="con-scheduling-deployment-configuration-kafka-mirror-maker" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods"><a class="link" href="#assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Scheduling pods based on other applications</a></h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods"><a class="link" href="#con-scheduling-based-on-other-pods-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Avoid critical applications to share the node</a></h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods"><a class="link" href="#affinity-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods"><a class="link" href="#configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-mirror-maker-node-scheduling"><a class="link" href="#assembly-node-scheduling-deployment-configuration-kafka-mirror-maker-node-scheduling">Scheduling pods to specific nodes</a></h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-mirror-maker-node-scheduling"><a class="link" href="#con-scheduling-to-specific-nodes-deployment-configuration-kafka-mirror-maker-node-scheduling">Node scheduling</a></h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-node-scheduling"><a class="link" href="#affinity-deployment-configuration-kafka-mirror-maker-node-scheduling">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-mirror-maker-node-scheduling"><a class="link" href="#proc-configuring-node-affinity-deployment-configuration-kafka-mirror-maker-node-scheduling">Configuring node affinity in Kafka components</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes"><a class="link" href="#assembly-dedidcated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Using dedicated nodes</a></h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes"><a class="link" href="#con-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Dedicated nodes</a></h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-mirror-maker-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-mirror-maker-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-dedicated-nodes"><a class="link" href="#affinity-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Affinity</a></h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-mirror-maker-dedicated-nodes"><a class="link" href="#tolerations-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Tolerations</a></h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes"><a class="link" href="#proc-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</a></h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-mirror-maker-resources-deployment-configuration-kafka-mirror-maker"><a class="link" href="#ref-list-of-kafka-mirror-maker-resources-deployment-configuration-kafka-mirror-maker">3.4.15. List of resources created as part of Kafka Mirror Maker</a></h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>&lt;mirror-maker-name&gt;</em>-mirror-maker</dt>
<dd>
<p>Deployment which is in charge to create the Kafka Mirror Maker pods.</p>
</dd>
<dt class="hdlist1"><em>&lt;mirror-maker-name&gt;</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Mirror Maker ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><em>&lt;mirror-maker-name&gt;</em>-mirror-maker</dt>
<dd>
<p>Pod Disruption Budget configured for the Kafka Mirror Maker worker nodes.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-customizing-deployments-str"><a class="link" href="#assembly-customizing-deployments-str">3.5. Customizing deployments</a></h3>
<div class="paragraph">
<p>Strimzi creates several OpenShift or Kubernetes resources, such as <code>Deployments</code>, <code>StatefulSets</code>, <code>Pods</code>, and <code>Services</code>, which are managed by OpenShift or Kubernetes operators.
Only the operator that is responsible for managing a particular OpenShift or Kubernetes resource can change that resource.
If you try to manually change an operator-managed OpenShift or Kubernetes resource, the operator will revert your changes back.</p>
</div>
<div class="paragraph">
<p>However, changing an operator-managed OpenShift or Kubernetes resource can be useful if you want to perform certain tasks, such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Adding custom labels or annotations that control how <code>Pods</code> are treated by Istio or other services;</p>
</li>
<li>
<p>Managing how <code>Loadbalancer</code>-type Services are created by the cluster.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can make these types of changes using the <code>template</code> property in the Strimzi custom resources.</p>
</div>
<div class="sect3">
<h4 id="con-customizing-template-properties-str"><a class="link" href="#con-customizing-template-properties-str">3.5.1. Template properties</a></h4>
<div class="paragraph">
<p>You can use the <code>template</code> property to configure aspects of the resource creation process.
You can include it in the following resources and properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka.spec.kafka</p>
</li>
<li>
<p>Kafka.spec.zookeeper</p>
</li>
<li>
<p>Kafka.spec.entityOperator</p>
</li>
<li>
<p>KafkaConnect.spec</p>
</li>
<li>
<p>KafkaConnectS2I.spec</p>
</li>
<li>
<p>KafkaMirrorMakerSpec</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the following example, the <code>template</code> property is used to modify the labels in a Kafka broker&#8217;s <code>StatefulSet</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
  labels:
    app: my-cluster
spec:
  kafka:
    # ...
    template:
      statefulset:
        metadata:
          labels:
            mylabel: myvalue
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">Supported resources in Kafka cluster</div>
<p>When defined in a Kafka cluster, the <code>template</code> object can have the following fields:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>statefulset</code></dt>
<dd>
<p>Configures the <code>StatefulSet</code> used by the Kafka broker.</p>
</dd>
<dt class="hdlist1"><code>pod</code></dt>
<dd>
<p>Configures the Kafka broker <code>Pods</code> created by the <code>StatefulSet</code>.</p>
</dd>
<dt class="hdlist1"><code>bootstrapService</code></dt>
<dd>
<p>Configures the bootstrap service used by clients running within OpenShift or Kubernetes to connect to the Kafka broker.</p>
</dd>
<dt class="hdlist1"><code>brokersService</code></dt>
<dd>
<p>Configures the headless service.</p>
</dd>
<dt class="hdlist1"><code>externalBootstrapService</code></dt>
<dd>
<p>Configures the bootstrap service used by clients connecting to Kafka brokers from outside of OpenShift or Kubernetes.</p>
</dd>
<dt class="hdlist1"><code>perPodService</code></dt>
<dd>
<p>Configures the per-Pod services used by clients connecting to the Kafka broker from outside OpenShift or Kubernetes to access individual brokers.</p>
</dd>
<dt class="hdlist1"><code>externalBootstrapRoute</code></dt>
<dd>
<p>Configures the bootstrap route used by clients connecting to the Kafka brokers from outside of OpenShift using OpenShift <code>Routes</code>.</p>
</dd>
<dt class="hdlist1"><code>perPodRoute</code></dt>
<dd>
<p>Configures the per-Pod routes used by clients connecting to the Kafka broker from outside OpenShift to access individual brokers using OpenShift <code>Routes</code>.</p>
</dd>
<dt class="hdlist1"><code>podDisruptionBudget</code></dt>
<dd>
<p>Configures the Pod Disruption Budget for Kafka broker <code>StatefulSet</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">Supported resources in Zookeeper cluster</div>
<p>When defined in a Zookeeper cluster, the <code>template</code> object can have the following fields:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>statefulset</code></dt>
<dd>
<p>Configures the Zookeeper <code>StatefulSet</code>.</p>
</dd>
<dt class="hdlist1"><code>pod</code></dt>
<dd>
<p>Configures the Zookeeper <code>Pods</code> created by the <code>StatefulSet</code>.</p>
</dd>
<dt class="hdlist1"><code>clientsService</code></dt>
<dd>
<p>Configures the service used by clients to access Zookeeper.</p>
</dd>
<dt class="hdlist1"><code>nodesService</code></dt>
<dd>
<p>Configures the headless service.</p>
</dd>
<dt class="hdlist1"><code>podDisruptionBudget</code></dt>
<dd>
<p>Configures the Pod Disruption Budget for Zookeeper <code>StatefulSet</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">Supported resources in Entity Operator</div>
<p>When defined in an Entity Operator , the template object can have the following fields:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>deployment</code></dt>
<dd>
<p>Configures the Deployment used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>pod</code></dt>
<dd>
<p>Configures the Entity Operator <code>Pod</code> created by the <code>Deployment</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">Supported resources in Kafka Connect and Kafka Connect with Source2Image support</div>
<p>When used with Kafka Connect and Kafka Connect with Source2Image support , the template object can have the following fields:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>deployment</code></dt>
<dd>
<p>Configures the Kafka Connect <code>Deployment</code>.</p>
</dd>
<dt class="hdlist1"><code>pod</code></dt>
<dd>
<p>Configures the Kafka Connect <code>Pods</code> created by the <code>Deployment</code>.</p>
</dd>
<dt class="hdlist1"><code>apiService</code></dt>
<dd>
<p>Configures the service used by the Kafka Connect REST API.</p>
</dd>
<dt class="hdlist1"><code>podDisruptionBudget</code></dt>
<dd>
<p>Configures the Pod Disruption Budget for Kafka Connect <code>Deployment</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">Supported resource in Kafka Mirror Maker</div>
<p>When used with Kafka Mirror Maker , the template object can have the following fields:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>deployment</code></dt>
<dd>
<p>Configures the Kafka Mirror Maker <code>Deployment</code>.</p>
</dd>
<dt class="hdlist1"><code>pod</code></dt>
<dd>
<p>Configures the Kafka Mirror Maker <code>Pods</code> created by the <code>Deployment</code>.</p>
</dd>
<dt class="hdlist1"><code>podDisruptionBudget</code></dt>
<dd>
<p>Configures the Pod Disruption Budget for Kafka Mirror Maker <code>Deployment</code>.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="con-customizing-labels-and-annotations-str"><a class="link" href="#con-customizing-labels-and-annotations-str">3.5.2. Labels and Annotations</a></h4>
<div class="paragraph">
<p>For every resource, you can configure additional <code>Labels</code> and <code>Annotations</code>.
<code>Labels</code> and <code>Annotations</code> are configured in the <code>metadata</code> property.
For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
template:
    statefulset:
        metadata:
            labels:
                label1: value1
                label2: value2
            annotations:
                annotation1: value1
                annotation2: value2
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>labels</code> and <code>annotations</code> fields can contain any labels or annotations that do not contain the reserved string <code>strimzi.io</code>.
Labels and annotations containing <code>strimzi.io</code> are used internally by Strimzi and cannot be configured by the user.</p>
</div>
</div>
<div class="sect3">
<h4 id="con-customizing-pods-str"><a class="link" href="#con-customizing-pods-str">3.5.3. Customizing Pods</a></h4>
<div class="paragraph">
<p>In addition to Labels and Annotations, you can customize some other fields on Pods.
These fields are described in the following table and affect how the Pod is created.</p>
</div>
<table class="tableblock frame-all grid-all stripes-none stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>terminationGracePeriodSeconds</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Defines the period of time, in seconds, by which the Pod must have terminated gracefully.
After the grace period, the Pod and its containers are forcefully terminated (killed).
The default value is <code>30</code> seconds.</p>
<p class="tableblock">NOTE: You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>imagePullSecrets</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Defines a list of references to OpenShift or Kubernetes Secrets that can be used for pulling container images from private repositories.
For more information about how to create a Secret with the credentials, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/" target="_blank" rel="noopener">Pull an Image from a Private Registry</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>securityContext</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configures pod-level security attributes for containers running as part of a given Pod.
For more information about configuring SecurityContext, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/" target="_blank" rel="noopener">Configure a Security Context for a Pod or Container</a>.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>These fields are effective on each type of cluster (Kafka and Zookeeper; Kafka Connect and Kafka Connect with S2I support; and Kafka Mirror Maker).</p>
</div>
<div class="paragraph">
<p>The following example shows these customized fields on a <code>template</code> property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
template:
    pod:
        metadata:
            labels:
                label1: value1
        imagePullSecrets:
             - name: my-docker-credentials
        securityContext:
             runAsUser: 1000001
             fsGroup: 0
        terminationGracePeriodSeconds: 120
# ...</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information, see <a href="#type-PodTemplate-reference"><code>PodTemplate</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-customizing-image-pull-policy-str"><a class="link" href="#con-customizing-image-pull-policy-str">3.5.4. Customizing the image pull policy</a></h4>
<div class="paragraph">
<p>Strimzi allows you to customize the image pull policy for containers in all pods deployed by the Cluster Operator.
The image pull policy is configured using the environment variable <code>STRIMZI_IMAGE_PULL_POLICY</code> in the Cluster Operator deployment.
The <code>STRIMZI_IMAGE_PULL_POLICY</code> environment variable can be set to three different values:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>Always</code></dt>
<dd>
<p>Container images are pulled from the registry every time the pod is started or restarted.</p>
</dd>
<dt class="hdlist1"><code>IfNotPresent</code></dt>
<dd>
<p>Container images are pulled from the registry only when they were not pulled before.</p>
</dd>
<dt class="hdlist1"><code>Never</code></dt>
<dd>
<p>Container images are never pulled from the registry.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The image pull policy can be currently customized only for all Kafka, Kafka Connect, and Kafka Mirror Maker clusters at once.
Changing the policy will result in a rolling update of all your Kafka, Kafka Connect, and Kafka Mirror Maker clusters.</p>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Cluster Operator configuration, see <a href="#assembly-operators-cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about Image Pull Policies, see <a href="https://kubernetes.io/docs/concepts/containers/images/#updating-images" target="_blank" rel="noopener">Disruptions</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-customizing-pod-disruption-budgets-str"><a class="link" href="#con-customizing-pod-disruption-budgets-str">3.5.5. Customizing Pod Disruption Budgets</a></h4>
<div class="paragraph">
<p>Strimzi creates a pod disruption budget for every new <code>StatefulSet</code> or <code>Deployment</code>.
By default, these pod disruption budgets only allow a single pod to be unavailable at a given time by setting the <code>maxUnavailable</code> value in the`PodDisruptionBudget.spec` resource to 1.
You can change the amount of unavailable pods allowed by changing the default value of <code>maxUnavailable</code> in the pod disruption budget template.
This template applies to each type of cluster (Kafka and Zookeeper; Kafka Connect and Kafka Connect with S2I support; and Kafka Mirror Maker).</p>
</div>
<div class="paragraph">
<p>The following example shows customized <code>podDisruptionBudget</code> fields on a <code>template</code> property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
template:
    podDisruptionBudget:
        metadata:
            labels:
                key1: label1
                key2: label2
            annotations:
                key1: label1
                key2: label2
        maxUnavailable: 1
# ...</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information, see <a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code> schema reference</a>.</p>
</li>
<li>
<p>The <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/" target="_blank" rel="noopener">Disruptions</a> chapter of the Kubernetes documentation.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-customizing-deployments-str"><a class="link" href="#proc-customizing-deployments-str">3.5.6. Customizing deployments</a></h4>
<div class="paragraph">
<p>This procedure describes how to customize <code>Labels</code> of a Kafka cluster.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>template</code> property in the <code>Kafka</code>, <code>KafkaConnect</code>, <code>KafkaConnectS2I</code>, or <code>KafkaMirrorMaker</code> resource.
For example, to modify the labels for the Kafka broker <code>StatefulSet</code>, use:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
  labels:
    app: my-cluster
spec:
  kafka:
    # ...
    template:
      statefulset:
        metadata:
          labels:
            mylabel: myvalue
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, use <code>kubectl edit</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl edit <em>Resource</em> <em>ClusterName</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, use <code>oc edit</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc edit <em>Resource</em> <em>ClusterName</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-operators-str"><a class="link" href="#assembly-operators-str">4. Operators</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="assembly-operators-cluster-operator-str"><a class="link" href="#assembly-operators-cluster-operator-str">4.1. Cluster Operator</a></h3>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-deploying-co"><a class="link" href="#con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</a></h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 2. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka, Kafka Connect, or Kafka Mirror Maker cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
<li>
<p>A <code>KafkaMirrorMaker</code> resource for the Kafka Mirror Maker instance.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, <code>KafkaConnectS2I</code>, or <code>Kafka Mirror Maker</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka, Kafka Connect, or Kafka Mirror Maker cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka, Kafka Connect, or Kafka Mirror Maker cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka, Kafka Connect, or Kafka Mirror Maker cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-deploying-co"><a class="link" href="#deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f install/cluster-operator -n _my-namespace_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-deploying-co"><a class="link" href="#deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f install/cluster-operator -n _my-project_
oc apply -f examples/templates/cluster-operator -n _my-project_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co"><a class="link" href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>my-namespace</em></code> or <code><em>my-project</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-project</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-whole-cluster-deploying-co"><a class="link" href="#deploying-cluster-operator-kubernetes-to-watch-whole-cluster-deploying-co">4.1.5. Deploying the Cluster Operator to watch all namespaces</a></h4>
<div class="paragraph">
<p>You can configure the Cluster Operator to watch Strimzi resources across all OpenShift projects or Kubernetes namespaces in your OpenShift or Kubernetes cluster. When running in this mode, the Cluster Operator automatically manages clusters in any new projects or namespaces that are created.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Your OpenShift or Kubernetes cluster is running.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Configure the Cluster Operator to watch all namespaces:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Edit the <code>050-Deployment-strimzi-cluster-operator.yaml</code> file.</p>
</li>
<li>
<p>Set the value of the <code>STRIMZI_NAMESPACE</code> environment variable to <code>*</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      # ...
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: "*"
        # ...</code></pre>
</div>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>Create <code>ClusterRoleBindings</code> that grant cluster-wide access to all OpenShift projects or Kubernetes namespaces to the Cluster Operator.</p>
<div class="paragraph">
<p>On OpenShift, use the <code>oc adm policy</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm policy add-cluster-role-to-user strimzi-cluster-operator-namespaced --serviceaccount strimzi-cluster-operator -n <em>my-project</em>
oc adm policy add-cluster-role-to-user strimzi-entity-operator --serviceaccount strimzi-cluster-operator -n <em>my-project</em>
oc adm policy add-cluster-role-to-user strimzi-topic-operator --serviceaccount strimzi-cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>Replace <code><em>my-project</em></code> with the project in which you want to install the Cluster Operator.</p>
</div>
<div class="paragraph">
<p>On Kubernetes, use the <code>kubectl create</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create clusterrolebinding strimzi-cluster-operator-namespaced --clusterrole=strimzi-cluster-operator-namespaced --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator
kubectl create clusterrolebinding strimzi-cluster-operator-entity-operator-delegation --clusterrole=strimzi-entity-operator --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator
kubectl create clusterrolebinding strimzi-cluster-operator-topic-operator-delegation --clusterrole=strimzi-topic-operator --serviceaccount <em>my-namespace</em>:strimzi-cluster-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>Replace <code><em>my-namespace</em></code> with the namespace in which you want to install the Cluster Operator.</p>
</div>
</li>
<li>
<p>Deploy the Cluster Operator to your OpenShift or Kubernetes cluster.</p>
<div class="paragraph">
<p>On OpenShift, use the <code>oc apply</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On Kubernetes, use the <code>kubectl apply</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-deploying-co"><a class="link" href="#deploying-cluster-operator-helm-chart-deploying-co">4.1.6. Deploying the Cluster Operator using Helm Chart</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi http://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-reconciliation-deploying-co"><a class="link" href="#con-cluster-operator-reconciliation-deploying-co">4.1.7. Reconciliation</a></h4>
<div class="paragraph">
<p>Although the operator reacts to all notifications about the desired cluster resources received from the OpenShift or Kubernetes cluster,
if the operator is not running, or if a notification is not received for any reason, the desired resources will get out of sync with the state of the running OpenShift or Kubernetes cluster.</p>
</div>
<div class="paragraph">
<p>In order to handle failovers properly, a periodic reconciliation process is executed by the Cluster Operator so that it can compare the state of the desired resources with the current cluster deployments in order to have a consistent state across all of them.
You can set the time interval for the periodic reconciliations using the <a href="#STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></a> variable.</p>
</div>
</div>
<div class="sect3">
<h4 id="ref-operators-cluster-operator-configuration-deploying-co"><a class="link" href="#ref-operators-cluster-operator-configuration-deploying-co">4.1.8. Cluster Operator Configuration</a></h4>
<div class="paragraph">
<p>The Cluster Operator can be configured through the following supported environment variables:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_NAMESPACE</code></dt>
<dd>
<p>A comma-separated list of OpenShift projects or Kubernetes namespaces that the operator should operate in.
When not set, set to empty string, or to <code>*</code> the cluster operator will operate in all OpenShift projects or Kubernetes namespaces.
The Cluster Operator deployment might use the <a href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api" target="_blank" rel="noopener">Kubernetes Downward API</a>
to set this automatically to the namespace the Cluster Operator is deployed in. See the example below:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">env:
  - name: STRIMZI_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1"><a id="STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"></a> <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>Optional, default: 120000 ms. The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>Optional, default <code>INFO</code>.
The level for printing logging messages. The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_OPERATION_TIMEOUT_MS</code></dt>
<dd>
<p>Optional, default: 300000 ms. The timeout for internal operations, in milliseconds. This value should be
increased when using Strimzi on clusters where regular OpenShift or Kubernetes operations take longer than usual (because of slow downloading of Docker images, for example).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_IMAGES</code></dt>
<dd>
<p>Required.
This provides a mapping from Kafka version to the corresponding Docker image containing a Kafka broker of that version.
The required syntax is whitespace or comma separated <code><em>&lt;version&gt;</em>=<em>&lt;image&gt;</em></code> pairs.
For example <code>2.0.0=strimzi/kafka:latest-kafka-2.0.0, 2.1.0=strimzi/kafka:latest-kafka-2.1.0</code>.
This is used when a <code>Kafka.spec.kafka.version</code> property is specified but not the <code>Kafka.spec.kafka.image</code>, as described in <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_INIT_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-init:latest</code>.
The image name to use as default for the init container started before the broker for initial configuration work (that is, rack support), if no image is specified as the <code>kafka-init-image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Kafka,
if no image is specified as the <code>Kafka.spec.kafka.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper:latest</code>.
The image name to use as the default when deploying Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_CONNECT_IMAGES</code></dt>
<dd>
<p>Required.
This provides a mapping from the Kafka version to the corresponding Docker image containing a Kafka connect of that version.
The required syntax is whitespace or comma separated <code><em>&lt;version&gt;</em>=<em>&lt;image&gt;</em></code> pairs.
For example <code>2.0.0=strimzi/kafka:latest-kafka-connect-2.0.0, 2.1.0=strimzi/kafka-connect:latest-kafka-2.1.0</code>.
This is used when a <code>KafkaConnect.spec.version</code> property is specified but not the <code>KafkaConnect.spec.image</code>, as described in <a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_CONNECT_S2I_IMAGES</code></dt>
<dd>
<p>Required.
This provides a mapping from the Kafka version to the corresponding Docker image containing a Kafka connect of that version.
The required syntax is whitespace or comma separated <code><em>&lt;version&gt;</em>=<em>&lt;image&gt;</em></code> pairs.
For example <code>2.0.0=strimzi/kafka:latest-kafka-connect-s2i-2.0.0, 2.1.0=strimzi/kafka-connect-s2i:latest-kafka-2.1.0</code>.
This is used when a <code>KafkaConnectS2I.spec.version</code> property is specified but not the <code>KafkaConnectS2I.spec.image</code>, as described in <a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_MIRROR_MAKER_IMAGES</code></dt>
<dd>
<p>Required.
This provides a mapping from the Kafka version to the corresponding Docker image containing a Kafka mirror maker of that version.
The required syntax is whitespace or comma separated <code><em>&lt;version&gt;</em>=<em>&lt;image&gt;</em></code> pairs.
For example <code>2.0.0=strimzi/kafka-mirror-maker:latest-kafka-2.0.0, 2.1.0=strimzi/kafka-mirror-maker:latest-kafka-2.1.0</code>.
This is used when a <code>KafkaMirrorMaker.spec.version</code> property is specified but not the <code>KafkaMirrorMaker.spec.image</code>, as described in <a href="#assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/topic-operator:latest</code>.
The image name to use as the default when deploying the topic operator,
if no image is specified as the <code>Kafka.spec.entityOperator.topicOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/user-operator:latest</code>.
The image name to use as the default when deploying the user operator,
if no image is specified as the <code>Kafka.spec.entityOperator.userOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/entity-operator-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for the Entity Operator, if
no image is specified as the <code>Kafka.spec.entityOperator.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_IMAGE_PULL_POLICY</code></dt>
<dd>
<p>Optional.
The <code>ImagePullPolicy</code> which will be applied to containers in all pods managed by Strimzi Cluster Operator.
The valid values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>.
If not specified, the OpenShift or Kubernetes defaults will be used.
Changing the policy will result in a rolling update of all your Kafka, Kafka Connect, and Kafka Mirror Maker clusters.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-rbac-deploying-co"><a class="link" href="#con-cluster-operator-rbac-deploying-co">4.1.9. Role-Based Access Control (RBAC)</a></h4>
<div class="sect4">
<h5 id="provisioning_role_based_access_control_rbac_for_the_cluster_operator"><a class="link" href="#provisioning_role_based_access_control_rbac_for_the_cluster_operator">Provisioning Role-Based Access Control (RBAC) for the Cluster Operator</a></h5>
<div class="paragraph">
<p>For the Cluster Operator to function it needs permission within the OpenShift or Kubernetes cluster to interact with resources such as <code>Kafka</code>, <code>KafkaConnect</code>, and so on, as well as the managed resources, such as <code>ConfigMaps</code>, <code>Pods</code>, <code>Deployments</code>, <code>StatefulSets</code>, <code>Services</code>, and so on.
Such permission is described in terms of OpenShift or Kubernetes role-based access control (RBAC) resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ServiceAccount</code>,</p>
</li>
<li>
<p><code>Role</code> and <code>ClusterRole</code>,</p>
</li>
<li>
<p><code>RoleBinding</code> and <code>ClusterRoleBinding</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In addition to running under its own <code>ServiceAccount</code> with a <code>ClusterRoleBinding</code>, the Cluster Operator manages some RBAC resources for the components that need access to OpenShift or Kubernetes resources.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes also includes privilege escalation protections that prevent components operating under one <code>ServiceAccount</code> from granting other <code>ServiceAccounts</code> privileges that the granting <code>ServiceAccount</code> does not have.
Because the Cluster Operator must be able to create the <code>ClusterRoleBindings</code>, and <code>RoleBindings</code> needed by resources it manages, the Cluster Operator must also have those same privileges.</p>
</div>
</div>
<div class="sect4">
<h5 id="delegated-privileges-deploying-co"><a class="link" href="#delegated-privileges-deploying-co">Delegated privileges</a></h5>
<div class="paragraph">
<p>When the Cluster Operator deploys resources for a desired <code>Kafka</code> resource it also creates <code>ServiceAccounts</code>, <code>RoleBindings</code>, and <code>ClusterRoleBindings</code>, as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The Kafka broker pods use a <code>ServiceAccount</code> called <code><em>cluster-name</em>-kafka</code></p>
<div class="ulist">
<ul>
<li>
<p>When the rack feature is used, the <code>strimzi-<em>cluster-name</em>-kafka-init</code> <code>ClusterRoleBinding</code> is used to grant this <code>ServiceAccount</code> access to the nodes within the cluster via a <code>ClusterRole</code> called <code>strimzi-kafka-broker</code></p>
</li>
<li>
<p>When the rack feature is not used no binding is created.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The Zookeeper pods use the default <code>ServiceAccount</code>, as they do not need access to the OpenShift or Kubernetes resources.</p>
</li>
<li>
<p>The Topic Operator pod uses a <code>ServiceAccount</code> called <code><em>cluster-name</em>-topic-operator</code></p>
<div class="ulist">
<ul>
<li>
<p>The Topic Operator produces OpenShift or Kubernetes events with status information, so the <code>ServiceAccount</code> is bound to a <code>ClusterRole</code> called <code>strimzi-topic-operator</code> which grants this access via the <code>strimzi-topic-operator-role-binding</code> <code>RoleBinding</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The pods for <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources use the default <code>ServiceAccount</code>, as they do not require access to the OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect4">
<h5 id="serviceaccount"><a class="link" href="#serviceaccount"><code>ServiceAccount</code></a></h5>
<div class="paragraph">
<p>The Cluster Operator is best run using a <code>ServiceAccount</code>:</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ServiceAccount</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Deployment</code> of the operator then needs to specify this in its <code>spec.template.spec.serviceAccountName</code>:</p>
</div>
<div class="listingblock">
<div class="title">Partial example of <code>Deployment</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
        strimzi.io/kind: cluster-operator
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note line 12, where the the <code>strimzi-cluster-operator</code> <code>ServiceAccount</code> is specified as the <code>serviceAccountName</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="clusterroles"><a class="link" href="#clusterroles"><code>ClusterRoles</code></a></h5>
<div class="paragraph">
<p>The Cluster Operator needs to operate using <code>ClusterRoles</code> that gives access to the necessary resources.
Depending on the OpenShift or Kubernetes cluster setup, a cluster administrator might be needed to create the <code>ClusterRoles</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Cluster administrator rights are only needed for the creation of the <code>ClusterRoles</code>.
The Cluster Operator will not run under the cluster admin account.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <code>ClusterRoles</code> follow the <em>principle of least privilege</em> and contain only those privileges needed by the Cluster Operator to operate Kafka, Kafka Connect, and Zookeeper clusters. The first set of assigned privileges allow the Cluster Operator to manage OpenShift or Kubernetes resources such as <code>StatefulSets</code>, <code>Deployments</code>, <code>Pods</code>, and <code>ConfigMaps</code>.</p>
</div>
<div class="paragraph">
<p>Cluster Operator uses ClusterRoles to grant permission at the namespace-scoped resources level and cluster-scoped resources level:</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with namespaced resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - serviceaccounts
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - rolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkas
  - kafkaconnects
  - kafkaconnects2is
  - kafkamirrormakers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
  - delete
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - deployments
  - deployments/scale
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps
  resources:
  - deployments
  - deployments/scale
  - deployments/status
  - statefulsets
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - extensions
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps.openshift.io
  resources:
  - deploymentconfigs
  - deploymentconfigs/scale
  - deploymentconfigs/status
  - deploymentconfigs/finalizers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - build.openshift.io
  resources:
  - buildconfigs
  - builds
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - watch
  - update
- apiGroups:
  - image.openshift.io
  resources:
  - imagestreams
  - imagestreams/status
  verbs:
  - create
  - delete
  - get
  - list
  - watch
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - extensions
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
  - routes
  - routes/custom-host
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The second includes the permissions needed for cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with cluster-scoped resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
rules:
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - clusterrolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-kafka-broker</code> <code>ClusterRole</code> represents the access needed by the init container in Kafka pods that is used for the rack feature. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to OpenShift or Kubernetes nodes to the Kafka broker pods</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-topic-operator</code> <code>ClusterRole</code> represents the access needed by the Topic Operator. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to events to the Topic Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
rules:
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkatopics
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkausers
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - patch
  - update
  - delete</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="clusterrolebindings"><a class="link" href="#clusterrolebindings"><code>ClusterRoleBindings</code></a></h5>
<div class="paragraph">
<p>The operator needs <code>ClusterRoleBindings</code> and <code>RoleBindings</code> which associates its <code>ClusterRole</code> with its <code>ServiceAccount</code>:
<code>ClusterRoleBindings</code> are needed for <code>ClusterRoles</code> containing cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ClusterRoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoleBindings</code> are also needed for the <code>ClusterRoles</code> needed for delegation:</p>
</div>
<div class="listingblock">
<div class="title">Examples <code>RoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoles</code> containing only namespaced resources are bound using <code>RoleBindings</code> only.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-the-topic-operator-str"><a class="link" href="#deploying-the-topic-operator-str">4.2. Topic Operator</a></h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-deploying"><a class="link" href="#what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</a></h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will delete the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="how-the-topic-operator-works-deploying"><a class="link" href="#how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</a></h4>
<div class="paragraph">
<p>A fundamental problem that the operator has to solve is that there is no single source of truth:
Both the <code>KafkaTopic</code> resource and the topic within Kafka can be modified independently of the operator.
Complicating this, the Topic Operator might not always be able to observe changes at each end in real time (for example, the operator might be down).</p>
</div>
<div class="paragraph">
<p>To resolve this, the operator maintains its own private copy of the information about each topic.
When a change happens either in the Kafka cluster, or in OpenShift or Kubernetes, it looks at both the state of the other system and at its private copy in order to determine what needs to change to keep everything in sync.
The same thing happens whenever the operator starts, and periodically while it is running.</p>
</div>
<div class="paragraph">
<p>For example, suppose the Topic Operator is not running, and a <code>KafkaTopic</code> <code>my-topic</code> gets created.
When the operator starts it will lack a private copy of "my-topic", so it can infer that the <code>KafkaTopic</code> has been created since it was last running.
The operator will create the topic corresponding to "my-topic" and also store a private copy of the metadata for "my-topic".</p>
</div>
<div class="paragraph">
<p>The private copy allows the operator to cope with scenarios where the topic configuration gets changed both in Kafka and in OpenShift or Kubernetes, so long as the changes are not incompatible (for example, both changing the same topic config key, but to different values).
In the case of incompatible changes, the Kafka configuration wins, and the <code>KafkaTopic</code> will be updated to reflect that.</p>
</div>
<div class="paragraph">
<p>The private copy is held in the same ZooKeeper ensemble used by Kafka itself.
This mitigates availability concerns, because if ZooKeeper is not running then Kafka itself cannot run, so the operator will be no less available than it would even if it was stateless.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-deploying"><a class="link" href="#deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</a></h4>
<div class="paragraph">
<p>This procedure describes how to deploy the Topic Operator using the Cluster Operator.
If you want to use the Topic Operator with a Kafka cluster that is not managed by Strimzi, you must deploy the Topic Operator as a standalone component. For more information, see <a href="#deploying-the-topic-operator-standalone-deploying">Deploying the standalone Topic Operator</a>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Ensure that the <code>Kafka.spec.entityOperator</code> object exists in the <code>Kafka</code> resource. This configures the Entity Operator.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  #...
  entityOperator:
    <strong>topicOperator: {}</strong>
    userOperator: {}</code></pre>
</div>
</div>
</li>
<li>
<p>Configure the Topic Operator using the fields described in <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code> schema reference</a>.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-topic-operator-with-resource-requests-limits-deploying"><a class="link" href="#proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource specifying in the <code>Kafka.spec.entityOperator.topicOperator.resources</code> property the resource requests and limits you want the Topic Operator to have.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  # kafka and zookeeper sections...
  topicOperator:
    resources:
      request:
        cpu: "1"
        memory: 500Mi
      limit:
        cpu: "1"
        memory: 500Mi</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the <code>Kafka</code> resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema of the resources object, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-standalone-deploying"><a class="link" href="#deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</a></h4>
<div class="paragraph">
<p>Deploying the Topic Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance is can operate <em>with</em> any Kafka cluster, not necessarily one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the Topic Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>install/topic-operator/05-Deployment-strimzi-topic-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of bootstrap brokers in your Kafka cluster, given as a comma-separated list of <code><em>hostname</em>:<em>port</em></code> pairs.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>hostname</em>:<em>port</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaTopic</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/topic-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the Topic Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Topic Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the environment variables used to configure the Topic Operator, see <a href="#topic-operator-environment-deploying">Topic Operator environment</a>.</p>
</li>
<li>
<p>For more information about getting the Cluster Operator to deploy the Topic Operator for you, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="topic-operator-environment-deploying"><a class="link" href="#topic-operator-environment-deploying">4.2.6. Topic Operator environment</a></h4>
<div class="paragraph">
<p>When deployed standalone the Topic Operator can be configured using environment variables.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The Topic Operator should be configured using the <code>Kafka.spec.entityOperator.topicOperator</code> property when deployed by the Cluster Operator.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_RESOURCE_LABELS</code></dt>
<dd>
<p>The label selector used to identify <code>KafkaTopics</code> to be managed by the operator.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_SESSION_TIMEOUT_MS</code></dt>
<dd>
<p>The Zookeeper session timeout, in milliseconds.
For example, <code>10000</code>.
Default: <code>20000</code> (20 seconds).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code></dt>
<dd>
<p>The list of Kafka bootstrap servers.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_CONNECT</code></dt>
<dd>
<p>The Zookeeper connection information.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TOPIC_METADATA_MAX_ATTEMPTS</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its larger size (that is, many partitions/replicas).
Default <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>The level for printing logging messages.
The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.
Default <code>INFO</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TLS_ENABLED</code></dt>
<dd>
<p>For enabling the TLS support so encrypting the communication with Kafka brokers.
Default <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_LOCATION</code></dt>
<dd>
<p>The path to the truststore containing certificates for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the truststore defined by <code>STRIMZI_TRUSTSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_LOCATION</code></dt>
<dd>
<p>The path to the keystore containing private keys for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the keystore defined by <code>STRIMZI_KEYSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-user-operator-str"><a class="link" href="#assembly-user-operator-str">4.3. User Operator</a></h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-deploying-uo"><a class="link" href="#con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</a></h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo"><a class="link" href="#proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</a></h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-standalone-deploying-uo"><a class="link" href="#proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</a></h4>
<div class="paragraph">
<p>Deploying the User Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance it can operate <em>with</em> any Kafka cluster, not only the one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the User Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>install/user-operator/05-Deployment-strimzi-user-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_CA_CERT_NAME</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to point to an OpenShift or Kubernetes <code>Secret</code> which should contain the public key of the Certificate Authority for signing new user certificates for TLS Client Authentication.
The <code>Secret</code> should contain the public key of the Certificate Authority under the key <code>ca.crt</code>.</p>
</li>
<li>
<p>The <code>STRIMZI_CA_KEY_NAME</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to point to an OpenShift or Kubernetes <code>Secret</code> which should contain the private key of the Certificate Authority for signing new user certificates for TLS Client Authentication.
The <code>Secret</code> should contain the private key of the Certificate Authority under the key <code>ca.key</code>.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>hostname</em>:<em>port</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaUser</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/user-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the User Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The User Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about getting the Cluster Operator to deploy the User Operator for you, see <a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">Deploying the User Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-the-topic-operator-str"><a class="link" href="#using-the-topic-operator-str">5. Using the Topic Operator</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="topic-operator-usage-recommendations-str"><a class="link" href="#topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</a></h3>
<div class="ulist">
<ul>
<li>
<p>Be consistent and always operate on <code>KafkaTopic</code> resources or always operate on topics directly. Avoid routinely using both methods for a given topic.</p>
</li>
<li>
<p>When creating a <code>KafkaTopic</code> resource:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>Choose a name for the <code>KafkaTopic</code> resource that reflects the name of the topic it describes.</p>
</li>
<li>
<p>Ideally the <code>KafkaTopic.metadata.name</code> should be the same as its <code>spec.topicName</code>. To do this, the topic name will have to be a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>When creating a topic:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>It is best to use a name that is a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>, otherwise the operator will have to modify the name when creating the corresponding <code>KafkaTopic</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="creating-a-topic-str"><a class="link" href="#creating-a-topic-str">5.2. Creating a topic</a></h3>
<div class="paragraph">
<p>This procedure describes how to create a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the <code>KafkaTopic</code> to be created</p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 10
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
It is recommended to use a topic name that is a valid OpenShift or Kubernetes resource name. Doing this means that it is not necessary to set the <code>KafkaTopic.spec.topicName</code> property. In any case the <code>KafkaTopic.spec.topicName</code> cannot be changed after creation.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The <code>KafkaTopic.spec.partitions</code> cannot be decreased.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Create the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the standalone Topic Operator, see <a href="#deploying-the-topic-operator-standalone-deploying">Deploying the standalone Topic Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="changing-a-topic-str"><a class="link" href="#changing-a-topic-str">5.3. Changing a topic</a></h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka topic by using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be changed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the desired <code>KafkaTopic</code></p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 16
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
You can get the current version of the resource using <code>oc get kafkatopic orders -o yaml</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Changing topic names using the <code>KafkaTopic.spec.topicName</code> variable and decreasing partition size using the <code>KafkaTopic.spec.partitions</code> variable is not supported by Kafka.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
Increasing <code>spec.partitions</code> for topics with keys will change how records are partitioned, which can be particularly problematic when the topic uses <em>semantic partitioning</em>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Update the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-a-topic-str"><a class="link" href="#deleting-a-topic-str">5.4. Deleting a topic</a></h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkatopic <em>your-topic-name</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkatopic <em>your-topic-name</em></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Whether the topic can actually be deleted depends on the value of the <code>delete.topic.enable</code> Kafka broker configuration, specified in the <code>Kafka.spec.kafka.config</code> property.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-using-the-user-operator-str"><a class="link" href="#assembly-using-the-user-operator-str">6. Using the User Operator</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect2">
<h3 id="con-what-the-user-operator-does-using-uo"><a class="link" href="#con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</a></h3>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect2">
<h3 id="con-mutual-tls-authentication-using-uo"><a class="link" href="#con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</a></h3>
<div class="sect3">
<h4 id="mutual_tls_authentication_2"><a class="link" href="#mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</a></h4>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_mutual_tls_authentication_for_clients_2"><a class="link" href="#when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</a></h4>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-tls-using-uo"><a class="link" href="#proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</a></h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using TLS authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using TLS see <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">Kafka broker listeners</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="con-scram-sha-authentication-using-uo"><a class="link" href="#con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</a></h3>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRAM-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="supported_scram_credentials_2"><a class="link" href="#supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</a></h4>
<div class="paragraph">
<p>Strimzi supports SCRAM-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_scram_sha_authentication_for_clients_2"><a class="link" href="#when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</a></h4>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-scram-using-uo"><a class="link" href="#proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</a></h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using SCRAM SHA authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using SCRAM SHA see <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">Kafka broker listeners</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="proc-changing-kafka-user-using-uo"><a class="link" href="#proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</a></h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka user by using a <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be changed</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the desired <code>KafkaUser</code>.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Update the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the updated credentials from the <code>my-user</code> secret in your application.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-kafka-user-using-uo"><a class="link" href="#deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</a></h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka user created with <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkauser <em>your-user-name</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkauser <em>your-user-name</em></code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="ref-kafka-user-using-uo"><a class="link" href="#ref-kafka-user-using-uo">6.8. Kafka User resource</a></h3>
<div class="paragraph">
<p>The <code>KafkaUser</code> resource is used to declare a user with its authentication mechanism, authorization mechanism, and access rights.</p>
</div>
<div class="sect3">
<h4 id="authentication"><a class="link" href="#authentication">6.8.1. Authentication</a></h4>
<div class="paragraph">
<p>Authentication is configured using the <code>authentication</code> property in <code>KafkaUser.spec</code>.
The authentication mechanism enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authentication mechanisms are the TLS Client Authentication mechanism and the SCRAM-SHA-512 mechanism.</p>
</div>
<div class="paragraph">
<p>When no authentication mechanism is specified, User Operator will not create the user or its credentials.</p>
</div>
<div class="sect4">
<h5 id="tls_client_authentication_5"><a class="link" href="#tls_client_authentication_5">TLS Client Authentication</a></h5>
<div class="paragraph">
<p>To use TLS client authentication, set the <code>type</code> field to <code>tls</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>KafkaUser</code> with enabled TLS Client Authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the user is created by the User Operator, it will create a new secret with the same name as the <code>KafkaUser</code> resource.
The secret will contain a public and private key which should be used for the TLS Client Authentication.
Bundled with them will be the public key of the client certification authority which was used to sign the user certificate.
All keys will be in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example of the <code>Secret</code> with user credentials</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: my-user
  labels:
    strimzi.io/kind: KafkaUser
    strimzi.io/cluster: my-cluster
type: Opaque
data:
  ca.crt: # Public key of the Clients CA
  user.crt: # Public key of the user
  user.key: # Private key of the user</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="scram_sha_512_authentication_4"><a class="link" href="#scram_sha_512_authentication_4">SCRAM-SHA-512 Authentication</a></h5>
<div class="paragraph">
<p>To use SCRAM-SHA-512 authentication mechanism, set the <code>type</code> field to <code>scram-sha-512</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>KafkaUser</code> with enabled SCRAM-SHA-512 authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the user is created by the User Operator, the User Operator will create a new secret with the same name as the <code>KafkaUser</code> resource.
The secret will contain the generated password in the <code>password</code> key.</p>
</div>
<div class="listingblock">
<div class="title">An example of the <code>Secret</code> with user credentials</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: my-user
  labels:
    strimzi.io/kind: KafkaUser
    strimzi.io/cluster: my-cluster
type: Opaque
data:
  password: # Generated password</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="authorization"><a class="link" href="#authorization">6.8.2. Authorization</a></h4>
<div class="paragraph">
<p>Authorization is configured using the <code>authorization</code> property in <code>KafkaUser.spec</code>.
The authorization type enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authorization type is the Simple authorization.</p>
</div>
<div class="paragraph">
<p>When no authorization is specified, the User Operator will not provision any access rights for the user.</p>
</div>
<div class="sect4">
<h5 id="simple_authorization_2"><a class="link" href="#simple_authorization_2">Simple Authorization</a></h5>
<div class="paragraph">
<p>To use Simple Authorization, set the <code>type</code> property to <code>simple</code>.
Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
Simple Authorization allows you to specify list of ACL rules in the <code>acls</code> property.</p>
</div>
<div class="paragraph">
<p>The <code>acls</code> property should contain a list of <code>AclRule</code> objects.
<code>AclRule</code> specifies the access rights whcih will be granted to the user.
The <code>AclRule</code> object contains following properties:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>type</code></dt>
<dd>
<p>Specifies the type of the ACL rule.
The type can be either <code>allow</code> or <code>deny</code>.
The <code>type</code> field is optional and when not specified, the ACL rule will be treated as <code>allow</code> rule.</p>
</dd>
<dt class="hdlist1"><code>operation</code></dt>
<dd>
<p>Specifies the operation which will be allowed or denied.
Following operations are supported:</p>
<div class="ulist">
<ul>
<li>
<p>Read</p>
</li>
<li>
<p>Write</p>
</li>
<li>
<p>Delete</p>
</li>
<li>
<p>Alter</p>
</li>
<li>
<p>Describe</p>
</li>
<li>
<p>All</p>
</li>
<li>
<p>IdempotentWrite</p>
</li>
<li>
<p>ClusterAction</p>
</li>
<li>
<p>Create</p>
</li>
<li>
<p>AlterConfigs</p>
</li>
<li>
<p>DescribeConfigs</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Not every operation can be combined with every resource.
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><code>host</code></dt>
<dd>
<p>Specifies a remote host from which is the rule allowed or denied.
Use <code>*</code> to allow or deny the operation from all hosts.
The <code>host</code> field is optional and when not specified, the value <code>*</code> will be used as default.</p>
</dd>
<dt class="hdlist1"><code>resource</code></dt>
<dd>
<p>Specifies the resource for which the rule applies.
Simple Authorization supports four different resource types:</p>
<div class="ulist">
<ul>
<li>
<p>Topics</p>
</li>
<li>
<p>Consumer Groups</p>
</li>
<li>
<p>Clusters</p>
</li>
<li>
<p>Transactional IDs</p>
<div class="paragraph">
<p>The resource type can be specified in the <code>type</code> property.
Use <code>topic</code> for Topics, <code>group</code> for Consumer Groups, <code>cluster</code> for clusters, and <code>transactionalId</code> for Transactional IDs.</p>
</div>
<div class="paragraph">
<p>Additionally, Topic, Group, and Transactional ID resources allow you to specify the name of the resource for which the rule applies.
The name can be specified in the <code>name</code> property.
The name can be either specified as literal or as a prefix.
To specify the name as literal, set the <code>patternType</code> property to the value <code>literal</code>.
Literal names will be taken exactly as they are specified in the <code>name</code> field.
To specify the name as a prefix, set the <code>patternType</code> property to the value <code>prefix</code>.
Prefix type names will use the value from the <code>name</code> only a prefix and will apply the rule to all resources with names starting with the value.
The cluster type resources have no name.</p>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>For more details about <code>SimpleAclAuthorizer</code>, its ACL rules and the allowed combinations of resources and operations, see <a href="http://kafka.apache.org/documentation/#security_authz" target="_blank" rel="noopener">Authorization and ACLs</a>.</p>
</div>
<div class="paragraph">
<p>For more information about the <code>AclRule</code> object, see <a href="#type-AclRule-reference"><code>AclRule</code> schema reference</a>.</p>
</div>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  # ...
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: prefix
        operation: Read</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="additional_resources_5"><a class="link" href="#additional_resources_5">6.8.3. Additional resources</a></h4>
<div class="ulist">
<ul>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about the TLS Client Authentication, see <a href="#con-mutual-tls-authentication-using-uo">Mutual TLS authentication for clients</a>.</p>
</li>
<li>
<p>For more information about the SASL SCRAM-SHA-512 authentication, see <a href="#con-scram-sha-authentication-using-uo">SCRAM-SHA authentication</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="security-str"><a class="link" href="#security-str">7. Security</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi supports encrypted communication between the Kafka and Strimzi components using the TLS protocol.
Communication between Kafka brokers (interbroker communication), between Zookeeper nodes (internodal communication), and between these and the Strimzi operators is always encrypted.
Communication between Kafka clients and Kafka brokers is encrypted according to how the cluster is configured.
For the Kafka and Strimzi components, TLS certificates are also used for authentication.</p>
</div>
<div class="paragraph">
<p>The Cluster Operator automatically sets up TLS certificates to enable encryption and authentication within your cluster.
It also sets up other TLS certificates if you want to enable encryption or TLS authentication between Kafka brokers and clients.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/secure_communication.png" alt="Secure Communication">
</div>
<div class="title">Figure 3. Example architecture diagram of the communication secured by TLS.</div>
</div>
<div class="sect2">
<h3 id="certificate-authorities-str"><a class="link" href="#certificate-authorities-str">7.1. Certificate Authorities</a></h3>
<div class="paragraph">
<p>To support encryption, each Strimzi component needs its own private keys and public key certificates.
All component certificates are signed by a Certificate Authority (CA) called the <em>cluster CA</em>.</p>
</div>
<div class="paragraph">
<p>Similarly, each Kafka client application connecting using TLS client authentication needs private keys and certificates.
The <em>clients CA</em> is used to sign the certificates for the Kafka clients.</p>
</div>
<div class="sect3">
<h4 id="ca_certificates"><a class="link" href="#ca_certificates">7.1.1. CA certificates</a></h4>
<div class="paragraph">
<p>Each CA has a self-signed public key certificate.</p>
</div>
<div class="paragraph">
<p>Kafka brokers are configured to trust certificates signed by either the clients CA or the cluster CA. Components to which clients do not need to connect, such as Zookeeper, only trust certificates signed by the cluster CA. Client applications that perform mutual TLS authentication have to trust the certificates signed by the cluster CA.</p>
</div>
<div class="paragraph">
<p>By default, Strimzi generates and renews CA certificates automatically. You can configure the management of CA certificates in the <code>Kafka.spec.clusterCa</code> and <code>Kafka.spec.clientsCa</code> objects.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="certificates-and-secrets-str"><a class="link" href="#certificates-and-secrets-str">7.2. Certificates and <code>Secrets</code></a></h3>
<div class="paragraph">
<p>Strimzi stores CA, component and Kafka client private keys and certificates in <code>Secrets</code>.
All keys are 2048 bits in size.</p>
</div>
<div class="paragraph">
<p>CA certificate validity periods, expressed as a number of days after certificate generation, can be configured in <code>Kafka.spec.clusterCa.validityDays</code>
and <code>Kafka.spec.clusterCa.validityDays</code>.</p>
</div>
<div class="sect3">
<h4 id="cluster_ca_secrets"><a class="link" href="#cluster_ca_secrets">7.2.1. Cluster CA <code>Secrets</code></a></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Cluster CA <code>Secrets</code> managed by the Cluster Operator in <em>&lt;cluster&gt;</em></caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-cluster-ca</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current private key for the cluster CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current certificate for the cluster CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-brokers</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-<em>&lt;num&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for Kafka broker pod <em>&lt;num&gt;</em>. Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-<em>&lt;num&gt;</em>.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for Kafka broker pod <em>&lt;num&gt;</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-nodes</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-<em>&lt;num&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for Zookeeper node <em>&lt;num&gt;</em>. Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-<em>&lt;num&gt;</em>.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for Zookeeper pod <em>&lt;num&gt;</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-entity-operator-certs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>entity-operator_.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for TLS communication between the Entity Operator and Kafka or Zookeeper.
                                   Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>entity-operator.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for TLS communication between the Entity Operator and Kafka or Zookeeper</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The CA certificates in <code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> must be trusted by Kafka client applications so that they validate the Kafka broker certificates when connecting to Kafka brokers over TLS.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Only <code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> needs to be used by clients.
All other <code>Secrets</code> in the table above only need to be accessed by the
 Strimzi components.
 You can enforce this using OpenShift or Kubernetes role-based access controls if necessary.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="client_ca_secrets"><a class="link" href="#client_ca_secrets">7.2.2. Client CA <code>Secrets</code></a></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Clients CA <code>Secrets</code> managed by the Cluster Operator in <em>&lt;cluster&gt;</em></caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-clients-ca</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current private key for the clients CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-clients-ca-cert</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current certificate for the clients CA.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The certificates in <code><em>&lt;cluster&gt;</em>-clients-ca-cert</code> are those which the Kafka brokers trust.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code><em>&lt;cluster&gt;</em>-cluster-ca</code> is used to sign certificates of client applications.
It needs to be accessible to the Strimzi components and for administrative access if you are intending to issue application certificates without using the User Operator.
You can enforce this using OpenShift or Kubernetes role-based access controls if necessary.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="user_secrets"><a class="link" href="#user_secrets">7.2.3. User <code>Secrets</code></a></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. <code>Secrets</code> managed by the User Operator</caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;user&gt;</em></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>user.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for the user, signed by the clients CA</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>user.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for the user</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="installing-your-own-ca-certificates-str"><a class="link" href="#installing-your-own-ca-certificates-str">7.3. Installing your own CA certificates</a></h3>
<div class="paragraph">
<p>This procedure describes how to install your own CA certificates and private keys instead of using CA certificates and private keys generated by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A Kafka cluster is not yet deployed.</p>
</li>
<li>
<p>Your own X.509 certificates and keys in PEM format for the cluster CA or clients CA.</p>
<div class="ulist">
<ul>
<li>
<p>If you want to use a cluster or clients CA which is not a Root CA, you have to include the whole chain in the certificate file.
The chain should be in the following order:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The cluster or clients CA</p>
</li>
<li>
<p>One or more intermediate CAs</p>
</li>
<li>
<p>The root CA</p>
</li>
</ol>
</div>
</li>
<li>
<p>All CAs in the chain should be configured as a CA in the X509v3 Basic Constraints.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Put your CA certificate in the corresponding <code>Secret</code> (<code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> for the cluster CA or <code><em>&lt;cluster&gt;</em>-clients-ca-cert</code> for the clients CA):</p>
<div class="paragraph">
<p>On Kubernetes, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete any existing secret (ignore "Not Exists" errors)
kubectl delete secret <em>&lt;ca-cert-secret&gt;</em>
# Create and label the new one
kubectl create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=ca.crt=<em>&lt;ca-cert-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete any existing secret (ignore "Not Exists" errors)
oc delete secret <em>&lt;ca-cert-secret&gt;</em>
# Create the new one
oc create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=ca.crt=<em>&lt;ca-cert-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Put your CA key in the corresponding <code>Secret</code> (<code><em>&lt;cluster&gt;</em>-cluster-ca</code> for the cluster CA or <code><em>&lt;cluster&gt;</em>-clients-ca</code> for the clients CA)</p>
<div class="paragraph">
<p>On Kubernetes, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
kubectl delete secret <em>&lt;ca-key-secret&gt;</em>
# Create the new one
kubectl create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
oc delete secret <em>&lt;ca-key-secret&gt;</em>
# Create the new one
oc create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Label both <code>Secrets</code> with labels <code>strimzi.io/kind=Kafka</code> and <code>strimzi.io/cluster=<em>&lt;my-cluster&gt;</em></code>:</p>
<div class="paragraph">
<p>On Kubernetes, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label secret <em>&lt;ca-cert-secret&gt;</em> strimzi.io/kind=Kafka strimzi.io/cluster=<em>&lt;my-cluster&gt;</em>
kubectl label secret <em>&lt;ca-key-secret&gt;</em> strimzi.io/kind=Kafka strimzi.io/cluster=<em>&lt;my-cluster&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label secret <em>&lt;ca-cert-secret&gt;</em> strimzi.io/kind=Kafka strimzi.io/cluster=<em>&lt;my-cluster&gt;</em>
oc label secret <em>&lt;ca-key-secret&gt;</em> strimzi.io/kind=Kafka strimzi.io/cluster=<em>&lt;my-cluster&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>Kafka</code> resource for your cluster, configuring either the <code>Kafka.spec.clusterCa</code> or the <code>Kafka.spec.clientsCa</code> object to <em>not</em> use generated CAs:</p>
<div class="listingblock">
<div class="title">Example fragment <code>Kafka</code> resource configuring the cluster CA to use certificates you supply for yourself</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kind: Kafka
version: v1alpha1
spec:
  # ...
  clusterCa:
    generateCertificateAuthority: false</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="con-certificate-renewal-str"><a class="link" href="#con-certificate-renewal-str">7.4. Certificate renewal</a></h3>
<div class="paragraph">
<p>The cluster CA and clients CA certificates are only valid for a limited time period, known as the validity period.
This is usually defined as a number of days since the certificate was generated.
For auto-generated CA certificates, you can configure the validity period in <code>Kafka.spec.clusterCa.validityDays</code> and <code>Kafka.spec.clientsCa.validityDays</code>.
The default validity period for both certificates is 365 days.
Manually-installed CA certificates should have their own validity period defined.</p>
</div>
<div class="paragraph">
<p>When a CA certificate expires, components and clients which still trust that certificate will not accept TLS connections from peers whose certificate were signed by the CA private key.
The components and clients need to trust the <em>new</em> CA certificate instead.</p>
</div>
<div class="paragraph">
<p>To allow the renewal of CA certificates without a loss of service, the Cluster Operator will initiate certificate renewal before the old CA certificates expire.
You can configure the renewal period in <code>Kafka.spec.clusterCa.renewalDays</code> and <code>Kafka.spec.clientsCa.renewalDays</code> (both default to 30 days).
The renewal period is measured backwards, from the expiry date of the current certificate.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Not Before                                     Not After
    |                                              |
    |&lt;--------------- validityDays ---------------&gt;|
                              &lt;--- renewalDays ---&gt;|</code></pre>
</div>
</div>
<div class="paragraph">
<p>The behavior of the Cluster Operator during the renewal period depends on whether the relevant setting is enabled, in either <code>Kafka.spec.clusterCa.generateCertificateAuthority</code> or <code>Kafka.spec.clientsCa.generateCertificateAuthority</code>.</p>
</div>
<div class="sect3">
<h4 id="renewal_process_with_generated_cas"><a class="link" href="#renewal_process_with_generated_cas">7.4.1. Renewal process with generated CAs</a></h4>
<div class="paragraph">
<p>The Cluster Operator performs the following process to renew CA certificates:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Generate a new CA certificate, but retaining the existing key. The new certificate replaces the old one with the name <code>ca.crt</code> within the corresponding <code>Secret</code>.</p>
</li>
<li>
<p>Generate new client certificates (for Zookeeper nodes, Kafka brokers, and the Entity Operator).
This is not strictly necessary because the signing key has not changed, but it keeps the validity period of the client certificate in sync with the CA certificate.</p>
</li>
<li>
<p>Restart Zookeeper nodes so that they will trust the new CA certificate and use the new client certificates.</p>
</li>
<li>
<p>Restart Kafka brokers so that they will trust the new CA certificate and use the new client certificates.</p>
</li>
<li>
<p>Restart the Topic and User Operators so that they will trust the new CA certificate and use the new client certificates.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="client_applications"><a class="link" href="#client_applications">7.4.2. Client applications</a></h4>
<div class="paragraph">
<p>The Cluster Operator is not aware of all the client applications using the Kafka cluster.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Depending on how your applications are configured, you might need take action to ensure they continue working after certificate renewal.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Consider the following important points to ensure that client applications continue working.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>When they connect to the cluster, client applications must trust the cluster CA certificate published in <em>&lt;cluster&gt;</em>-cluster-ca-cert.</p>
</li>
<li>
<p>When using the User Operator to provision client certificates, client applications must use the current <code>user.crt</code> and <code>user.key</code> published in their <code><em>&lt;user&gt;</em></code> <code>Secret</code> when they connect to the cluster.
For workloads running inside the same OpenShift or Kubernetes cluster this can be achieved by mounting the secrets as a volume and having the client Pods construct their key- and truststores from the current state of the <code>Secrets</code>.
For more details on this procedure, see <a href="#configuring-internal-clients-to-trust-cluster-ca-str">Configuring internal clients to trust the cluster CA</a>.</p>
</li>
<li>
<p>When renewing client certificates, if you are provisioning client certificates and keys manually, you must generate new client certificates and ensure the new certificates are used by clients within the renewal period. Failure to do this by the end of the renewal period could result in client applications being unable to connect.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="tls-connections-str"><a class="link" href="#tls-connections-str">7.5. TLS connections</a></h3>
<div class="sect3">
<h4 id="zookeeper_communication"><a class="link" href="#zookeeper_communication">7.5.1. Zookeeper communication</a></h4>
<div class="paragraph">
<p>Zookeeper does not support TLS itself.
By deploying an <code>stunnel</code> sidecar within every Zookeeper pod, the Cluster Operator is able to provide data encryption and authentication between Zookeeper nodes in a cluster.
Zookeeper communicates only with the <code>stunnel</code> sidecar over the loopback interface.
The <code>stunnel</code> sidecar then proxies all Zookeeper traffic, TLS decrypting data upon entry into a Zookeeper pod and TLS encrypting data upon departure from a Zookeeper pod.</p>
</div>
<div class="paragraph">
<p>This TLS encrypting <code>stunnel</code> proxy is instantiated from the <code>spec.zookeeper.stunnelImage</code> specified in the Kafka resource.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka_interbroker_communication"><a class="link" href="#kafka_interbroker_communication">7.5.2. Kafka interbroker communication</a></h4>
<div class="paragraph">
<p>Communication between Kafka brokers is done through the <code>REPLICATION</code> listener on port 9091, which is encrypted by default.</p>
</div>
<div class="paragraph">
<p>Communication between Kafka brokers and Zookeeper nodes uses an <code>stunnel</code> sidecar, as described above.</p>
</div>
</div>
<div class="sect3">
<h4 id="topic_and_user_operators"><a class="link" href="#topic_and_user_operators">7.5.3. Topic and User Operators</a></h4>
<div class="literalblock">
<div class="content">
<pre>Like the Cluster Operator, the Topic and User Operators each use an `stunnel` sidecar when communicating with Zookeeper.
The Topic Operator connects to Kafka brokers on port 9091.</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="kafka_client_connections"><a class="link" href="#kafka_client_connections">7.5.4. Kafka Client connections</a></h4>
<div class="paragraph">
<p>Encrypted communication between Kafka brokers and clients running within the same OpenShift or Kubernetes cluster is provided through the <code>CLIENTTLS</code> listener on port 9093.</p>
</div>
<div class="paragraph">
<p>Encrypted communication between Kafka brokers and clients running outside the same OpenShift or Kubernetes cluster is provided through the <code>EXTERNAL</code> listener on port 9094.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
You can use the <code>CLIENT</code> listener on port 9092 for unencrypted communication with brokers.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="configuring-internal-clients-to-trust-cluster-ca-str"><a class="link" href="#configuring-internal-clients-to-trust-cluster-ca-str">7.6. Configuring internal clients to trust the cluster CA</a></h3>
<div class="paragraph">
<p>This procedure describes how to configure a Kafka client that resides inside the OpenShift or Kubernetes cluster  connecting to the <code>tls</code> listener on port 9093  to trust the cluster CA certificate.</p>
</div>
<div class="paragraph">
<p>The easiest way to achieve this for an internal client is to use a volume mount to access the <code>Secrets</code> containing the necessary certificates and keys.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource within the OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>A Kafka client application inside the OpenShift or Kubernetes cluster which will connect using TLS and needs to trust the cluster CA certificate.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>When defining the client <code>Pod</code></p>
</li>
<li>
<p>The Kafka client has to be configured to trust certificates signed by this CA.
For the Java-based Kafka Producer, Consumer, and Streams APIs, you can do this by importing the CA certificate into the JVM&#8217;s truststore using the following <code>keytool</code> command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">keytool -keystore client.truststore.jks -alias CARoot -import -file ca.crt</code></pre>
</div>
</div>
</li>
<li>
<p>To configure the Kafka client, specify the following properties:</p>
<div class="ulist">
<ul>
<li>
<p><code>security.protocol: SSL</code> when using TLS for encryption (with or without TLS authentication), or <code>security.protocol: SASL_SSL</code> when using SCRAM-SHA authentication over TLS.</p>
</li>
<li>
<p><code>ssl.truststore.location</code>: the truststore location where the certificates were imported.</p>
</li>
<li>
<p><code>ssl.truststore.password</code>: the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For the procedure for configuring external clients to trust the cluster CA, see <a href="#configuring-external-clients-to-trust-cluster-ca-str">Configuring external clients to trust the cluster CA</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="configuring-external-clients-to-trust-cluster-ca-str"><a class="link" href="#configuring-external-clients-to-trust-cluster-ca-str">7.7. Configuring external clients to trust the cluster CA</a></h3>
<div class="paragraph">
<p>This procedure describes how to configure a Kafka client that resides outside the OpenShift or Kubernetes cluster  connecting to the <code>external</code> listener on port 9094  to trust the cluster CA certificate.</p>
</div>
<div class="paragraph">
<p>You can use the same procedure to configure clients inside OpenShift or Kubernetes, which connect to the <code>tls</code> listener on port 9093, but it is usually more convenient to access the <code>Secrets</code> using a volume mount in the client <code>Pod</code>.</p>
</div>
<div class="paragraph">
<p>Follow this procedure when setting up the client and during the renewal period, when the old clients CA certificate is replaced.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The <code><em>&lt;cluster-name&gt;</em>-cluster-ca-cert</code> <code>Secret</code> will contain more than one CA certificate during CA certificate renewal. Clients must add <em>all</em> of them to their truststores.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource within the OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>A Kafka client application outside the OpenShift or Kubernetes cluster which will connect using TLS and needs to trust the cluster CA certificate.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Extract the cluster CA certificate from the generated <code><em>&lt;cluster-name&gt;</em>-cluster-ca-cert</code> <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes, run the following command to extract the certificates:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>&lt;cluster-name&gt;</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following command to extract the certificates:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>&lt;cluster-name&gt;</em>-cluster-ca-cert --keys ca.crt</code></pre>
</div>
</div>
</li>
<li>
<p>The Kafka client has to be configured to trust certificates signed by this CA.
For the Java-based Kafka Producer, Consumer, and Streams APIs, you can do this by importing the CA certificates into the JVM&#8217;s truststore using the following <code>keytool</code> command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">keytool -keystore client.truststore.jks -alias CARoot -import -file ca.crt</code></pre>
</div>
</div>
</li>
<li>
<p>To configure the Kafka client, specify the following properties:</p>
<div class="ulist">
<ul>
<li>
<p><code>security.protocol: SSL</code> when using TLS for encryption (with or without TLS authentication), or <code>security.protocol: SASL_SSL</code> when using SCRAM-SHA authentication over TLS.</p>
</li>
<li>
<p><code>ssl.truststore.location</code>: the truststore location where the certificates were imported.</p>
</li>
<li>
<p><code>ssl.truststore.password</code>: the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For the procedure for configuring internal clients to trust the cluster CA, see <a href="#configuring-internal-clients-to-trust-cluster-ca-str">Configuring internal clients to trust the cluster CA</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-upgrade-str"><a class="link" href="#assembly-upgrade-str">8. Strimzi and Kafka upgrades</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Each version of Strimzi supports a range of versions of Apache Kafka.
You can upgrade to a higher Kafka version as long as that version is supported by your version of Strimzi.
In some cases, you can also downgrade to a lower supported Kafka version.</p>
</div>
<div class="paragraph">
<p>When a newer version of Strimzi is available, it may provide support for newer versions of Kafka.
Therefore, you will need to upgrade to the new version of Strimzi before you can upgrade to a higher supported Kafka version.
Upgrading the version of Strimzi is done by upgrading the Cluster Operator deployment to the new version.</p>
</div>
<div class="sect2">
<h3 id="proc-upgrading-the-cluster-operator-0-10-0-to-0-11-0-str"><a class="link" href="#proc-upgrading-the-cluster-operator-0-10-0-to-0-11-0-str">8.1. Upgrading the Cluster Operator from 0.10.0 to 0.11.0</a></h3>
<div class="paragraph">
<p>This procedure will describe how to upgrade a Cluster Operator deployment from version 0.10.0 to version 0.11.0.
The availability of Kafka clusters managed by the Cluster Operator is not affected by the upgrade operation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing version 0.10.0 Cluster Operator deployment to be upgraded.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Backup the existing Cluster Operator resources.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubectl get all -l app=strimzi &gt; strimzi-backup.yaml</pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>oc get -l all app=strimzi &gt; strimzi-backup.yaml</pre>
</div>
</div>
</li>
<li>
<p>Update the Cluster Operator.
You will need to modify the installation files according to the namespace the Cluster Operator is running in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you modified one or more environment variables in your existing Cluster Operator <code>Deployment</code>, edit
<code>install/cluster-operator/050-Deployment-cluster-operator.yaml</code> to reflect the changes that you made.</p>
</div>
</li>
<li>
<p>When you have an updated configuration you can deploy it along with the rest of the install resources.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubectl apply -f install/cluster-operator</pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>oc apply -f install/cluster-operator</pre>
</div>
</div>
<div class="paragraph">
<p>Wait for the associated rolling updates to complete.</p>
</div>
</li>
<li>
<p>Update existing resources to cope with deprecated custom resource properties.</p>
<div class="ulist">
<ul>
<li>
<p>If you have <code>Kafka</code> resources that specify <code>Kafka.spec.topicOperator</code>, rewrite them to use <code>Kafka.spec.entityOperator.topicOperator</code> instead.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="proc-upgrading-the-cluster-operator-str"><a class="link" href="#proc-upgrading-the-cluster-operator-str">8.2. Upgrading the Cluster Operator from 0.9.0 to 0.10.0</a></h3>
<div class="paragraph">
<p>This procedure will describe how to upgrade a Cluster Operator deployment from version 0.9.x to version 0.10.0.
The availability of Kafka clusters managed by the Cluster Operator is not affected by the upgrade operation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing version 0.9.0 Cluster Operator deployment to be upgraded.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Update your existing <code>Kafka</code>, <code>KafkaConnect</code>, <code>KafkaConnectS2I</code>, and <code>KafkaMirrorMaker</code> resources, as follows:</p>
<div class="ulist">
<ul>
<li>
<p>Add <code>Kafka.spec.kafka.version</code> with the value <code>2.0.1</code></p>
</li>
<li>
<p>Add <code>KafkaConnect.spec.version</code> with the value <code>2.0.1</code></p>
</li>
<li>
<p>Add <code>KafkaConnectS2I.spec.version</code> with the value <code>2.0.1</code></p>
</li>
<li>
<p>Add <code>KafkaMirrorMaker.spec.version</code> with the value <code>2.0.1</code></p>
<div class="paragraph">
<p>Wait for the associated rolling updates to complete.</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Backup the existing Cluster Operator resources.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubectl get all -l app=strimzi &gt; strimzi-backup.yaml</pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>oc get all -l app=strimzi &gt; strimzi-backup.yaml</pre>
</div>
</div>
</li>
<li>
<p>Update the Cluster Operator.
You will need to modify the installation files according to the namespace the Cluster Operator is running in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you modified one or more environment variables in your existing Cluster Operator <code>Deployment</code>, edit
<code>install/cluster-operator/050-Deployment-cluster-operator.yaml</code> to reflect the changes that you made.</p>
</div>
</li>
<li>
<p>When you have an updated configuration you can deploy it along with the rest of the install resources.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubectl apply -f install/cluster-operator</pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>oc apply -f install/cluster-operator</pre>
</div>
</div>
<div class="paragraph">
<p>Wait for the associated rolling updates to complete.</p>
</div>
</li>
<li>
<p>Update existing resources to cope with deprecated custom resource properties.</p>
<div class="ulist">
<ul>
<li>
<p>If you have <code>Kafka</code> resources that specify <code>Kafka.spec.topicOperator</code>, rewrite them to use <code>Kafka.spec.entityOperator.topicOperator</code> instead.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="assembly-upgrading-kafka-versions-str"><a class="link" href="#assembly-upgrading-kafka-versions-str">8.3. Upgrading and downgrading Kafka versions</a></h3>
<div class="sect3">
<h4 id="con-versions-and-images-str"><a class="link" href="#con-versions-and-images-str">8.3.1. Versions and images overview</a></h4>
<div class="paragraph">
<p>The Cluster Operator embeds knowledge of different Kafka versions, but not of the corresponding images in which those versions are provided.
Using the <code>STRIMZI_KAFKA_IMAGES</code> environment variable, the Cluster Operator is configured with a mapping between the Kafka version and the image to be used when that version is requested in a given <code>Kafka</code> resource.</p>
</div>
<div class="paragraph">
<p>Each <code>Kafka</code> resource can be configured with a <code>Kafka.spec.kafka.version</code>.
If <code>Kafka.spec.kafka.image</code> is not configured then the default image for the given version will be used.
If <code>Kafka.spec.kafka.image</code> is given, this overrides the default.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
The Cluster Operator cannot validate that an image actually contains a Kafka broker of the expected version.
Take care to ensure that the given image corresponds to the given Kafka version.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="con-kafka-upgrades-using-cluster-operator-str"><a class="link" href="#con-kafka-upgrades-using-cluster-operator-str">8.3.2. Kafka upgrades using the Cluster Operator</a></h4>
<div class="paragraph">
<p>How the Cluster Operator will perform an upgrade depends on the differences between:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The interbroker protocol version of the two Kafka versions</p>
</li>
<li>
<p>The log message format version of the two Kafka versions</p>
</li>
<li>
<p>The version of Zookeeper used by the two Kafka versions</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When each of these versions is the same, as is typically the case for a patch level upgrade (for example 2.0.0 to 2.0.1), then the Cluster Operator can perform the upgrade using a single rolling update of the Kafka brokers.
When one or more of these versions differ, the Cluster Operator will require two or three rolling updates of the Kafka brokers to perform the upgrade.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-upgrading-brokers-newer-kafka-0-9-0-to-0-10-0-str"><a class="link" href="#proc-upgrading-brokers-newer-kafka-0-9-0-to-0-10-0-str">8.3.3. Upgrading brokers to a newer Kafka version</a></h4>
<div class="paragraph">
<p>This procedure describes how to upgrade a Strimzi Kafka cluster from one version to a higher version; for example 2.0.0 to 2.1.0.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator, which supports both versions of Kafka, is up and running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be upgraded.</p>
</li>
<li>
<p>You have checked that your <code>Kafka.spec.kafka.config</code> contains no options that are not supported in the version of Kafka that you are upgrading to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Consult the table below and determine whether the new Kafka version has a different log message format version than the previous version.</p>
</li>
</ol>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kafka version</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Interbroker protocol version</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Log message format version</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Zookeeper version</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.4.13</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.4.13</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.4.13</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>+
If the log message format versions are the same proceed to the next step.
Otherwise, ensure the <code>Kafka.spec.kafka.config</code> has the <code>log.message.format.version</code> configured to the default for the previous version.</p>
</div>
<div class="paragraph">
<p>+
For example, if upgrading from 2.0.0:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1alpha1
kind: Kafka
spec:
  # ...
  kafka:
    version: 2.0.0
    config:
      log.message.format.version: "2.0"
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>+
NOTE: You must format the value of <code>log.message.format.version</code> as a string to prevent it from being interpreted as a number.</p>
</div>
<div class="paragraph">
<p>+
If <code>log.message.format.version</code> is unset then set it and wait for the resulting rolling restart of the Kafka cluster to complete.</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="olist arabic">
<ol class="arabic" start="2">
<li>
<p>Change the <code>Kafka.spec.kafka.version</code> to specify the new version, but leave the <code>log.message.format.version</code> as the previous version.
If the image to be used is different from the image for the given version of Kafka configured in the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> then configure the <code>Kafka.spec.kafka.image</code> as well.</p>
<div class="paragraph">
<p>For example, if upgrading from Kafka 2.0.0 to 2.1.0:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1alpha1
kind: Kafka
spec:
  # ...
  kafka:
    version: 2.1.0 <b class="conum">(1)</b>
    config:
      log.message.format.version: "2.0" <b class="conum">(2)</b>
      # ...</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>This is changed to the new version</p>
</li>
<li>
<p>This remains at the previous version</p>
</li>
</ol>
</div>
</li>
<li>
<p>Wait for the Cluster Operator to upgrade the cluster.
If the old and new versions of Kafka have different interbroker protocol versions, look in the Cluster Operator logs for an <code>INFO</code> level message in the following format:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Reconciliation #<em>&lt;num&gt;</em>(watch) Kafka(<em>&lt;namespace&gt;</em>/<em>&lt;name&gt;</em>): Kafka version upgrade from <em>&lt;from-version&gt;</em> to <em>&lt;to-version&gt;</em>, phase 2 of 2 completed</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, if the old and new versions of Kafka have the same interbroker protocol version, look in the Cluster Operator logs for an <code>INFO</code> level message  in the following format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Reconciliation #<em>&lt;num&gt;</em>(watch) Kafka(<em>&lt;namespace&gt;</em>/<em>&lt;name&gt;</em>): Kafka version upgrade from <em>&lt;from-version&gt;</em> to <em>&lt;to-version&gt;</em>, phase 1 of 1 completed</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, using <code>grep</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc logs -f <em>&lt;cluster-operator-pod-name&gt;</em> | grep -E "Kafka version upgrade from [0-9.]+ to [0-9.]+, phase ([0-9]+) of \1 completed"</code></pre>
</div>
</div>
</li>
<li>
<p>Upgrade all your client applications to use the new version of the client libraries.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
You cannot downgrade after completing this step. If, for whatever reason, you need to revert the update at this point, follow the procedure <a href="#proc-downgrading-brokers-older-kafka-str">Downgrading brokers to an older Kafka version</a>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>If the log message format versions, as identified in step 1, are the same proceed to the next step.
Otherwise change the <code>log.message.format.version</code> in <code>Kafka.spec.kafka.config</code> to the default version for the new version of Kafka now being used.
For example, if upgrading to 2.1.0:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1alpha1
kind: Kafka
spec:
  # ...
  kafka:
    version: 2.1.0
    config:
      log.message.format.version: "2.1"
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Wait for the Cluster Operator to update the cluster.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>See <a href="#proc-downgrading-brokers-older-kafka-str">Downgrading brokers to an older Kafka version</a> for the procedure to downgrade a Strimzi Kafka cluster from one version to a lower version, for example 2.0.1 to 2.0.0.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-kafka-downgrades-using-cluster-operator-str"><a class="link" href="#con-kafka-downgrades-using-cluster-operator-str">8.3.4. Kafka downgrades using the Cluster Operator</a></h4>
<div class="paragraph">
<p>Whether and how the Cluster Operator will perform a downgrade depends on the differences between:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The interbroker protocol version of the two Kafka versions</p>
</li>
<li>
<p>The log message format version of the two Kafka versions</p>
</li>
<li>
<p>The version of Zookeeper used by the two Kafka versions</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If the downgraded version of Kafka has the same log message format version then downgrading is always possible.
In this case the Cluster Operator will be able to downgrade by performing a single rolling restart of the brokers.</p>
</div>
<div class="paragraph">
<p>If the downgraded version of Kafka has a different log message format version, then downgrading is only possible if the running cluster has
<em>always</em> had <code>log.message.format.version</code> set to the version used by the downgraded version.
This is typically only the case when the upgrade procedure has been aborted before the <code>log.message.format.version</code> was changed.
In this case the downgrade will require two rolling restarts of the brokers if the interbroker protocol of the two versions is different, or a single rolling restart if they are the same.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-downgrading-brokers-older-kafka-str"><a class="link" href="#proc-downgrading-brokers-older-kafka-str">8.3.5. Downgrading brokers to an older Kafka version</a></h4>
<div class="paragraph">
<p>You can downgrade a Strimzi Kafka cluster from one version to a lower version; for example, from 2.1.0 to 2.0.0.</p>
</div>
<div class="paragraph">
<p>In this procedure the term <em>previous version</em> means the version being downgraded <em>to</em> (such as 2.0.0), and the term <em>new version</em> means the version being downgraded <em>from</em> (such as 2.1.0).</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Downgrading is not possible if the version being downgraded <em>from</em> has ever used a <code>log.message.format.version</code> that is not supported by the version being downgraded <em>to</em> (including where the default value for <code>log.message.format.version</code> is used).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1alpha1
kind: Kafka
spec:
  # ...
  kafka:
    version: 2.1.0
    config:
      log.message.format.version: "2.0"
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>This resource can be downgraded to Kafka version 2.0.0 because the <code>log.message.format.version</code> has not been changed.
If the <code>log.message.format.version</code> were absent (so that the parameter took its default value for a 2.1.0 broker of 2.1), or was <code>"2.1"</code> then downgrade would not be possible.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is up and running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be downgraded.</p>
</li>
<li>
<p>The <code>Kafka.spec.kafka.config</code> has a <code>log.message.format.version</code> that is supported by the version being downgraded to.</p>
</li>
<li>
<p>You have checked that your <code>Kafka.spec.kafka.config</code> contains no options which are not supported in the version of Kafka being downgraded to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Change the <code>Kafka.spec.kafka.version</code> to specify the version being downgraded <em>to</em>.
If the image to be used is different from the image for the given version of Kafka configured in the Cluster Operator&#8217;s <code>STRIMZI_KAFKA_IMAGES</code> then configure the <code>Kafka.spec.kafka.image</code> as well.</p>
<div class="paragraph">
<p>For example, if downgrading from Kafka 2.1.0 to 2.0.0:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1alpha1
kind: Kafka
spec:
  # ...
  kafka:
    version: 2.0.0 <b class="conum">(1)</b>
    config:
      log.message.format.version: "2.0" <b class="conum">(2)</b>
      # ...</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>This is changed to the downgraded version</p>
</li>
<li>
<p>This is unchanged</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
It is necessary to format the value of <code>log.message.format.version</code> as a string to prevent it being interpreted as a number.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Wait for the Cluster Operator to downgrade the cluster.
If both the previous and new versions of Kafka have a different interbroker protocol version look in the Cluster Operator logs for an <code>INFO</code> level message  in the following format:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Reconciliation #<em>&lt;num&gt;</em>(watch) Kafka(<em>&lt;namespace&gt;</em>/<em>&lt;name&gt;</em>): Kafka version downgrade from <em>&lt;from-version&gt;</em> to <em>&lt;to-version&gt;</em>, phase 2 of 2 completed</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, if both the previous and new versions of Kafka have the same interbroker protocol version look in the Cluster Operator logs for an <code>INFO</code> level message in the following format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Reconciliation #<em>&lt;num&gt;</em>(watch) Kafka(<em>&lt;namespace&gt;</em>/<em>&lt;name&gt;</em>): Kafka version downgrade from <em>&lt;from-version&gt;</em> to <em>&lt;to-version&gt;</em>, phase 1 of 1 completed</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, using <code>grep</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc logs -f <em>&lt;cluster-operator-pod-name&gt;</em> | grep -E "Kafka version downgrade from [0-9.]+ to [0-9.]+, phase ([0-9]+) of \1 completed"</code></pre>
</div>
</div>
</li>
<li>
<p>Downgrade each client application to use the previous version of the client libraries.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="frequently_asked_questions"><a class="link" href="#frequently_asked_questions">Appendix A: Frequently Asked Questions</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="cluster_operator"><a class="link" href="#cluster_operator">A.1. Cluster Operator</a></h3>
<div class="sect3">
<h4 id="why_do_i_need_cluster_admin_privileges_to_install_strimzi"><a class="link" href="#why_do_i_need_cluster_admin_privileges_to_install_strimzi">A.1.1. Why do I need cluster admin privileges to install Strimzi?</a></h4>
<div class="paragraph">
<div class="title">Additional resources</div>
<p>To install Strimzi, you must have the ability to create Custom Resource Definitions (CRDs).
CRDs instruct OpenShift or Kubernetes about resources that are specific to Strimzi, such as Kafka, KafkaConnect, and so on.
Because CRDs are a cluster-scoped resource rather than being scoped to a particular OpenShift or Kubernetes namespace, they typically require cluster admin privileges to install.</p>
</div>
<div class="paragraph">
<p>In addition, you must also have the ability to create ClusterRoles and ClusterRoleBindings. Like CRDs, these are cluster-scoped resources that typically require cluster admin privileges.</p>
</div>
<div class="paragraph">
<p>The cluster administrator can inspect all the resources being installed (in the <code>/install/</code> directory) to assure themselves that the <code>ClusterRoles</code> do not grant unnecessary privileges. For more information about why the Cluster Operator installation resources grant the ability to create <code>ClusterRoleBindings</code> see the following question.</p>
</div>
<div class="paragraph">
<p>After installation, the Cluster Operator will run as a regular <code>Deployment</code>; any non-admin user with privileges to access the <code>Deployment</code> can configure it.</p>
</div>
<div id="normal-user-access-custom-resources-str" class="paragraph">
<p>By default, normal users will not have the privileges necessary to manipulate the custom resources, such as <code>Kafka</code>, <code>KafkaConnect</code> and so on, which the Cluster Operator deals with.
These privileges can be granted using normal RBAC resources by the cluster administrator. See <a href="#assembly-getting-started-strimzi-admin-str">this procedure</a> for more details of how to do this.</p>
</div>
</div>
<div class="sect3">
<h4 id="why_does_the_cluster_operator_require_the_ability_to_create_clusterrolebindings_is_that_not_a_security_risk"><a class="link" href="#why_does_the_cluster_operator_require_the_ability_to_create_clusterrolebindings_is_that_not_a_security_risk">A.1.2. Why does the Cluster Operator require the ability to create <code>ClusterRoleBindings</code>? Is that not a security risk?</a></h4>
<div class="paragraph">
<p>OpenShift or Kubernetes has built-in <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#privilege-escalation-prevention-and-bootstrapping" target="_blank" rel="noopener">privilege escalation prevention</a>.
That means that the Cluster Operator cannot grant privileges it does not have itself.
Which in turn means that the Cluster Operator needs to have the privileges necessary for <em>all</em> the components it orchestrates.</p>
</div>
<div class="paragraph">
<p>In the context of this question there are two places where the Cluster Operator needs to create bindings to <code>ClusterRoleBindings</code> to <code>ServiceAccounts</code>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The Topic Operator and User Operator need to be able to manipulate <code>KafkaTopics</code> and <code>KafkaUsers</code>, respectively.
The Cluster Operator therefore needs to be able to grant them this access, which it does by creating a <code>Role</code> and <code>RoleBinding</code>.
For this reason the Cluster Operator itself needs to be able to create <code>Roles</code> and <code>RoleBindings</code> in the namespace that those operators will run in.
However, because of the privilege escalation prevention, the Cluster Operator cannot grant privileges it does not have itself (in particular it cannot grant such privileges in namespace it cannot access).</p>
</li>
<li>
<p>When using rack-aware partition assignment, Strimzi needs to be able to discover the failure domain (for example, the Availability Zone in AWS) of the node on which a broker pod is assigned.
To do this the broker pod needs to be able to get information about the <code>Node</code> it is running on.
A <code>Node</code> is a cluster-scoped resource, so access to it can only be granted via a <code>ClusterRoleBinding</code> (not a namespace-scoped <code>RoleBinding</code>).
Therefore the Cluster Operator needs to be able to create <code>ClusterRoleBindings</code>.
But again, because of privilege escalation prevention, the Cluster Operator cannot grant privileges it does not have itself (so it cannot, for example, create a <code>ClusterRoleBinding</code> to a <code>ClusterRole</code> to grant privileges that the Cluster Operator does not not already have).</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="why_can_standard_openshift_or_kubernetes_users_not_create_the_custom_resource_kafka_kafkatopic_and_so_on"><a class="link" href="#why_can_standard_openshift_or_kubernetes_users_not_create_the_custom_resource_kafka_kafkatopic_and_so_on">A.1.3. Why can standard OpenShift or Kubernetes users not create the custom resource (<code>Kafka</code>, <code>KafkaTopic</code>, and so on)?</a></h4>
<div class="paragraph">
<p>Because, when they installed Strimzi, the OpenShift or Kubernetes cluster administrator did not grant the necessary privileges to standard users.</p>
</div>
<div class="paragraph">
<p>See <a href="#normal-user-access-custom-resources-str">this FAQ answer</a> for more details.</p>
</div>
</div>
<div class="sect3">
<h4 id="log_contains_warnings_about_failing_to_acquire_lock"><a class="link" href="#log_contains_warnings_about_failing_to_acquire_lock">A.1.4. Log contains warnings about failing to acquire lock</a></h4>
<div class="paragraph">
<p>For each cluster, the Cluster Operator always executes only one operation at a time. The Cluster Operator uses locks
to make sure that there are never two parallel operations running for the same cluster. In case an operation requires
more time to complete, other operations will wait until it is completed and the lock is released.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">INFO</dt>
<dd>
<p>Examples of cluster operations are <em>cluster creation</em>, <em>rolling update</em>, <em>scale down</em> or <em>scale up</em> and so on.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>If the wait for the lock takes too long, the operation times out and the following warning message will be printed to
the log:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">2018-03-04 17:09:24 WARNING AbstractClusterOperations:290 - Failed to acquire lock for kafka cluster lock::kafka::myproject::my-cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p>Depending on the exact configuration of <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code> and <code>STRIMZI_OPERATION_TIMEOUT_MS</code>, this
warning message may appear regularly without indicating any problems. The operations which time out will be picked up by
the next periodic reconciliation. It will try to acquire the lock again and execute.</p>
</div>
<div class="paragraph">
<p>Should this message appear periodically even in situations when there should be no other operations running for a given
cluster, it might indicate that due to some error the lock was not properly released. In such cases it is recommended to
restart the cluster operator.</p>
</div>
</div>
<div class="sect3">
<h4 id="hostname_verification_fails_when_connecting_to_nodeports_using_tls"><a class="link" href="#hostname_verification_fails_when_connecting_to_nodeports_using_tls">A.1.5. Hostname verification fails when connecting to NodePorts using TLS</a></h4>
<div class="paragraph">
<p>Currently, off-cluster access using NodePorts with TLS encryption enabled does not support TLS hostname verification.
As a result, the clients that verify the hostname will fail to connect.
For example, the Java client will fail with the following exception:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 168.72.15.231 found
    at sun.security.util.HostnameChecker.matchIP(HostnameChecker.java:168)
    at sun.security.util.HostnameChecker.match(HostnameChecker.java:94)
    at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:455)
    at sun.security.ssl.X509TrustManagerImpl.checkIdentity(X509TrustManagerImpl.java:436)
    at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:252)
    at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:136)
    at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1501)
    ... 17 more</code></pre>
</div>
</div>
<div class="paragraph">
<p>To connect, you must disable hostname verification.
In the Java client, you can do this by setting the configuration option <code>ssl.endpoint.identification.algorithm</code> to an empty string.</p>
</div>
<div class="paragraph">
<p>When configuring the client using a properties file, you can do it this way:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="paragraph">
<p>When configuring the client directly in Java, set the configuration option to an empty string:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">props.put("ssl.endpoint.identification.algorithm", "");</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installing_kubernetes_and_openshift_cluster"><a class="link" href="#installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>The easiest way to get started with OpenShift or Kubernetes is using the <code>Minikube</code>, <code>Minishift</code> or <code>oc cluster up</code>
utilities. This section provides basic guidance on how to use them. More details are provided on the websites of
the tools themselves.</p>
</div>
<div class="sect2">
<h3 id="kubernetes"><a class="link" href="#kubernetes">B.1. Kubernetes</a></h3>
<div class="paragraph">
<p>In order to interact with a Kubernetes cluster the <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"><code>kubectl</code></a>
utility needs to be installed.</p>
</div>
<div class="paragraph">
<p>The easiest way to get a running Kubernetes cluster is using <code>Minikube</code>. <code>Minikube</code> can be downloaded and installed
from the <a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Kubernetes website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minikube</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, it can be started using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minikube start --memory 4096</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="openshift"><a class="link" href="#openshift">B.2. OpenShift</a></h3>
<div class="paragraph">
<p>In order to interact with an OpenShift cluster, the <a href="https://github.com/openshift/origin/releases"><code>oc</code></a> utility is needed.</p>
</div>
<div class="paragraph">
<p>An OpenShift cluster can be started in two different ways. The <code>oc</code> utility can start a cluster locally using the
command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc cluster up</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command requires Docker to be installed. More information about this way can be found
<a href="https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md">here</a>.</p>
</div>
<div class="paragraph">
<p>Another option is to use <code>Minishift</code>. <code>Minishift</code> is an OpenShift installation within a VM. It can be downloaded and
installed from the <a href="https://docs.openshift.org/latest/minishift/index.html">Minishift website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minishift</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, <code>Minishift</code> can be started using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minishift start --memory 4GB</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="metrics-str"><a class="link" href="#metrics-str">Appendix C: Metrics</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section describes how to monitor Strimzi Kafka and ZooKeeper clusters using Grafana dashboards.
In order to run the example dashboards you must configure Prometheus server and add the appropriate <a href="https://github.com/prometheus/jmx_exporter">Prometheus JMX Exporter</a> rules to your Kafka cluster resource.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
The resources referenced in this section serve as a good starting point for setting up monitoring, but they are provided as an example only.
If you require further support on configuration and running Prometheus or Grafana in production then please reach out to their respective communities.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When adding Prometheus and Grafana servers to an Apache Kafka deployment using <code>minikube</code> or <code>minishift</code>, the memory available to the virtual machine should be increased (to 4 GB of RAM, for example, instead of the default 2 GB). Information on how to increase the default amount of memory can be found in the following section <a href="#installing_kubernetes_and_openshift_cluster">Installing OpenShift or Kubernetes cluster</a>.</p>
</div>
<div class="sect2">
<h3 id="kafka_metrics_configuration"><a class="link" href="#kafka_metrics_configuration">C.1. Kafka Metrics Configuration</a></h3>
<div class="paragraph">
<p>Strimzi uses the <a href="https://github.com/prometheus/jmx_exporter">Prometheus JMX Exporter</a> to export JMX metrics from Kafka and ZooKeeper to a Prometheus HTTP metrics endpoint that is scraped by Prometheus server.
The Grafana dashboard relies on the Kafka and ZooKeeper Prometheus JMX Exporter relabeling rules defined in the example <code>Kafka</code> resource configuration in <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/kafka/kafka-metrics.yaml"><code>kafka-metrics.yaml</code></a>.
Copy this configuration to your own <code>Kafka</code> resource definition, or run this example, in order to use the provided Grafana dashboards.</p>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift"><a class="link" href="#deploying_on_openshift">C.1.1. Deploying on OpenShift</a></h4>
<div class="paragraph">
<p>To deploy the example Kafka cluster the following command should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/kafka/kafka-metrics.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes"><a class="link" href="#deploying_on_kubernetes">C.1.2. Deploying on Kubernetes</a></h4>
<div class="paragraph">
<p>To deploy the example Kafka cluster the following command should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/kafka/kafka-metrics.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="prometheus"><a class="link" href="#prometheus">C.2. Prometheus</a></h3>
<div class="paragraph">
<p>The provided Prometheus <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/prometheus.yaml"><code>prometheus.yaml</code></a> YAML file describes all the resources required by Prometheus in order to effectively monitor a Strimzi Kafka &amp; ZooKeeper cluster.
These resources lack important production configuration to run a healthy and highly available Prometheus server.
They should only be used to demonstrate this Grafana dashboard example.</p>
</div>
<div class="paragraph">
<p>The following resources are defined:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>ClusterRole</code> that grants permissions to read Prometheus health endpoints of the Kubernetes system, including cAdvisor and kubelet for container metrics.  The Prometheus server configuration uses the Kubernetes service discovery feature in order to discover the pods in the cluster from which it gets metrics.  In order to have this feature working, it is necessary for the service account used for running the Prometheus service pod to have access to the API server to get the pod list.</p>
</li>
<li>
<p>A <code>ServiceAccount</code> for the Prometheus pods to run under.</p>
</li>
<li>
<p>A <code>ClusterRoleBinding</code> which binds the aforementioned <code>ClusterRole</code> to the <code>ServiceAccount</code>.</p>
</li>
<li>
<p>A <code>Deployment</code> to manage the actual Prometheus server pod.</p>
</li>
<li>
<p>A <code>ConfigMap</code> to manage the configuration of Prometheus Server.</p>
</li>
<li>
<p>A <code>Service</code> to provide an easy to reference hostname for other services to connect to Prometheus server (such as Grafana).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Prometheus also provides an alerting system through the <a href="https://prometheus.io/docs/alerting/alertmanager/">alert manager</a> component.
In order to enable alerting, the provided <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alerting-rules.yaml"><code>alerting-rules.yaml</code></a> file describes a <code>ConfigMap</code> resource which defines sample alerting rules on Kafka and Zookeeper metrics.
When an alert condition is evaluated as true on the Prometheus server, it sends the alert data to the alert manager which then uses the configured notification methods to notify the user.</p>
</div>
<div class="paragraph">
<p>More information about how to set up alerting rules <a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">here</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift_2"><a class="link" href="#deploying_on_openshift_2">C.2.1. Deploying on OpenShift</a></h4>
<div class="paragraph">
<p>The provided <code>prometheus.yaml</code> file, with all the Prometheus related resources, creates a <code>ClusterRoleBinding</code> in the <code>myproject</code> namespace.
It also discovers an alert manager instance in the same namespace.
If you are using a different namespace, download the resource file and update it as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/prometheus.yaml | sed -e 's/namespace: .*/namespace: _my-namespace_/;s/regex: myproject/regex: _my-namespace_/' &gt; prometheus.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>The provided <code>alerting-rules.yaml</code> file creates a <code>ConfigMap</code> with sample alerting rules; download the resource file as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alerting-rules.yaml &gt; alerting-rules.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>To deploy all these resources you can run the following.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc login -u system:admin
oc apply -f alerting-rules.yaml
oc apply -f prometheus.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes_2"><a class="link" href="#deploying_on_kubernetes_2">C.2.2. Deploying on Kubernetes</a></h4>
<div class="paragraph">
<p>The provided <code>prometheus.yaml</code> file, with all the Prometheus related resources, creates a <code>ClusterRoleBinding</code> in the <code>myproject</code> namespace.
If you are using a different namespace, download the resource file and update it as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/prometheus.yaml | sed -e 's/namespace: .*/namespace: _my-namespace_/;s/regex: myproject/regex: _my-namespace_/' &gt; prometheus.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>The provided <code>alerting-rules.yaml</code> file creates a <code>ConfigMap</code> with sample alerting rules; download the resource file as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">curl -s https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alerting-rules.yaml &gt; alerting-rules.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>To deploy all these resources you can run the following.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f alerting-rules.yaml
kubectl apply -f prometheus.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="grafana"><a class="link" href="#grafana">C.3. Grafana</a></h3>
<div class="paragraph">
<p>A Grafana server is necessary to get a visualisation of the Prometheus metrics.  The source for the Grafana docker image used can be found in the <code>./metrics/examples/grafana/grafana-openshift</code> directory.</p>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift_3"><a class="link" href="#deploying_on_openshift_3">C.3.1. Deploying on OpenShift</a></h4>
<div class="paragraph">
<p>To deploy Grafana the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/grafana/grafana.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes_3"><a class="link" href="#deploying_on_kubernetes_3">C.3.2. Deploying on Kubernetes</a></h4>
<div class="paragraph">
<p>To deploy Grafana the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/grafana/grafana.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="grafana_dashboard"><a class="link" href="#grafana_dashboard">C.4. Grafana dashboard</a></h3>
<div class="paragraph">
<p>As an example, and in order to visualize the exported metrics in Grafana, two sample dashboards are provided <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.11.1/metrics/examples/grafana/strimzi-kafka.json"><code>strimzi-kafka.json</code></a> and <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.11.1/metrics/examples/grafana/strimzi-zookeeper.json"><code>strimzi-zookeeper.json</code></a>.
These dashboards represent a good starting point for key metrics to monitor Kafka and ZooKeeper clusters, but depending on your infrastructure you may need to update or add to them.
Please note that they are not representative of all the metrics available.
No alerting rules are defined.</p>
</div>
<div class="paragraph">
<p>The Grafana Prometheus data source, and the above dashboards, can be set up in Grafana by following these steps.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For accessing the dashboard, you can use the <code>port-forward</code> command for forwarding traffic from the Grafana pod to the host. For example, you can access the Grafana UI by running <code>oc port-forward grafana-1-fbl7s 3000:3000</code> (or using <code>kubectl</code> instead of <code>oc</code>) and then pointing a browser to <code><a href="http://localhost:3000" class="bare">http://localhost:3000</a></code>.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Access to the Grafana UI using <code>admin/admin</code> credentials.  On the following view you can choose to skip resetting the admin password, or set it to a password you desire.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_login.png" alt="Grafana login">
</div>
</div>
</li>
<li>
<p>Click on the "Add data source" button from the Grafana home in order to add Prometheus as data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_home.png" alt="Grafana home">
</div>
</div>
</li>
<li>
<p>Fill in the information about the Prometheus data source, specifying a name and "Prometheus" as type. In the URL field, the connection string to the Prometheus server (that is, <code><a href="http://prometheus:9090" class="bare">http://prometheus:9090</a></code>) should be specified. After "Add" is clicked, Grafana will test the connection to the data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_prometheus_data_source.png" alt="Add Prometheus data source">
</div>
</div>
</li>
<li>
<p>From the top left menu, click on "Dashboards" and then "Import" to open the "Import Dashboard" window where the provided <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.11.1/metrics/examples/grafana/strimzi-kafka.json"><code>strimzi-kafka.json</code></a> and <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.11.1/metrics/examples/grafana/strimzi-zookeeper.json"><code>strimzi-zookeeper.json</code></a> files can be imported or their content pasted.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_import_dashboard.png" alt="Add Grafana dashboard">
</div>
</div>
</li>
<li>
<p>After importing the dashboards, the Grafana dashboard homepage will now list two dashboards for you to choose from.  After your Prometheus server has been collecting metrics for a Strimzi cluster for some time you should see a populated dashboard such as the examples list below.</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="kafka_dashboard"><a class="link" href="#kafka_dashboard">C.4.1. Kafka Dashboard</a></h4>
<div class="imageblock">
<div class="content">
<img src="images/grafana_kafka_dashboard.png" alt="Kafka dashboard">
</div>
</div>
</div>
<div class="sect3">
<h4 id="zookeeper_dashboard"><a class="link" href="#zookeeper_dashboard">C.4.2. ZooKeeper Dashboard</a></h4>
<div class="imageblock">
<div class="content">
<img src="images/grafana_zookeeper_dashboard.png" alt="ZooKeeper dashboard">
</div>
</div>
</div>
<div class="sect3">
<h4 id="metrics_references"><a class="link" href="#metrics_references">C.4.3. Metrics References</a></h4>
<div class="paragraph">
<p>To learn more about what metrics are available to monitor for Kafka, ZooKeeper, and Kubernetes in general, please review the following resources.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://kafka.apache.org/documentation/#monitoring">Apache Kafka Monitoring</a> - A list of JMX metrics exposed by Apache Kafka.
It includes a description, JMX mbean name, and in some cases a suggestion on what is a normal value returned.</p>
</li>
<li>
<p><a href="https://zookeeper.apache.org/doc/current/zookeeperJMX.html">ZooKeeper JMX</a> - A list of JMX metrics exposed by Apache ZooKeeper.</p>
</li>
<li>
<p><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">Prometheus - Monitoring Docker Container Metrics using cAdvisor</a> - cAdvisor (short for container Advisor) analyzes and exposes resource usage (such as CPU, Memory, and Disk) and performance data from running containers within pods on Kubernetes.
cAdvisor is bundled along with the kubelet binary so that it is automatically available within Kubernetes clusters.
This reference describes how to monitor cAdvisor metrics in various ways using Prometheus.</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">cAdvisor Metrics</a> - A full list of cAdvisor metrics as exposed through Prometheus.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="prometheus_alerting"><a class="link" href="#prometheus_alerting">C.5. Prometheus alerting</a></h3>
<div class="paragraph">
<p>In the monitoring space, one of the useful aspects is to be notified when some metrics conditions are verified.
They allow a human operator to get notifications about problems in the monitored system.</p>
</div>
<div class="paragraph">
<p>Prometheus allows to write so called "alerting rules" which describe such a conditions using <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">PromQL</a> expressions that are continuously evaluated.
When an expression becomes true, the described condition is met and the Prometheus server fires an alert.</p>
</div>
<div class="paragraph">
<p>Prometheus itself is not responsible for sending notifications to the users when an alert is fired.
A different component, the Prometheus alert manager, is in charge to do so, sending emails, chat messages or using different notification methods.
When an alert condition is verified, the alert is fired and the Prometheus server sends it to the alert manager which will send notifications.</p>
</div>
</div>
<div class="sect2">
<h3 id="prometheus_alert_manager"><a class="link" href="#prometheus_alert_manager">C.6. Prometheus alert manager</a></h3>
<div class="paragraph">
<p>Other than a server for scraping metrics, Prometheus provides an alerting system through the alert manager component.
It is possible to declare alerting rules on the Prometheus server in order to be notified about specific conditions in the metrics.
When an alert condition is evaluated as true, Prometheus sends alert data to the alert manager which then sends notifications out.
Notifications can be sent via methods such as email, Slack, PagerDuty and HipChat</p>
</div>
<div class="paragraph">
<p>The provided Prometheus <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alertmanager.yaml"><code>alertmanager.yaml</code></a> YAML file describes all the resources required for deploying and configuring the alert manager.</p>
</div>
<div class="paragraph">
<p>The following resources are defined:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Deployment</code> to manage the actual alert manager pod.</p>
</li>
<li>
<p>A <code>ConfigMap</code> to manage the configuration of the alert manager.</p>
</li>
<li>
<p>A <code>Service</code> to provide an easy to reference hostname for other services to connect to alert manager (such as Prometheus).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The provided sample configuration configures the alert manager to send notification to a Slack channel.
Before deploying the alert manager it is needed to update the following parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <code>slack_api_url</code> field with the actual value of the Slack API URL related to the application for the Slack workspace.</p>
</li>
<li>
<p>The <code>channel</code> field with the actual Slack channel on which sending the notifications.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift_4"><a class="link" href="#deploying_on_openshift_4">C.6.1. Deploying on OpenShift</a></h4>
<div class="paragraph">
<p>To deploy the alert manager the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alertmanager.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes_4"><a class="link" href="#deploying_on_kubernetes_4">C.6.2. Deploying on Kubernetes</a></h4>
<div class="paragraph">
<p>To deploy the alert manager the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alertmanager.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="alerts_examples"><a class="link" href="#alerts_examples">C.6.3. Alerts examples</a></h4>
<div class="paragraph">
<p>The provided <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.11.1/metrics/examples/prometheus/alerting-rules.yaml"><code>alerting-rules.yaml</code></a> YAML file provides the following sample alerting rules on Kafka and Zookeeper metrics.</p>
</div>
<div class="paragraph">
<p>Kafka alerts are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>UnderReplicatedPartitions</code>: the under replicated partitions metric gives the number of partitions for which the current broker is the leader replica but the follower replicas are not caught up.
This metric provides insights about offline brokers which hosts the follower replicas.
This alert is raised when this value is greater than zero, providing the information of the under replicated partitions for each broker.</p>
</li>
<li>
<p><code>AbnormalControllerState</code>: the active controller metric indicate if the current broker is the controller for the cluster.
It can just be 0 or 1.
During the life of a cluster, only one broker should be the controller and the cluster needs to have always an active controller.
Having two or more brokers saying that they are controllers indicates a problem.
This alert is raised when the sum of all the values for this metric on all broker is not equals to 1.
It means that there is no active controller (the sum is 0) or more than one controller (the sum is greater than 1).</p>
</li>
<li>
<p><code>UnderMinIsrPartitionCount</code>: the Kafka broker <code>min.insync.replicas</code> allows to specify the minimum number of replicas that have to acknowledge a write operation for successful in order to be in-sync.
The under min ISR partition count metric defines the number of partitions that this broker leads for which in-sync replicas count is less than the min in-sync.
This alert is raised when this value is greater than zero, providing the information of the under min ISR partition count for each broker.</p>
</li>
<li>
<p><code>OfflineLogDirectoryCount</code>: the offline log directory count metric indicate the number of log directories which are offline (due to an hardware failure for example) so that the broker cannot store incoming messages anymore.
This alert is raised when this value is greater than zero, providing the information of the number of offline log directories for each broker.</p>
</li>
<li>
<p><code>KafkaRunningOutOfSpace</code>: the running out of space metric indicates the remaining amount of disk space that can be used for writing Kafka&#8217;s data.
This alert is raised when this value is lower than 5GiB. It provides information on the disk that is running out of space for each persistent volume claim.
NOTE: The availability of this metric and alert is dependent on your version of OpenShift or Kubernetes.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Zookeeper alerts are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>AvgRequestLatency</code>: the average request latency metric indicates the amount of time it takes for the server to respond to a client request.
This alert is raised when this value is greater than 10 (ticks), providing the actual value of the average request latency for each server.</p>
</li>
<li>
<p><code>OutstandingRequests</code>: the outstanding requests metric indicates the number of queued requests in the server.
This value goes up when the server receives more requests than it can process.
This alert is raised when this value is greater than 10 (ticks), providing the actual number of outstanding requests for each server.</p>
</li>
<li>
<p><code>ZookeeperRunningOutOfSpace</code>: the running out of space metric indicates the remaining amount of disk space that can be used for writing data to Zookeeper.
This alert is raised when this value is lower than 5GiB. It provides information on the disk that is running out of space for each persistent volume claim.
Note: The availability of this metric and alert is dependent on your version of OpenShift or Kubernetes.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="api_reference-str"><a class="link" href="#api_reference-str">Appendix D: Custom Resource API Reference</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="type-Kafka-reference"><a class="link" href="#type-Kafka-reference">D.1. <code>Kafka</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka and Zookeeper clusters, and Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaSpec-reference"><a class="link" href="#type-KafkaSpec-reference">D.2. <code>KafkaSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-Kafka-reference"><code>Kafka</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kafka</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Zookeeper cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">entityOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Entity Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">clusterCa</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the cluster certificate authority.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertificateAuthority-reference"><code>CertificateAuthority</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">clientsCa</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the clients certificate authority.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertificateAuthority-reference"><code>CertificateAuthority</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">maintenanceTimeWindows</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A list of time windows for the maintenance tasks (that is, certificates renewal). Each time window is defined by a cron expression.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaClusterSpec-reference"><a class="link" href="#type-KafkaClusterSpec-reference">D.3. <code>KafkaClusterSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods. The default value depends on the configured <code>Kafka.spec.kafka.version</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim, jbod].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a>, <a href="#type-JbodStorage-reference"><code>JbodStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">listeners</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures listeners of Kafka brokers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization configuration for Kafka brokers. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaAuthorizationSimple-reference"><code>KafkaAuthorizationSimple</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The kafka broker config. Properties with the following prefixes cannot be set: listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer., super.user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rack</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the <code>broker.rack</code> broker config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Rack-reference"><code>Rack</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokerRackInitImage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image of the init container used for initializing the <code>broker.rack</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka cluster resources. The template allows users to specify how are the <code>StatefulSet</code>, <code>Pods</code> and <code>Services</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaClusterTemplate-reference"><code>KafkaClusterTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">version</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The kafka broker version. Defaults to 2.1.0. Consult the user documentation to understand the process required to upgrade or downgrade the version.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EphemeralStorage-reference"><a class="link" href="#type-EphemeralStorage-reference">D.4. <code>EphemeralStorage</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-JbodStorage-reference"><code>JbodStorage</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>EphemeralStorage</code> from <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a>.
It must have the value <code>ephemeral</code> for the type <code>EphemeralStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">id</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>ephemeral</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PersistentClaimStorage-reference"><a class="link" href="#type-PersistentClaimStorage-reference">D.5. <code>PersistentClaimStorage</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-JbodStorage-reference"><code>JbodStorage</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>PersistentClaimStorage</code> from <a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>.
It must have the value <code>persistent-claim</code> for the type <code>PersistentClaimStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>persistent-claim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">selector</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteClaim</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">class</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The storage class to use for dynamic volume allocation.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">id</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-JbodStorage-reference"><a class="link" href="#type-JbodStorage-reference">D.6. <code>JbodStorage</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>JbodStorage</code> from <a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a>.
It must have the value <code>jbod</code> for the type <code>JbodStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>jbod</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">volumes</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of volumes as Storage objects representing the JBOD disks array.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListeners-reference"><a class="link" href="#type-KafkaListeners-reference">D.7. <code>KafkaListeners</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">plain</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures plain listener on port 9092.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures TLS listener on port 9093.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">external</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures external listener on port 9094. The type depends on the value of the <code>external.type</code> property within the given object, which must be one of [route, loadbalancer, nodeport].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerPlain-reference"><a class="link" href="#type-KafkaListenerPlain-reference">D.8. <code>KafkaListenerPlain</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with <code>type: tls</code>. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">networkPolicyPeers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">networking/v1 networkpolicypeer</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">NetworkPolicyPeer</a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationTls-reference"><a class="link" href="#type-KafkaListenerAuthenticationTls-reference">D.9. <code>KafkaListenerAuthenticationTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationTls</code> from <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaListenerAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationScramSha512-reference"><a class="link" href="#type-KafkaListenerAuthenticationScramSha512-reference">D.10. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationScramSha512</code> from <a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaListenerAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerTls-reference"><a class="link" href="#type-KafkaListenerTls-reference">D.11. <code>KafkaListenerTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">networkPolicyPeers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">networking/v1 networkpolicypeer</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">NetworkPolicyPeer</a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalRoute-reference"><a class="link" href="#type-KafkaListenerExternalRoute-reference">D.12. <code>KafkaListenerExternalRoute</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalRoute</code> from <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>route</code> for the type <code>KafkaListenerExternalRoute</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>route</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">networkPolicyPeers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">networking/v1 networkpolicypeer</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">NetworkPolicyPeer</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">overrides</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Overrides for external bootstrap and broker services and externally advertised addresses.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-RouteListenerOverride-reference"><code>RouteListenerOverride</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-RouteListenerOverride-reference"><a class="link" href="#type-RouteListenerOverride-reference">D.13. <code>RouteListenerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrap</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External bootstrap service configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-RouteListenerBootstrapOverride-reference"><code>RouteListenerBootstrapOverride</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External broker services configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-RouteListenerBrokerOverride-reference"><code>RouteListenerBrokerOverride</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-RouteListenerBootstrapOverride-reference"><a class="link" href="#type-RouteListenerBootstrapOverride-reference">D.14. <code>RouteListenerBootstrapOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-RouteListenerOverride-reference"><code>RouteListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">address</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">host</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Host for the bootstrap route. This field will be used in the <code>spec.host</code> field of the OpenShift Route.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-RouteListenerBrokerOverride-reference"><a class="link" href="#type-RouteListenerBrokerOverride-reference">D.15. <code>RouteListenerBrokerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-RouteListenerOverride-reference"><code>RouteListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">broker</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Id of the kafka broker (broker identifier).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedHost</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host name which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedPort</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The port number which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">host</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Host for the broker route. This field will be used in the <code>spec.host</code> field of the OpenShift Route.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalLoadBalancer-reference"><a class="link" href="#type-KafkaListenerExternalLoadBalancer-reference">D.16. <code>KafkaListenerExternalLoadBalancer</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalLoadBalancer</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>loadbalancer</code> for the type <code>KafkaListenerExternalLoadBalancer</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>loadbalancer</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">networkPolicyPeers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">networking/v1 networkpolicypeer</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">NetworkPolicyPeer</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">overrides</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Overrides for external bootstrap and broker services and externally advertised addresses.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-LoadBalancerListenerOverride-reference"><code>LoadBalancerListenerOverride</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Enables TLS encryption on the listener. By default set to <code>true</code> for enabled TLS encryption.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-LoadBalancerListenerOverride-reference"><a class="link" href="#type-LoadBalancerListenerOverride-reference">D.17. <code>LoadBalancerListenerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrap</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External bootstrap service configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-LoadBalancerListenerBootstrapOverride-reference"><code>LoadBalancerListenerBootstrapOverride</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External broker services configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-LoadBalancerListenerBrokerOverride-reference"><code>LoadBalancerListenerBrokerOverride</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-LoadBalancerListenerBootstrapOverride-reference"><a class="link" href="#type-LoadBalancerListenerBootstrapOverride-reference">D.18. <code>LoadBalancerListenerBootstrapOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-LoadBalancerListenerOverride-reference"><code>LoadBalancerListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">address</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-LoadBalancerListenerBrokerOverride-reference"><a class="link" href="#type-LoadBalancerListenerBrokerOverride-reference">D.19. <code>LoadBalancerListenerBrokerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-LoadBalancerListenerOverride-reference"><code>LoadBalancerListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">broker</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Id of the kafka broker (broker identifier).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedHost</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host name which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedPort</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The port number which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalNodePort-reference"><a class="link" href="#type-KafkaListenerExternalNodePort-reference">D.20. <code>KafkaListenerExternalNodePort</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalNodePort</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>.
It must have the value <code>nodeport</code> for the type <code>KafkaListenerExternalNodePort</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>nodeport</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">networkPolicyPeers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">networking/v1 networkpolicypeer</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#networkpolicypeer-v1-networking">NetworkPolicyPeer</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">overrides</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Overrides for external bootstrap and broker services and externally advertised addresses.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-NodePortListenerOverride-reference"><code>NodePortListenerOverride</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Enables TLS encryption on the listener. By default set to <code>true</code> for enabled TLS encryption.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-NodePortListenerOverride-reference"><a class="link" href="#type-NodePortListenerOverride-reference">D.21. <code>NodePortListenerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrap</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External bootstrap service configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-NodePortListenerBootstrapOverride-reference"><code>NodePortListenerBootstrapOverride</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">External broker services configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-NodePortListenerBrokerOverride-reference"><code>NodePortListenerBrokerOverride</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-NodePortListenerBootstrapOverride-reference"><a class="link" href="#type-NodePortListenerBootstrapOverride-reference">D.22. <code>NodePortListenerBootstrapOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-NodePortListenerOverride-reference"><code>NodePortListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">address</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nodePort</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Node port for the bootstrap service.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-NodePortListenerBrokerOverride-reference"><a class="link" href="#type-NodePortListenerBrokerOverride-reference">D.23. <code>NodePortListenerBrokerOverride</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-NodePortListenerOverride-reference"><code>NodePortListenerOverride</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">broker</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Id of the kafka broker (broker identifier).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedHost</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host name which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">advertisedPort</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The port number which will be used in the brokers' <code>advertised.brokers</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nodePort</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Node port for the broker service.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaAuthorizationSimple-reference"><a class="link" href="#type-KafkaAuthorizationSimple-reference">D.24. <code>KafkaAuthorizationSimple</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">superUsers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of super users. Should contain list of user principals which should get unlimited access rights.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Rack-reference"><a class="link" href="#type-Rack-reference">D.25. <code>Rack</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topologyKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A key that matches labels assigned to the OpenShift or Kubernetes cluster nodes. The value of the label is used to set the broker&#8217;s <code>broker.rack</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Probe-reference"><a class="link" href="#type-Probe-reference">D.26. <code>Probe</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">initialDelaySeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The initial delay before first the health is first checked.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">timeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The timeout for each attempted health check.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-JvmOptions-reference"><a class="link" href="#type-JvmOptions-reference">D.27. <code>JvmOptions</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-XX</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A map of -XX options to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xms</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xms option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xmx</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xmx option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">gcLoggingEnabled</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies whether the Garbage Collection logging is enabled. The default is true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Resources-reference"><a class="link" href="#type-Resources-reference">D.28. <code>Resources</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">limits</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource limits applied at runtime.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">requests</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource requests applied during pod scheduling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CpuMemory-reference"><a class="link" href="#type-CpuMemory-reference">D.29. <code>CpuMemory</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-Resources-reference"><code>Resources</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">cpu</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">CPU.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">memory</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Memory.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-InlineLogging-reference"><a class="link" href="#type-InlineLogging-reference">D.30. <code>InlineLogging</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>InlineLogging</code> from <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a>.
It must have the value <code>inline</code> for the type <code>InlineLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>inline</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">loggers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A Map from logger name to logger level.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalLogging-reference"><a class="link" href="#type-ExternalLogging-reference">D.31. <code>ExternalLogging</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>ExternalLogging</code> from <a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>.
It must have the value <code>external</code> for the type <code>ExternalLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>external</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the <code>ConfigMap</code> from which to get the logging configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-TlsSidecar-reference"><a class="link" href="#type-TlsSidecar-reference">D.32. <code>TlsSidecar</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the container.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logLevel</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The log level for the TLS sidecar. Default value is <code>notice</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [emerg, debug, crit, err, alert, warning, notice, info])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaClusterTemplate-reference"><a class="link" href="#type-KafkaClusterTemplate-reference">D.33. <code>KafkaClusterTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">statefulset</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka <code>StatefulSet</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pod</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka <code>Pods</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodTemplate-reference"><code>PodTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka bootstrap <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokersService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka broker <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">externalBootstrapRoute</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka external bootstrap <code>Route</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">externalBootstrapService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka external bootstrap <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">perPodRoute</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka per-pod <code>Routes</code> used for access from outside of OpenShift.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">perPodService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka per-pod <code>Services</code> used for access from outside of Kubernetes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">podDisruptionBudget</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka <code>PodDisruptionBudget</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ResourceTemplate-reference"><a class="link" href="#type-ResourceTemplate-reference">D.34. <code>ResourceTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorTemplate-reference"><code>EntityOperatorTemplate</code></a>, <a href="#type-KafkaClusterTemplate-reference"><code>KafkaClusterTemplate</code></a>, <a href="#type-KafkaConnectTemplate-reference"><code>KafkaConnectTemplate</code></a>, <a href="#type-KafkaMirrorMakerTemplate-reference"><code>KafkaMirrorMakerTemplate</code></a>, <a href="#type-ZookeeperClusterTemplate-reference"><code>ZookeeperClusterTemplate</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metadata</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Metadata which should be applied to the resource.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-MetadataTemplate-reference"><code>MetadataTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-MetadataTemplate-reference"><a class="link" href="#type-MetadataTemplate-reference">D.35. <code>MetadataTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code></a>, <a href="#type-PodTemplate-reference"><code>PodTemplate</code></a>, <a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">labels</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Labels which should be added to the resource template. Can be applied to different resources such as <code>StatefulSets</code>, <code>Deployments</code>, <code>Pods</code>, and <code>Services</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">annotations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Annotations which should be added to the resource template. Can be applied to different resources such as <code>StatefulSets</code>, <code>Deployments</code>, <code>Pods</code>, and <code>Services</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PodTemplate-reference"><a class="link" href="#type-PodTemplate-reference">D.36. <code>PodTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorTemplate-reference"><code>EntityOperatorTemplate</code></a>, <a href="#type-KafkaClusterTemplate-reference"><code>KafkaClusterTemplate</code></a>, <a href="#type-KafkaConnectTemplate-reference"><code>KafkaConnectTemplate</code></a>, <a href="#type-KafkaMirrorMakerTemplate-reference"><code>KafkaMirrorMakerTemplate</code></a>, <a href="#type-ZookeeperClusterTemplate-reference"><code>ZookeeperClusterTemplate</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metadata</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Metadata which should be applied to the resource.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-MetadataTemplate-reference"><code>MetadataTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imagePullSecrets</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of references to secrets in the same namespace to use for pulling any of the images used by this Pod.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#localobjectreference-v1-core">core/v1 localobjectreference</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#localobjectreference-v1-core">LocalObjectReference</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">securityContext</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures pod-level security attributes and common container settings.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#podsecuritycontext-v1-core">core/v1 podsecuritycontext</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#podsecuritycontext-v1-core">PodSecurityContext</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">terminationGracePeriodSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process.Value must be non-negative integer. The value zero indicates delete immediately. Defaults to 30 seconds.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PodDisruptionBudgetTemplate-reference"><a class="link" href="#type-PodDisruptionBudgetTemplate-reference">D.37. <code>PodDisruptionBudgetTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterTemplate-reference"><code>KafkaClusterTemplate</code></a>, <a href="#type-KafkaConnectTemplate-reference"><code>KafkaConnectTemplate</code></a>, <a href="#type-KafkaMirrorMakerTemplate-reference"><code>KafkaMirrorMakerTemplate</code></a>, <a href="#type-ZookeeperClusterTemplate-reference"><code>ZookeeperClusterTemplate</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metadata</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Metadata which should be applied to the <code>PodDistruptionBugetTemplate</code> resource.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-MetadataTemplate-reference"><code>MetadataTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">maxUnavailable</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Maximum number of unavailable pods to allow voluntary Pod eviction. A Pod eviction will only be allowed when "maxUnavailable" or fewer pods are unavailable after the eviction. Setting this value to 0 will prevent all voluntary evictions and the pods will need to be evicted manually. Defaults to 1.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ZookeeperClusterSpec-reference"><a class="link" href="#type-ZookeeperClusterSpec-reference">D.38. <code>ZookeeperClusterSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The zookeeper broker config. Properties with the following prefixes cannot be set: server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Zookeeper. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper cluster resources. The template allows users to specify how are the <code>StatefulSet</code>, <code>Pods</code> and <code>Services</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ZookeeperClusterTemplate-reference"><code>ZookeeperClusterTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ZookeeperClusterTemplate-reference"><a class="link" href="#type-ZookeeperClusterTemplate-reference">D.39. <code>ZookeeperClusterTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">statefulset</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper <code>StatefulSet</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pod</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper <code>Pods</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodTemplate-reference"><code>PodTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">clientService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper client <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nodesService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper nodes <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">podDisruptionBudget</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Zookeeper <code>PodDisruptionBudget</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-TopicOperatorSpec-reference"><a class="link" href="#type-TopicOperatorSpec-reference">D.40. <code>TopicOperatorSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorJvmOptions-reference"><code>EntityOperatorJvmOptions</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityOperatorJvmOptions-reference"><a class="link" href="#type-EntityOperatorJvmOptions-reference">D.41. <code>EntityOperatorJvmOptions</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">gcLoggingEnabled</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies whether the Garbage Collection logging is enabled. The default is true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityOperatorSpec-reference"><a class="link" href="#type-EntityOperatorSpec-reference">D.42. <code>EntityOperatorSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">userOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Entity Operator resources. The template allows users to specify how is the <code>Deployment</code> and <code>Pods</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorTemplate-reference"><code>EntityOperatorTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityTopicOperatorSpec-reference"><a class="link" href="#type-EntityTopicOperatorSpec-reference">D.43. <code>EntityTopicOperatorSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorJvmOptions-reference"><code>EntityOperatorJvmOptions</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityUserOperatorSpec-reference"><a class="link" href="#type-EntityUserOperatorSpec-reference">D.44. <code>EntityUserOperatorSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the User Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorJvmOptions-reference"><code>EntityOperatorJvmOptions</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityOperatorTemplate-reference"><a class="link" href="#type-EntityOperatorTemplate-reference">D.45. <code>EntityOperatorTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deployment</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Entity Operator <code>Deployment</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pod</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Entity Operator <code>Pods</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodTemplate-reference"><code>PodTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertificateAuthority-reference"><a class="link" href="#type-CertificateAuthority-reference">D.46. <code>CertificateAuthority</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<div class="paragraph">
<p>Configuration of how TLS certificates are used within the cluster. This applies to certificates used for both internal communication within the cluster and to certificates used for client access via <code>Kafka.spec.kafka.listeners.tls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">generateCertificateAuthority</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">validityDays</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of days generated certificates should be valid for. The default is 365.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">renewalDays</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed. When <code>generateCertificateAuthority</code> is true, this will cause the generation of a new certificate. When <code>generateCertificateAuthority</code> is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateExpirationPolicy</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">How should CA certificate expiration be handled when <code>generateCertificateAuthority=true</code>. The default is for a new CA certificate to be generated reusing the existing private key.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [replace-key, renew-certificate])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnect-reference"><a class="link" href="#type-KafkaConnect-reference">D.47. <code>KafkaConnect</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectSpec-reference"><a class="link" href="#type-KafkaConnectSpec-reference">D.48. <code>KafkaConnectSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how is the <code>Deployment</code>, <code>Pods</code> and <code>Service</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTemplate-reference"><code>KafkaConnectTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">externalConfiguration</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">version</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect version. Defaults to 2.1.0. Consult the user documentation to understand the process required to upgrade or downgrade the version.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectTemplate-reference"><a class="link" href="#type-KafkaConnectTemplate-reference">D.49. <code>KafkaConnectTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deployment</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect <code>Deployment</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pod</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect <code>Pods</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodTemplate-reference"><code>PodTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">apiService</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect API <code>Service</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">podDisruptionBudget</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect <code>PodDisruptionBudget</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationTls-reference"><a class="link" href="#type-KafkaConnectAuthenticationTls-reference">D.50. <code>KafkaConnectAuthenticationTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationTls</code> from <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaConnectAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateAndKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Certificate and private key pair for TLS authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertAndKeySecretSource-reference"><code>CertAndKeySecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertAndKeySecretSource-reference"><a class="link" href="#type-CertAndKeySecretSource-reference">D.51. <code>CertAndKeySecretSource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">key</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the private key in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationScramSha512-reference"><a class="link" href="#type-KafkaConnectAuthenticationScramSha512-reference">D.52. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationScramSha512</code> from <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaConnectAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">passwordSecret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Password used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PasswordSecretSource-reference"><code>PasswordSecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">username</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Username used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PasswordSecretSource-reference"><a class="link" href="#type-PasswordSecretSource-reference">D.53. <code>PasswordSecretSource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">password</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the key in the Secret under which the password is stored.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the password.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalConfiguration-reference"><a class="link" href="#type-ExternalConfiguration-reference">D.54. <code>ExternalConfiguration</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">env</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ExternalConfigurationEnv-reference"><code>ExternalConfigurationEnv</code></a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">volumes</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ExternalConfigurationVolumeSource-reference"><code>ExternalConfigurationVolumeSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalConfigurationEnv-reference"><a class="link" href="#type-ExternalConfigurationEnv-reference">D.55. <code>ExternalConfigurationEnv</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with <code>KAFKA_</code> or <code>STRIMZI_</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">valueFrom</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ExternalConfigurationEnvVarSource-reference"><code>ExternalConfigurationEnvVarSource</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalConfigurationEnvVarSource-reference"><a class="link" href="#type-ExternalConfigurationEnvVarSource-reference">D.56. <code>ExternalConfigurationEnvVarSource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-ExternalConfigurationEnv-reference"><code>ExternalConfigurationEnv</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">configMapKeyRef</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Refernce to a key in a ConfigMap.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ConfigMapKeySelector-v1-core">core/v1 ConfigMapKeySelector</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ConfigMapKeySelector-v1-core">ConfigMapKeySelector</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretKeyRef</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to a key in a Secret.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#SecretKeySelector-v1-core">core/v1 SecretKeySelector</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#SecretKeySelector-v1-core">SecretKeySelector</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalConfigurationVolumeSource-reference"><a class="link" href="#type-ExternalConfigurationVolumeSource-reference">D.57. <code>ExternalConfigurationVolumeSource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">configMap</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ConfigMapVolumeSource-v1-core">core/v1 ConfigMapVolumeSource</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ConfigMapVolumeSource-v1-core">ConfigMapVolumeSource</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of the volume which will be added to the Kafka Connect pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#SecretVolumeSource-v1-core">core/v1 SecretVolumeSource</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#SecretVolumeSource-v1-core">SecretVolumeSource</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectTls-reference"><a class="link" href="#type-KafkaConnectTls-reference">D.58. <code>KafkaConnectTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">trustedCertificates</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Trusted certificates for TLS connection.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertSecretSource-reference"><code>CertSecretSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertSecretSource-reference"><a class="link" href="#type-CertSecretSource-reference">D.59. <code>CertSecretSource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a>, <a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2I-reference"><a class="link" href="#type-KafkaConnectS2I-reference">D.60. <code>KafkaConnectS2I</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2ISpec-reference"><a class="link" href="#type-KafkaConnectS2ISpec-reference">D.61. <code>KafkaConnectS2ISpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how is the <code>Deployment</code>, <code>Pods</code> and <code>Service</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTemplate-reference"><code>KafkaConnectTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">externalConfiguration</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ExternalConfiguration-reference"><code>ExternalConfiguration</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">insecureSourceRepository</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When true this configures the source repository with the 'Local' reference policy and an import policy that accepts insecure source tags.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">version</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect version. Defaults to 2.1.0. Consult the user documentation to understand the process required to upgrade or downgrade the version.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopic-reference"><a class="link" href="#type-KafkaTopic-reference">D.62. <code>KafkaTopic</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the topic.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaTopicSpec-reference"><code>KafkaTopicSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopicSpec-reference"><a class="link" href="#type-KafkaTopicSpec-reference">D.63. <code>KafkaTopicSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">partitions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of partitions the topic should have. This cannot be decreased after topic creation. It can be increased after topic creation, but it is important to understand the consequences that has, especially for topics with semantic partitioning.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of replicas the topic should have.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The topic configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the topic. When absent this will default to the metadata.name of the topic. It is recommended to not set this unless the topic name is not a valid Kubernetes resource name.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUser-reference"><a class="link" href="#type-KafkaUser-reference">D.64. <code>KafkaUser</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserSpec-reference"><a class="link" href="#type-KafkaUserSpec-reference">D.65. <code>KafkaUserSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUser-reference"><code>KafkaUser</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication mechanism enabled for this Kafka user. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>, <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization rules for this Kafka user. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserTlsClientAuthentication-reference"><a class="link" href="#type-KafkaUserTlsClientAuthentication-reference">D.66. <code>KafkaUserTlsClientAuthentication</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserTlsClientAuthentication</code> from <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaUserTlsClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserScramSha512ClientAuthentication-reference"><a class="link" href="#type-KafkaUserScramSha512ClientAuthentication-reference">D.67. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserScramSha512ClientAuthentication</code> from <a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaUserScramSha512ClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserAuthorizationSimple-reference"><a class="link" href="#type-KafkaUserAuthorizationSimple-reference">D.68. <code>KafkaUserAuthorizationSimple</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaUserAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">acls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of ACL rules which should be applied to this user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRule-reference"><code>AclRule</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRule-reference"><a class="link" href="#type-AclRule-reference">D.69. <code>AclRule</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">host</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host from which the action described in the ACL rule is allowed or denied.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">operation</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Operation which will be allowed or denied. Supported operations are: Read, Write, Create, Delete, Alter, Describe, ClusterAction, AlterConfigs, DescribeConfigs, IdempotentWrite and All.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [Read, Write, Delete, Alter, Describe, All, IdempotentWrite, ClusterAction, Create, AlterConfigs, DescribeConfigs])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resource</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Indicates the resource for which given ACL rule applies. The type depends on the value of the <code>resource.type</code> property within the given object, which must be one of [topic, group, cluster, transactionalId].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>, <a href="#type-AclRuleTransactionalIdResource-reference"><code>AclRuleTransactionalIdResource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The type of the rule. Currently the only supported type is <code>allow</code>. ACL rules with type <code>allow</code> are used to allow user to execute the specified operations. Default value is <code>allow</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [allow, deny])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleTopicResource-reference"><a class="link" href="#type-AclRuleTopicResource-reference">D.70. <code>AclRuleTopicResource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleTopicResource</code> from <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>, <a href="#type-AclRuleTransactionalIdResource-reference"><code>AclRuleTransactionalIdResource</code></a>.
It must have the value <code>topic</code> for the type <code>AclRuleTopicResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>topic</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleGroupResource-reference"><a class="link" href="#type-AclRuleGroupResource-reference">D.71. <code>AclRuleGroupResource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleGroupResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>, <a href="#type-AclRuleTransactionalIdResource-reference"><code>AclRuleTransactionalIdResource</code></a>.
It must have the value <code>group</code> for the type <code>AclRuleGroupResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>group</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleClusterResource-reference"><a class="link" href="#type-AclRuleClusterResource-reference">D.72. <code>AclRuleClusterResource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleClusterResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleTransactionalIdResource-reference"><code>AclRuleTransactionalIdResource</code></a>.
It must have the value <code>cluster</code> for the type <code>AclRuleClusterResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>cluster</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleTransactionalIdResource-reference"><a class="link" href="#type-AclRuleTransactionalIdResource-reference">D.73. <code>AclRuleTransactionalIdResource</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleTransactionalIdResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>.
It must have the value <code>transactionalId</code> for the type <code>AclRuleTransactionalIdResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>transactionalId</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMaker-reference"><a class="link" href="#type-KafkaMirrorMaker-reference">D.74. <code>KafkaMirrorMaker</code> schema reference</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the mirror maker.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerSpec-reference"><a class="link" href="#type-KafkaMirrorMakerSpec-reference">D.75. <code>KafkaMirrorMakerSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMaker-reference"><code>KafkaMirrorMaker</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the <code>Deployment</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">whitelist</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B can be achieved by using the whitelist <code>'A|B'</code>. Or, as a special case, you can mirror all topics using the whitelist '*'. Multiple regular expressions separated by commas can be specified as well.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">consumer</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of source cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">producer</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of target cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Mirror Maker. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">JMX Exporter documentation</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">template</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Mirror Maker resources. The template allows users to specify how is the <code>Deployment</code> and <code>Pods</code> generated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerTemplate-reference"><code>KafkaMirrorMakerTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">version</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Mirror Maker version. Defaults to 2.1.0. Consult the user documentation to understand the process required to upgrade or downgrade the version.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerConsumerSpec-reference"><a class="link" href="#type-KafkaMirrorMakerConsumerSpec-reference">D.76. <code>KafkaMirrorMakerConsumerSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">numStreams</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies the number of consumer stream threads to create.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">groupId</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A unique string that identifies the consumer group this consumer belongs to.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for connecting to the cluster. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The mirror maker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration for connecting to the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerAuthenticationTls-reference"><a class="link" href="#type-KafkaMirrorMakerAuthenticationTls-reference">D.77. <code>KafkaMirrorMakerAuthenticationTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaMirrorMakerAuthenticationTls</code> from <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaMirrorMakerAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateAndKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to the <code>Secret</code> which holds the certificate and private key pair.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertAndKeySecretSource-reference"><code>CertAndKeySecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerAuthenticationScramSha512-reference"><a class="link" href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference">D.78. <code>KafkaMirrorMakerAuthenticationScramSha512</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaMirrorMakerAuthenticationScramSha512</code> from <a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaMirrorMakerAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">passwordSecret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to the <code>Secret</code> which holds the password.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PasswordSecretSource-reference"><code>PasswordSecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">username</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Username used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerTls-reference"><a class="link" href="#type-KafkaMirrorMakerTls-reference">D.79. <code>KafkaMirrorMakerTls</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">trustedCertificates</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Trusted certificates for TLS connection.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertSecretSource-reference"><code>CertSecretSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerProducerSpec-reference"><a class="link" href="#type-KafkaMirrorMakerProducerSpec-reference">D.80. <code>KafkaMirrorMakerProducerSpec</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for connecting to the cluster. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The mirror maker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration for connecting to the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerTemplate-reference"><a class="link" href="#type-KafkaMirrorMakerTemplate-reference">D.81. <code>KafkaMirrorMakerTemplate</code> schema reference</a></h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deployment</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Mirror Maker <code>Deployment</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ResourceTemplate-reference"><code>ResourceTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pod</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Mirror Maker <code>Pods</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodTemplate-reference"><code>PodTemplate</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">podDisruptionBudget</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Template for Kafka Mirror Maker <code>PodDisruptionBudget</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PodDisruptionBudgetTemplate-reference"><code>PodDisruptionBudgetTemplate</code></a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2019-02-21 11:13:55 CET
</div>
</div>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlighting()</script>
</body>
</html>