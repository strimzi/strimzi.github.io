<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.7.1">
<title>Using Strimzi</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Uncomment @import statement below to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
*:not(pre)>code.nobreak{word-wrap:normal}
*:not(pre)>code.nowrap{white-space:nowrap}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote::before{display:none}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{word-spacing:0;line-height:1.6}
.quoteblock.abstract blockquote::before,.quoteblock.abstract p::before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd){background:#f8f8f7}
table.stripes-none tr,table.stripes-odd tr:nth-of-type(even){background:none}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Using Strimzi</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#overview-str">1. Overview of Strimzi</a>
<ul class="sectlevel2">
<li><a href="#key-features-str">1.1. Kafka Key Features</a></li>
<li><a href="#document-conventions-str">1.2. Document Conventions</a></li>
</ul>
</li>
<li><a href="#getting-started-str">2. Getting started with Strimzi</a>
<ul class="sectlevel2">
<li><a href="#downloads-str">2.1. Strimzi Downloads</a></li>
<li><a href="#cluster-operator-str">2.2. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-str">2.2.5. Deploying the Cluster Operator using Helm Chart</a></li>
</ul>
</li>
<li><a href="#kafka-cluster-str">2.3. Kafka cluster</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</a></li>
<li><a href="#deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</a></li>
</ul>
</li>
<li><a href="#kafka-connect-str">2.4. Kafka Connect</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to Kubernetes</a></li>
<li><a href="#deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to OpenShift</a></li>
<li><a href="#using-kafka-connect-with-plugins-str">2.4.3. Using Kafka Connect with plugins</a></li>
</ul>
</li>
<li><a href="#deploying-example-clients-str">2.5. Deploying example clients</a></li>
<li><a href="#assembly-getting-started-topic-operator-str">2.6. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-str">2.6.1. Overview of the Topic Operator component</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-str">2.6.2. Deploying the Topic Operator using the Cluster Operator</a></li>
</ul>
</li>
<li><a href="#assembly-getting-started-user-operator-str">2.7. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-str">2.7.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">2.7.2. Deploying the User Operator using the Cluster Operator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-str">3. Deployment configuration</a>
<ul class="sectlevel2">
<li><a href="#assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</a></li>
<li><a href="#assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Replicas</a></li>
<li><a href="#assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</a></li>
<li><a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</a></li>
<li><a href="#assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</a></li>
<li><a href="#assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Replicas</a></li>
<li><a href="#assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</a></li>
<li><a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka">3.1.10. Logging</a></li>
<li><a href="#assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</a></li>
<li><a href="#assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.18. List of resources created as part of Kafka cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</a></li>
<li><a href="#assembly-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka-connect">3.2.13. List of resources created as part of Kafka Connect cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</a></li>
<li><a href="#assembly-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka-connect-s2i">3.3.13. List of resources created as part of Kafka Connect cluster with Source2Image support</a></li>
<li><a href="#using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.14. Using OpenShift builds and S2I to create new images</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-operators-str">4. Operators</a>
<ul class="sectlevel2">
<li><a href="#assembly-operators-cluster-operator-str">4.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-deploying-co">4.1.5. Deploying the Cluster Operator using Helm Chart</a></li>
<li><a href="#con-cluster-operator-reconciliation-deploying-co">4.1.6. Reconciliation</a></li>
<li><a href="#ref-operators-cluster-operator-configuration-deploying-co">4.1.7. Cluster Operator Configuration</a></li>
<li><a href="#con-cluster-operator-rbac-deploying-co">4.1.8. Role-Based Access Control (RBAC)</a></li>
</ul>
</li>
<li><a href="#deploying-the-topic-operator-str">4.2. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</a></li>
<li><a href="#how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</a></li>
<li><a href="#proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</a></li>
<li><a href="#deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</a></li>
<li><a href="#topic-operator-environment-deploying">4.2.6. Topic Operator environment</a></li>
</ul>
</li>
<li><a href="#assembly-user-operator-str">4.3. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</a></li>
<li><a href="#proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#using-the-topic-operator-str">5. Using the Topic Operator</a>
<ul class="sectlevel2">
<li><a href="#topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</a></li>
<li><a href="#creating-a-topic-str">5.2. Creating a topic</a></li>
<li><a href="#changing-a-topic-str">5.3. Changing a topic</a></li>
<li><a href="#deleting-a-topic-str">5.4. Deleting a topic</a></li>
</ul>
</li>
<li><a href="#assembly-using-the-user-operator-str">6. Using the User Operator</a>
<ul class="sectlevel2">
<li><a href="#con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</a></li>
<li><a href="#con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</a>
<ul class="sectlevel3">
<li><a href="#mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</a></li>
<li><a href="#when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</a></li>
<li><a href="#con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</a>
<ul class="sectlevel3">
<li><a href="#supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</a></li>
<li><a href="#when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</a></li>
<li><a href="#proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</a></li>
<li><a href="#deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</a></li>
<li><a href="#ref-kafka-user-using-uo">6.8. Kafka User resource</a>
<ul class="sectlevel3">
<li><a href="#authentication">6.8.1. Authentication</a></li>
<li><a href="#authorization">6.8.2. Authorization</a></li>
<li><a href="#additional_resources_4">6.8.3. Additional resources</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#security">7. Security</a>
<ul class="sectlevel2">
<li><a href="#certificates">7.1. Certificates</a></li>
<li><a href="#interbroker_kafka_communication">7.2. Interbroker Kafka Communication</a></li>
<li><a href="#zookeeper_communication">7.3. Zookeeper Communication</a></li>
<li><a href="#kafka_client_connections_via_tls">7.4. Kafka Client connections via TLS</a></li>
</ul>
</li>
<li><a href="#frequently_asked_questions">Appendix A: Frequently Asked Questions</a>
<ul class="sectlevel2">
<li><a href="#cluster_operator">A.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#log_contains_warnings_about_failing_to_acquire_lock">A.1.1. Log contains warnings about failing to acquire lock</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</a>
<ul class="sectlevel2">
<li><a href="#kubernetes">B.1. Kubernetes</a></li>
<li><a href="#openshift">B.2. OpenShift</a></li>
</ul>
</li>
<li><a href="#api_reference-str">Appendix C: Custom Resource API Reference</a>
<ul class="sectlevel2">
<li><a href="#type-Kafka-reference">C.1. <code>Kafka</code> schema reference</a></li>
<li><a href="#type-KafkaSpec-reference">C.2. <code>KafkaSpec</code> schema reference</a></li>
<li><a href="#type-KafkaClusterSpec-reference">C.3. <code>KafkaClusterSpec</code> schema reference</a></li>
<li><a href="#type-EphemeralStorage-reference">C.4. <code>EphemeralStorage</code> schema reference</a></li>
<li><a href="#type-PersistentClaimStorage-reference">C.5. <code>PersistentClaimStorage</code> schema reference</a></li>
<li><a href="#type-KafkaListeners-reference">C.6. <code>KafkaListeners</code> schema reference</a></li>
<li><a href="#type-KafkaListenerPlain-reference">C.7. <code>KafkaListenerPlain</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationTls-reference">C.8. <code>KafkaListenerAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationScramSha512-reference">C.9. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-KafkaListenerTls-reference">C.10. <code>KafkaListenerTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalRoute-reference">C.11. <code>KafkaListenerExternalRoute</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalLoadBalancer-reference">C.12. <code>KafkaListenerExternalLoadBalancer</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalNodePort-reference">C.13. <code>KafkaListenerExternalNodePort</code> schema reference</a></li>
<li><a href="#type-KafkaAuthorizationSimple-reference">C.14. <code>KafkaAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-Rack-reference">C.15. <code>Rack</code> schema reference</a></li>
<li><a href="#type-Probe-reference">C.16. <code>Probe</code> schema reference</a></li>
<li><a href="#type-JvmOptions-reference">C.17. <code>JvmOptions</code> schema reference</a></li>
<li><a href="#type-Resources-reference">C.18. <code>Resources</code> schema reference</a></li>
<li><a href="#type-CpuMemory-reference">C.19. <code>CpuMemory</code> schema reference</a></li>
<li><a href="#type-InlineLogging-reference">C.20. <code>InlineLogging</code> schema reference</a></li>
<li><a href="#type-ExternalLogging-reference">C.21. <code>ExternalLogging</code> schema reference</a></li>
<li><a href="#type-Sidecar-reference">C.22. <code>Sidecar</code> schema reference</a></li>
<li><a href="#type-ZookeeperClusterSpec-reference">C.23. <code>ZookeeperClusterSpec</code> schema reference</a></li>
<li><a href="#type-TopicOperatorSpec-reference">C.24. <code>TopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityOperatorSpec-reference">C.25. <code>EntityOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityTopicOperatorSpec-reference">C.26. <code>EntityTopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityUserOperatorSpec-reference">C.27. <code>EntityUserOperatorSpec</code> schema reference</a></li>
<li><a href="#type-KafkaConnect-reference">C.28. <code>KafkaConnect</code> schema reference</a></li>
<li><a href="#type-KafkaConnectSpec-reference">C.29. <code>KafkaConnectSpec</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationTls-reference">C.30. <code>KafkaConnectAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-CertAndKeySecretSource-reference">C.31. <code>CertAndKeySecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationScramSha512-reference">C.32. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-PasswordSecretSource-reference">C.33. <code>PasswordSecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectTls-reference">C.34. <code>KafkaConnectTls</code> schema reference</a></li>
<li><a href="#type-CertSecretSource-reference">C.35. <code>CertSecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2I-reference">C.36. <code>KafkaConnectS2I</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2ISpec-reference">C.37. <code>KafkaConnectS2ISpec</code> schema reference</a></li>
<li><a href="#type-KafkaTopic-reference">C.38. <code>KafkaTopic</code> schema reference</a></li>
<li><a href="#type-KafkaTopicSpec-reference">C.39. <code>KafkaTopicSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUser-reference">C.40. <code>KafkaUser</code> schema reference</a></li>
<li><a href="#type-KafkaUserSpec-reference">C.41. <code>KafkaUserSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUserTlsClientAuthentication-reference">C.42. <code>KafkaUserTlsClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserScramSha512ClientAuthentication-reference">C.43. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserAuthorizationSimple-reference">C.44. <code>KafkaUserAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-AclRule-reference">C.45. <code>AclRule</code> schema reference</a></li>
<li><a href="#type-AclRuleTopicResource-reference">C.46. <code>AclRuleTopicResource</code> schema reference</a></li>
<li><a href="#type-AclRuleGroupResource-reference">C.47. <code>AclRuleGroupResource</code> schema reference</a></li>
<li><a href="#type-AclRuleClusterResource-reference">C.48. <code>AclRuleClusterResource</code> schema reference</a></li>
</ul>
</li>
<li><a href="#metrics-str">Appendix D: Metrics</a>
<ul class="sectlevel2">
<li><a href="#deploying_on_openshift">D.1. Deploying on OpenShift</a>
<ul class="sectlevel3">
<li><a href="#prometheus">D.1.1. Prometheus</a></li>
<li><a href="#grafana">D.1.2. Grafana</a></li>
</ul>
</li>
<li><a href="#deploying_on_kubernetes">D.2. Deploying on Kubernetes</a>
<ul class="sectlevel3">
<li><a href="#prometheus_2">D.2.1. Prometheus</a></li>
<li><a href="#grafana_2">D.2.2. Grafana</a></li>
</ul>
</li>
<li><a href="#grafana_dashboard">D.3. Grafana dashboard</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="overview-str">1. Overview of Strimzi</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi makes it easy to run Apache Kafka on OpenShift or Kubernetes. Apache Kafka is a popular platform for streaming data delivery and processing. For more information about Apache Kafka, see the <a href="http://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka website</a>.</p>
</div>
<div class="paragraph">
<p>Strimzi is based on Apache Kafka 2.0.0 and consists of three main components:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Cluster Operator</dt>
<dd>
<p>Responsible for deploying and managing Apache Kafka clusters within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">Topic Operator</dt>
<dd>
<p>Responsible for managing Kafka topics within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">User Operator</dt>
<dd>
<p>Responsible for managing Kafka users within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>This guide describes how to install and use Strimzi.</p>
</div>
<div class="sect2">
<h3 id="key-features-str">1.1. Kafka Key Features</h3>
<div class="ulist">
<ul>
<li>
<p>Scalability and performance</p>
<div class="ulist">
<ul>
<li>
<p>Designed for horizontal scalability</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message ordering guarantee</p>
<div class="ulist">
<ul>
<li>
<p>At partition level</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message rewind/replay</p>
<div class="ulist">
<ul>
<li>
<p>"Long term" storage</p>
</li>
<li>
<p>Allows to reconstruct application state by replaying the messages</p>
</li>
<li>
<p>Combined with compacted topics allows to use Kafka as key-value store</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="document-conventions-str">1.2. Document Conventions</h3>
<div class="paragraph">
<div class="title">Replaceables</div>
<p>In this document, replaceable text is styled in monospace and surrounded by angle brackets.</p>
</div>
<div class="paragraph">
<p>For example, in the following code, you will want to replace <code><em>&lt;my-namespace&gt;</em></code> with the name of your namespace:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-namespace&gt;</em>/' examples/install/cluster-operator/*ClusterRoleBinding*.yaml</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="getting-started-str">2. Getting started with Strimzi</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi works on all types of clusters, from public and private clouds on to local deployments intended for development.
This guide expects that an OpenShift or Kubernetes cluster is available and the
<code>kubectl</code> and
<code>oc</code> command-line tools are installed and configured to connect to the running cluster.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Supported Versions</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Product</th>
<th class="tableblock halign-left valign-top">Version</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.9 and later</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenShift Origin</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.9 and later</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apache Kafka</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0.0</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>When no existing OpenShift or Kubernetes cluster is available, <code>Minikube</code> or <code>Minishift</code> can be used to create a local
cluster. More details can be found in <a href="#installing_kubernetes_and_openshift_cluster">Installing Kubernetes and OpenShift clusters</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
To run the commands in this guide, your
Kubernetes and
OpenShift Origin user must have the rights to manage role-based access control (RBAC).
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="downloads-str">2.1. Strimzi Downloads</h3>
<div class="paragraph">
<p>Strimzi releases are available for download from <a href="https://github.com/strimzi/strimzi-kafka-operator/releases" target="_blank" rel="noopener">GitHub</a>.
The release artifacts contain documentation
and example YAML files for deployment on OpenShift or Kubernetes.
The example files are used throughout this documentation and can be used to install Strimzi.
There is a Helm Chart for deployment the Cluster Operator, using <a href="https://helm.sh/" target="_blank" rel="noopener">Helm</a>, as well.
The container images are available through the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="cluster-operator-str">2.2. Cluster Operator</h3>
<div class="paragraph">
<p>Strimzi uses the Cluster Operator to deploy and manage Kafka (including Zookeeper) and Kafka Connect clusters.
The Cluster Operator is deployed inside of the
Kubernetes or
OpenShift cluster.
To deploy a Kafka cluster, a <code>Kafka</code> resource with the cluster configuration has to be created within the
Kubernetes or
OpenShift cluster.
Based on what is declared inside of the <code>Kafka</code> resource, the Cluster Operator deploys a corresponding Kafka cluster.
For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Strimzi contains example YAML files, which make deploying a Cluster Operator easier.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 1. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka or Kafka Connect cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, or <code>KafkaConnectS2I</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka or Kafka Connect cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka or Kafka Connect cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka or Kafka Connect cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-namespace&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f examples/install/cluster-operator -n _&lt;my-namespace&gt;_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-project&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/install/cluster-operator -n _&lt;my-project&gt;_
oc apply -f examples/templates/cluster-operator -n _&lt;my-project&gt;_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-namespace&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>examples/install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>&lt;my-namespace&gt;</em></code> or <code><em>&lt;my-project&gt;</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>&lt;my-namespace&gt;</em>
kubectl apply -f examples/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>&lt;my-namespace&gt;</em>
kubectl apply -f examples/install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>&lt;my-namespace&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>&lt;my-project&gt;</em>
oc apply -f examples/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>&lt;my-project&gt;</em>
oc apply -f examples/install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>&lt;my-project&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/cluster-operator -n <em>&lt;my-namespace&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/cluster-operator -n <em>&lt;my-project&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-str">2.2.5. Deploying the Cluster Operator using Helm Chart</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi https://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-cluster-str">2.3. Kafka cluster</h3>
<div class="paragraph">
<p>When installing Kafka, Strimzi also installs a Zookeeper cluster and adds the necessary configuration to connect Kafka with Zookeeper.</p>
</div>
<div class="paragraph">
<p>Strimzi provides two options for Kafka cluster deployment:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Ephemeral</dt>
<dd>
<p>is suitable only for development and testing purposes and not for production. This deployment uses <code>emptyDir</code> volumes for storing broker information (Zookeeper) and topics or partitions
(Kafka). Using an <code>emptyDir</code> volume means that its content is strictly related to the pod life cycle and is deleted when the pod goes down.</p>
</dd>
<dt class="hdlist1">Persistent</dt>
<dd>
<p>uses <code>PersistentVolumes</code> to store Zookeeper and Kafka data. The <code>PersistentVolume</code> is
acquired using a <code>PersistentVolumeClaim</code> to make it independent of the actual type of the <code>PersistentVolume</code>. For example, it can use
HostPath volumes on Minikube or
Amazon EBS volumes in Amazon AWS deployments without any changes in the YAML files. The <code>PersistentVolumeClaim</code> can use a <code>StorageClass</code> to trigger automatic volume provisioning.</p>
</dd>
</dl>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying a Kafka cluster, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you are planning to use the Kafka broker for development or testing, create an ephemeral cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you are planning to use the Kafka cluster in production, create a persistent cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
<li>
<p>For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</h4>
<div class="paragraph">
<p>OpenShift provides a template for deploying the Kafka cluster either in the OpenShift console or on the command-line.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying a Kafka cluster, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you are planning to use the Kafka cluster for development or testing, create an ephemeral cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you are planning to use the Kafka cluster in production, create a persistent cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>
For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-connect-str">2.4. Kafka Connect</h3>
<div class="paragraph">
<p>The Cluster Operator deploys a <a href="https://kafka.apache.org/documentation/#connect" target="_blank" rel="noopener">Kafka Connect</a> cluster, which can be used with your Kafka broker deployment.
It is implemented as a <code>Deployment</code> with a configurable number of workers.
The default image currently contains only the <code>FileStreamSinkConnector</code> and <code>FileStreamSourceConnector</code> connectors.
The REST interface for managing the Kafka Connect cluster is exposed internally within the OpenShift or Kubernetes cluster as a <code>kafka-connect</code> service on port <code>8083</code>.</p>
</div>
<div class="paragraph">
<p>Example <code>KafkaConnect</code> resources and the details about the <code>KafkaConnect</code> format for deploying Kafka Connect can be found in
<a href="#assembly-deployment-configuration-kafka-connect-str">Kafka Connect cluster configuration</a>
and
<a href="#assembly-deployment-configuration-kafka-connect-s2i-str">Kafka Connect cluster with Source2Image support</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Connect, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Deploy Kafka Connect on Kubernetes by creating the corresponding <code>KafkaConnect</code> resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to OpenShift</h4>
<div class="paragraph">
<p>On OpenShift, Kafka Connect is provided in the form of a template. It can be deployed from the template using the command-line or through the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Connect, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Create a Kafka Connect cluster from the command-line:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="using-kafka-connect-with-plugins-str">2.4.3. Using Kafka Connect with plugins</h4>
<div class="paragraph">
<p>Strimzi container images for Kafka Connect contain, by default, only the <code>FileStreamSinkConnector</code> and <code>FileStreamSourceConnector</code> connectors which are part of Apache Kafka.</p>
</div>
<div class="paragraph">
<p>To facilitate deployment with 3rd party connectors, Kafka Connect is configured to automatically load all plugins or connectors that are present in the <code>/opt/kafka/plugins</code> directory during startup.</p>
</div>
<div class="paragraph">
<p>There are two ways of adding custom plugins into this directory:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Using a custom Docker image</p>
</li>
<li>
<p>Using the OpenShift build system with the Strimzi S2I</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="creating-new-image-from-base-str">Create a new image based on our base image</h5>
<div class="paragraph">
<p>Strimzi provides its own Docker image for running Kafka Connect, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as
<code>strimzi/kafka-connect:0.7.0</code>.
This image can be used as a base image for building a new custom image with additional plugins.</p>
</div>
<div class="paragraph">
<p>The following procedure describes the process for creating such a custom image.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a new <code>Dockerfile</code> using <code>strimzi/kafka-connect:0.7.0</code> as the base image:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>FROM strimzi/kafka-connect:0.7.0
USER root:root
COPY ./<em>&lt;my-plugins&gt;</em>/ /opt/kafka/plugins/
USER kafka:kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Build the container image and upload it to the appropriate container image repository.</p>
</li>
<li>
<p>Set the <code>KafkaConnect.spec.image</code> property of the KafkaConnect custom resource or the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable to point to the new container image.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable, see <a href="#ref-operators-cluster-operator-configuration-deploying-co">Cluster Operator Configuration</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaConnect.spec.image property</code>, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">Container images</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="using-openshift-s2i-create-image-str">Using OpenShift builds and S2I to create new images</h5>
<div class="paragraph">
<p>OpenShift supports <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a>, which can be used together with the <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images.
An OpenShift build takes a builder image with S2I support together with source code and binaries provided by the user and uses them to build a new container image.
The newly created container image is stored in OpenShift&#8217;s local container image repository and can be used in deployments.
Strimzi provides a Kafka Connect builder image, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.7.0</code> with this S2I support.
It takes user-provided binaries (with plugins and connectors) and creates a new Kafka Connect image.
This enhanced Kafka Connect image can be used with the Kafka Connect deployment.</p>
</div>
<div class="paragraph">
<p>The S2I deployment provided as an OpenShift template. It can be deployed from the template using the command-line
or the OpenShift console.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a Kafka Connect S2I cluster from the command-line</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Once the cluster is deployed, a new build can be triggered from the command-line by creating a directory
with Kafka Connect plugins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>&lt;my-plugins&gt;</em>/
./<em>&lt;my-plugins&gt;</em>/
├── debezium-connector-mongodb
│   ├── bson-3.4.2.jar
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mongodb-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mongodb-driver-3.4.2.jar
│   ├── mongodb-driver-core-3.4.2.jar
│   └── README.md
├── debezium-connector-mysql
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mysql-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mysql-binlog-connector-java-0.13.0.jar
│   ├── mysql-connector-java-5.1.40.jar
│   ├── README.md
│   └── wkb-1.0.2.jar
└── debezium-connector-postgres
    ├── CHANGELOG.md
    ├── CONTRIBUTE.md
    ├── COPYRIGHT.txt
    ├── debezium-connector-postgres-0.7.1.jar
    ├── debezium-core-0.7.1.jar
    ├── LICENSE.txt
    ├── postgresql-42.0.0.jar
    ├── protobuf-java-2.6.1.jar
    └── README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Start a new image build using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>&lt;my-connect-cluster-connect&gt;</em> --from-dir ./<em>&lt;my-plugins&gt;</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build will be changed according to the cluster name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build is finished, the new image will be used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-example-clients-str">2.5. Deploying example clients</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the client to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the producer.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc run kafka-producer -ti --image=strimzi/kafka:0.7.0 --restart=Never \-- bin/kafka-console-producer.sh --broker-list <em>&lt;cluster-name&gt;</em>-kafka-bootstrap:9092 --topic <em>&lt;my-topic&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Type your message into the console where the producer is running.</p>
</li>
<li>
<p>Press Enter to send the message.</p>
</li>
<li>
<p>Deploy the consumer.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc run kafka-consumer -ti --image=strimzi/kafka:0.7.0 --restart=Never \-- bin/kafka-console-consumer.sh --bootstrap-server <em>&lt;cluster-name&gt;</em>-kafka-bootstrap:9092 --topic <em>&lt;my-topic&gt;</em> --from-beginning</code></pre>
</div>
</div>
</li>
<li>
<p>Confirm that you see the incoming messages in the consumer console.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-topic-operator-str">2.6. Topic Operator</h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-str">2.6.1. Overview of the Topic Operator component</h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will create the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-str">2.6.2. Deploying the Topic Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Topic Operator can be included in the Entity Operator.
Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator</code> object that configures the Entity Operator.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-user-operator-str">2.7. User Operator</h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-str">2.7.1. Overview of the User Operator component</h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-str">2.7.2. Deploying the User Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-deployment-configuration-str">3. Deployment configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This chapter describes how to configure different aspects of the supported deployments:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka clusters</p>
</li>
<li>
<p>Kafka Connect clusters</p>
</li>
<li>
<p>Kafka Connect clusters with <em>Source2Image</em> support</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</h3>
<div class="paragraph">
<p>The full schema of the <code>Kafka</code> resource is described in the <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.
All labels that are applied to the desired <code>Kafka</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</h4>
<div class="paragraph">
<p>Kafka brokers and Zookeeper are stateful applications.
They need to store data on disks.
Strimzi allows you to configure the type of storage, which they want to use for Kafka and Zookeeper.
Storage configuration is mandatory and has to be specified in every <code>Kafka</code> resource.</p>
</div>
<div class="paragraph">
<p>Storage can be configured using the <code>storage</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi supports two types of storage:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Ephemeral</p>
</li>
<li>
<p>Persistent</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The type of storage is specified in the <code>type</code> field.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Once the Kafka cluster is deployed, the storage cannot be changed.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="ref-ephemeral-storage-deployment-configuration-kafka">Ephemeral storage</h5>
<div class="paragraph">
<p>Ephemeral storage uses the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir" target="_blank" rel="noopener">`emptyDir` volumes</a> to store data.
To use ephemeral storage, the <code>type</code> field should be set to <code>ephemeral</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<code>EmptyDir</code> volumes are not persistent and the data stored in them will be lost when the Pod is restarted.
After the new pod is started, it has to recover all data from other nodes of the cluster.
Ephemeral storage is not suitable for use with single node Zookeeper clusters and for Kafka topics with replication factor 1, because it will lead to data loss.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example of Ephemeral storage</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: ephemeral
    # ...
  zookeeper:
    # ...
    storage:
      type: ephemeral
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="ref-persistent-storage-deployment-configuration-kafka">Persistent storage</h5>
<div class="paragraph">
<p>Persistent storage uses <a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/" target="_blank" rel="noopener">Persistent Volume Claims</a> to provision persistent volumes for storing data.
Persistent Volume Claims can be used to provision volumes of many different types, depending on the <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> which will provision the volume.
The data types which can be used with persistent volume claims include many types of SAN storage as well as <a href="https://kubernetes.io/docs/concepts/storage/volumes/#local" target="_blank" rel="noopener">Local persistent volumes</a>.</p>
</div>
<div class="paragraph">
<p>To use persistent storage, the <code>type</code> has to be set to <code>persistent-claim</code>.
Persistent storage supports additional configuration options:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>size</code> (required)</dt>
<dd>
<p>Defines the size of the persistent volume claim, for example, "1000Gi".</p>
</dd>
<dt class="hdlist1"><code>class</code> (optional)</dt>
<dd>
<p>The OpenShift or Kubernetes <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> to use for dynamic volume provisioning.</p>
</dd>
<dt class="hdlist1"><code>selector</code> (optional)</dt>
<dd>
<p>Allows selecting a specific persistent volume to use.
It contains a <code>matchLabels</code> field which contains key:value pairs representing labels for selecting such a volume.</p>
</dd>
<dt class="hdlist1"><code>delete-claim</code> (optional)</dt>
<dd>
<p>Boolean value which specifies if the Persistent Volume Claim has to be deleted when the cluster is undeployed.
Default is <code>false</code>.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Resizing persistent storage for existing Strimzi clusters is not currently supported.
You must decide the necessary storage size before deploying the cluster.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with 1000Gi <code>size</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1000Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following example demonstrates the use of a storage class.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with specific Storage Class</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  class: my-storage-class
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, a <code>selector</code> can be used to select a specific labeled persistent volume to provide needed features such as an SSD.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with selector</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  selector:
    matchLabels:
      "hdd-type": "ssd"
  deleteClaim: true
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">Persistent Volume Claim naming</div>
<p>When the persistent storage is used, it will create Persistent Volume Claims with the following names:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>data-<em>&lt;cluster-name&gt;</em>-kafka-<em>&lt;idx&gt;</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code>[idx]</code>.</p>
</dd>
<dt class="hdlist1"><code>data-<em>&lt;cluster-name&gt;</em>-zookeeper-<em>&lt;idx&gt;</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code>[idx]</code>.</p>
</dd>
</dl>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about ephemeral storage, see <a href="#type-EphemeralStorage-reference">ephemeral storage schema reference</a>.</p>
</li>
<li>
<p>For more information about persistent storage, see <a href="#type-PersistentClaimStorage-reference">persistent storage schema reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Replicas</h4>
<div class="paragraph">
<p>Kafka cluster can run with many brokers and Kafka brokers can run with various numbers of nodes.
The number of brokers used for the Kafka cluster is defined in the Kafka resource.
The best number of brokers for your cluster has to be determined based on your specific use case.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-broker-replicas-deployment-configuration-kafka">Configuring the number of broker nodes</h5>
<div class="paragraph">
<p>Number of Kafka broker nodes is configured using the <code>replicas</code> property in <code>Kafka.spec.kafka</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    replicas: 3
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka brokers.
You can specify and configure most of the options listed in <a href="http://kafka.apache.org/11/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Broker ID configuration</p>
</li>
<li>
<p>Configuration of log data directories</p>
</li>
<li>
<p>Inter-broker communication</p>
</li>
<li>
<p>Zookeeper connectivity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-broker-configuration-deployment-configuration-kafka">Kafka broker configuration</h5>
<div class="paragraph">
<p>Kafka broker can be configured using the <code>config</code> property in <code>Kafka.spec.kafka</code>.</p>
</div>
<div class="paragraph">
<p>This property should contain the Kafka broker configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://kafka.apache.org/11/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>advertised.</code></p>
</li>
<li>
<p><code>broker.</code></p>
</li>
<li>
<p><code>listener.</code></p>
</li>
<li>
<p><code>host.name</code></p>
</li>
<li>
<p><code>port</code></p>
</li>
<li>
<p><code>inter.broker.listener.name</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>password.</code></p>
</li>
<li>
<p><code>principal.builder.class</code></p>
</li>
<li>
<p><code>log.dir</code></p>
</li>
<li>
<p><code>zookeeper.connect</code></p>
</li>
<li>
<p><code>zookeeper.set.acl</code></p>
</li>
<li>
<p><code>authorizer.</code></p>
</li>
<li>
<p><code>super.user</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Cluster Operator log file.
All other options will be passed to Kafka.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Kafka cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.kafka.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka brokers.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka broker configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    config:
      num.partitions: 1
      num.recovery.threads.per.data.dir: 1
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      num.network.threads: 3
      num.io.threads: 8
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      group.initial.rebalance.delay.ms: 0
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-brokers-deployment-configuration-kafka">Configuring Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    config:
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</h4>
<div class="paragraph">
<p>Strimzi allows users to configure the listeners which will be enabled in Kafka brokers.
Two types of listeners are supported:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Plain listener on port 9092 (without encryption)</p>
</li>
<li>
<p>TLS listener on port 9093 (with encryption)</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="con-mutual-tls-authentication-deployment-configuration-kafka">Mutual TLS authentication for clients</h5>
<div class="sect5">
<h6 id="mutual_tls_authentication">Mutual TLS authentication</h6>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_mutual_tls_authentication_for_clients">When to use mutual TLS authentication for clients</h6>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-scram-sha-authentication-deployment-configuration-kafka">SCRAM-SHA authentication</h5>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRMA-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="supported_scram_credentials">Supported SCRAM credentials</h6>
<div class="paragraph">
<p>Strimzi supports SCRMA-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_scram_sha_authentication_for_clients">When to use SCRAM-SHA authentication for clients</h6>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-kafka-listeners-deployment-configuration-kafka">Kafka listeners</h5>
<div class="paragraph">
<p>You can configure Kafka broker listeners using the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
The <code>listeners</code> property contains three sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>plain</code></p>
</li>
<li>
<p><code>tls</code></p>
</li>
<li>
<p><code>external</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If these sub-properties are not defined, the listener is disabled.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with all listeners enabled</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
  tls: {}
# ...</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with only the plain listener enables</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
# ...</code></pre>
</div>
</div>
<div class="sect5">
<h6 id="external_listener">External listener</h6>
<div class="paragraph">
<p>The external listener is used to connect to a Kafka cluster from outside of an OpenShift or Kubernetes environment.
Strimzi supports three types of external listeners:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>route</code></p>
</li>
<li>
<p><code>loadbalancer</code></p>
</li>
<li>
<p><code>nodeport</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Each type of external listener uses TLS encryption.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using OpenShift Routes</div>
<p>An external listener of type <code>route</code> exposes Kafka by using OpenShift <code>Routes</code> and the HAProxy router.
A dedicated <code>Route</code> is created for every Kafka broker pod.
An additional <code>Route</code> is created to serve as a Kafka bootstrap address.
Kafka clients can use these <code>Routes</code> to connect to Kafka on port 443.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code>Routes</code> are available only on OpenShift. External listeners of type <code>route</code> cannot be used on Kubernetes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more information on using <code>Routes</code> to access Kafka, see <a href="#proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using loadbalancers</div>
<p>External listeners of type <code>loadbalancer</code> expose Kafka by using <code>Loadbalancer</code> type <code>Services</code>.
A new loadbalancer service is created for every Kafka broker pod.
An additional loadbalancer is created to serve as a Kafka <em>bootstrap</em> address.
Loadbalancers listen to connections on port 9094.</p>
</div>
<div class="paragraph">
<p>For more information on using loadbalancers to access Kafka, see <a href="#proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using node ports</div>
<p>External listeners of type <code>nodeport</code> expose Kafka by using <code>NodePort</code> type <code>Services</code>.
When exposing Kafka in this way, Kafka clients connect directly to the nodes of OpenShift or Kubernetes.
You must enable access to the ports on the OpenShift or Kubernetes nodes for each client (for example, in firewalls or security groups).
Each Kafka broker pod is then accessible on a separate port.
Additional <code>NodePort</code> type <code>Service</code> is created to serve as a Kafka bootstrap address.</p>
</div>
<div class="paragraph">
<p>When configuring the advertised addresses for the Kafka broker pods, Strimzi uses the address of the node on which the given pod is running.
When selecting the node address, the different address types are used with the following priority:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS hostname verification is not currently supported when exposing Kafka clusters using node ports.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more information on using node ports to access Kafka, see <a href="#proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="listener_authentication">Listener authentication</h6>
<div class="paragraph">
<p>The listener sub-properties can also contain additional configuration.
Both listeners support the <code>authentication</code> property. This is used to specify an authentication mechanism specific to that listener:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>mutual TLS authentication (only on the <code>tls</code> listener)</p>
</li>
<li>
<p>SCRAM-SHA authentication</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If no <code>authentication</code> property is specified then the listener does not authenticate clients which connect though that listener.</p>
</div>
<div class="listingblock">
<div class="title">An example where the plain listener is configured for SCRAM-SHA authentication and the <code>tls</code> listener with mutual TLS authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain:
    authentication:
      type: scram-sha-512
  tls:
    authentication:
      type: tls
  external:
    type: loadbalancer
    authentication:
      type: tls
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Authentication must be configured when using the User Operator to manage <code>KafkaUsers</code>.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-listeners-deployment-configuration-kafka">Configuring Kafka listeners</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>An example configuration of the plain (unencrypted) listener without authentication:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      plain: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>route</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use <code>Routes</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: route
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the address of the bootstrap <code>Route</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get routes _&lt;cluster-name&gt;_-kafka-bootstrap -o=jsonpath='{.status.ingress[0].host}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the address together with port 443 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Extract the public certificate of the broker certification authority</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/_&lt;cluster-name&gt;_-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>loadbalancer</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use loadbalancers:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: loadbalancer
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the hostname of the bootstrap loadbalancer.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If no hostname was found (nothing was returned by the command), use the loadbalancer IP address.</p>
</div>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the hostname or IP address together with port 9094 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Extract the public certificate of the broker certification authority.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>&lt;cluster-name&gt;</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>&lt;cluster-name&gt;</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>nodeport</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use node ports:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: nodeport
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the port number of the bootstrap service.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>The port should be used in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Find the address of the OpenShift or Kubernetes node.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get node <em>&lt;node-name&gt;</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get node <em>&lt;node-name&gt;</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If several different addresses are returned, select the address type you want based on the following order:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
<div class="paragraph">
<p>Use the address with the port found in the previous step in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>Extract the public certificate of the broker certification authority</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>&lt;cluster-name&gt;</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>&lt;cluster-name&gt;</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</h4>
<div class="paragraph">
<p>Strimzi supports authentication and authorization.
Authentication can be configured independently for each <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener</a>.
Authorization is always configured for the whole Kafka cluster.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-authentication-deployment-configuration-kafka">Authentication</h5>
<div class="paragraph">
<p>Authentication is configured as part of the <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener configuration</a> in the <code>authentication</code> property.
When the <code>authentication</code> property is missing, no authentication will be enabled on given listener.
The authentication mechanism which will be used is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>Currently, the only supported authentication mechanism is the TLS client authentication.</p>
</div>
<div class="sect5">
<h6 id="tls_client_authentication">TLS Client Authentication</h6>
<div class="paragraph">
<p>TLS Client authentication can be enabled by specifying the <code>type</code> as <code>tls</code>.
The TLS client authentication is supported only on the <code>tls</code> listener.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>authentication</code> with type <code>tls</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authentication:
  type: tls
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authentication-deployment-configuration-kafka">Configuring authentication in Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
Add the <code>authentication</code> field to the listeners where you want to enable authentication.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      tls:
        authentication:
          type: tls
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authentication mechanisms, see <a href="#ref-kafka-authentication-deployment-configuration-kafka">authentication reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="ref-kafka-authorization-deployment-configuration-kafka">Authorization</h5>
<div class="paragraph">
<p>Authorization can be configured using the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
When the <code>authorization</code> property is missing, no authorization will be enabled.
When authorization is enabled it will be applied for all enabled <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listeners</a>.
The authorization method is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>Currently, the only supported authorization method is the Simple authorization.</p>
</div>
<div class="sect5">
<h6 id="simple_authorization">Simple authorization</h6>
<div class="paragraph">
<p>Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
To enable simple authorization, the <code>type</code> field should be set to <code>simple</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of Simple authorization</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authorization:
  type: simple
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authorization-deployment-configuration-kafka">Configuring authorization in Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add or edit the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    authorization:
      type: simple
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authorization methods, see <a href="#ref-kafka-authorization-deployment-configuration-kafka">authorization reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Replicas</h4>
<div class="paragraph">
<p>Zookeeper clusters or ensembles usually run with an odd number of nodes and always requires the majority of the nodes to be available in order to maintain a quorum.
Maintaining a quorum is important because when the Zookeeper cluster loses a quorum, it will stop responding to clients.
As a result, a Zookeeper cluster without a quorum will cause the Kafka brokers to stop working as well.
This is why having a stable and highly available Zookeeper cluster is very important for Strimzi.</p>
</div>
<div class="paragraph">
<p>A Zookeeper cluster is usually deployed with three, five, or seven nodes.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Three nodes</dt>
<dd>
<p>Zookeeper cluster consisting of three nodes requires at least two nodes to be up and running in order to maintain the quorum.
It can tolerate only one node being unavailable.</p>
</dd>
<dt class="hdlist1">Five nodes</dt>
<dd>
<p>Zookeeper cluster consisting of five nodes requires at least three nodes to be up and running in order to maintain the quorum.
It can tolerate two nodes being unavailable.</p>
</dd>
<dt class="hdlist1">Seven nodes</dt>
<dd>
<p>Zookeeper cluster consisting of seven nodes requires at least four nodes to be up and running in order to maintain the quorum.
It can tolerate three nodes being unavailable.</p>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For development purposes, it is also possible to run Zookeeper with a single node.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Having more nodes does not necessarily mean better performance, as the costs to maintain the quorum will rise with the number of nodes in the cluster.
Depending on your availability requirements, you can decide for the number of nodes to use.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-replicas-deployment-configuration-kafka">Number of Zookeeper nodes</h5>
<div class="paragraph">
<p>The number of Zookeeper nodes can be configured using the <code>replicas</code> property in <code>Kafka.spec.zookeeper</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing replicas configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-replicas-deployment-configuration-kafka">Changing number of replicas</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Zookeeper nodes.
You can specify and configure most of the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Configuration of data directories</p>
</li>
<li>
<p>Zookeeper cluster composition</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-node-configuration-deployment-configuration-kafka">Zookeeper configuration</h5>
<div class="paragraph">
<p>Zookeeper nodes can be configured using the <code>config</code> property in <code>Kafka.spec.zookeeper</code>.
This property should contain the Zookeeper configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>server.</code></p>
</li>
<li>
<p><code>dataDir</code></p>
</li>
<li>
<p><code>dataLogDir</code></p>
</li>
<li>
<p><code>clientPort</code></p>
</li>
<li>
<p><code>authProvider</code></p>
</li>
<li>
<p><code>quorum.auth</code></p>
</li>
<li>
<p><code>requireClientAuthScheme</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Zookeeper.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Zookeeper cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.zookeeper.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Zookeeper nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>timeTick</code> with default value <code>2000</code></p>
</li>
<li>
<p><code>initLimit</code> with default value <code>5</code></p>
</li>
<li>
<p><code>syncLimit</code> with default value <code>2</code></p>
</li>
<li>
<p><code>autopurge.purgeInterval</code> with default value <code>1</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured when they are not present in the <code>Kafka.spec.zookeeper.config</code> property.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Zookeeper configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-nodes-deployment-configuration-kafka">Configuring Zookeeper</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</h4>
<div class="paragraph">
<p>The Entity Operator is responsible for managing different entities in a running Kafka cluster.
The currently supported entities are:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Kafka topics</dt>
<dd>
<p>managed by the Topic Operator.</p>
</dd>
<dt class="hdlist1">Kafka users</dt>
<dd>
<p>managed by the User Operator</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Both Topic and User Operators can be deployed on their own.
But the easiest way to deploy them is together with the Kafka cluster as part of the Entity Operator.
The Entity Operator can include either one or both of them depending on the configuration.
They will be automatically configured to manage the topics and users of the Kafka cluster with which they are deployed.</p>
</div>
<div class="paragraph">
<p>For more information about Topic Operator, see <a href="#deploying-the-topic-operator-str">Topic Operator</a>.
For more information about how to use Topic Operator to create or delete topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-entity-operator-deployment-configuration-kafka">Configuration</h5>
<div class="paragraph">
<p>The Entity Operator can be configured using the <code>entityOperator</code> property in <code>Kafka.spec</code></p>
</div>
<div class="paragraph">
<p>The <code>entityOperator</code> property supports several sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tlsSidecar</code></p>
</li>
<li>
<p><code>affinity</code></p>
</li>
<li>
<p><code>tolerations</code></p>
</li>
<li>
<p><code>topicOperator</code></p>
</li>
<li>
<p><code>userOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>tlsSidecar</code> property can be used to configure the TLS sidecar container which is used to communicate with Zookeeper.
For more details about configuring the TLS sidecar, see <a href="#assembly-tls-sidecar-deployment-configuration-kafka">TLS sidecar</a>.</p>
</div>
<div class="paragraph">
<p>The <code>affinity</code> and <code>tolerations</code> properties can be used to configure how OpenShift or Kubernetes schedules the Entity Operator pod.
For more details about pod scheduling, see <a href="#assembly-scheduling-deployment-configuration-kafka">Configuring pod scheduling</a>.</p>
</div>
<div class="paragraph">
<p>The <code>topicOperator</code> property contains the configuration of the Topic Operator.
When this option is missing, the Entity Operator will be deployed without the Topic Operator.</p>
</div>
<div class="paragraph">
<p>The <code>userOperator</code> property contains the configuration of the User Operator.
When this option is missing, the Entity Operator will be deployed without the User Operator.</p>
</div>
<div class="listingblock">
<div class="title">Example of basic configuration enabling both operators</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator: {}
    userOperator: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>When both <code>topicOperator</code> and <code>userOperator</code> properties are missing, the Entity Operator will be not deployed.</p>
</div>
<div class="sect5">
<h6 id="topic_operator">Topic Operator</h6>
<div class="paragraph">
<p>Topic Operator deployment can be configured using additional options inside the <code>topicOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaTopics</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 90.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 20 seconds.</p>
</dd>
<dt class="hdlist1"><code>topicMetadataMaxAttempts</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its many partitions or replicas. Default is <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the Topic Operator
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the Topic Operator
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="user_operator">User Operator</h6>
<div class="paragraph">
<p>User Operator deployment can be configured using additional options inside the <code>userOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaUsers</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 120.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 6 seconds.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the User Operator.
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the User Operator.
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-entity-operator-deployment-configuration-kafka">Configuring Entity Operator</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>entityOperator</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka">3.1.10. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>&lt;logger.name&gt;</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</h4>
<div class="paragraph">
<p>The rack awareness feature in Strimzi helps to spread the Kafka broker pods and Kafka topic replicas across different racks.
Enabling rack awareness helps to improve availability of Kafka brokers and the topics they are hosting.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
"Rack" might represent an availability zone, data center, or an actual rack in your data center.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-rack-awareness-deployment-configuration-kafka">Configuring rack awareness in Kafka brokers</h5>
<div class="paragraph">
<p>Kafka rack awareness can be configured in the <code>rack</code> property of <code>Kafka.spec.kafka</code>.
The <code>rack</code> object has one mandatory field named <code>topologyKey</code>.
This key needs to match one of the labels assigned to the OpenShift or Kubernetes cluster nodes.
The label is used by OpenShift or Kubernetes when scheduling the Kafka broker pods to nodes.
If the OpenShift or Kubernetes cluster is running on a cloud provider platform, that label should represent the availability zone where the node is running.
Usually, the nodes are labeled with <code>failure-domain.beta.kubernetes.io/zone</code> that can be easily used as the <code>topologyKey</code> value.
This has the effect of spreading the broker pods across zones, and also setting the brokers' <code>broker.rack</code> configuration parameter inside Kafka broker.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Consult your OpenShift or Kubernetes administrator regarding the node label that represent the zone / rack into which the node is deployed.</p>
</li>
<li>
<p>Edit the <code>rack</code> property in the <code>Kafka</code> resource using the label as the topology key.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    rack:
      topologyKey: failure-domain.beta.kubernetes.io/zone
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional Resources</div>
<ul>
<li>
<p>For information about Configuring init container image for Kafka rack awareness, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xmx</div>
<p><code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default value used for <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory request</a> configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory request, the JVM&#8217;s maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>When there is no memory request, the JVM&#8217;s maximum memory will be set according to the RAM available to the container.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<div class="title">-Xms</div>
<p><code>-Xms</code> configures the initial heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Setting the same value for initial and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</h4>
<div class="paragraph">
<p>Sidecar is a container which is running in a pod and serves an auxiliary purpose.
The purpose of the TLS sidecar is to encrypt or decrypt the communication between Strimzi components and Zookeeper since Zookeeper does not support TLS encryption natively.
Zookeeper does not support TLS encryption natively.
Therefore Strimzi uses the sidecar to add the TLS support.</p>
</div>
<div class="paragraph">
<p>The TLS sidecar is currrently being used in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka brokers</p>
</li>
<li>
<p>Zookeeper</p>
</li>
<li>
<p>Entity Operator</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="ref-tls-sidecar-deployment-configuration-kafka">TLS sidecar configuration</h5>
<div class="paragraph">
<p>The TLS sidecar can be configured using the <code>tlsSidecar</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The TLS sidecar supports two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>image</code></p>
</li>
<li>
<p><code>resources</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>resources</code> property can be used to specify the <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory and CPU resources</a> allocated for the TLS sidecar.</p>
</div>
<div class="paragraph">
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      image: my-org/my-image:latest
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-tls-sidecar-deployment-configuration-kafka">Configuring TLS sidecar</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>tlsSidecar</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.18. List of resources created as part of Kafka cluster</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-brokers</code></dt>
<dd>
<p>Service needed to have DNS resolve the Kafka broker pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-bootstrap</code></dt>
<dd>
<p>Service can be used as bootstrap servers for Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap service for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-<em>&lt;pod-id&gt;</em></code></dt>
<dd>
<p>Service used to route traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap route for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-<em>&lt;pod-id&gt;</em></code></dt>
<dd>
<p>Route for traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-config</code></dt>
<dd>
<p>ConfigMap which contains the Kafka ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka-brokers</code></dt>
<dd>
<p>Secret with Kafka broker keys.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-kafka</code></dt>
<dd>
<p>Service account used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>&lt;namespace-name&gt;</em>-<em>&lt;cluster-name&gt;</em>-kafka-init</code></dt>
<dd>
<p>Cluster role binding used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-zookeeper</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-zookeeper-nodes</code></dt>
<dd>
<p>Service needed to have DNS resolve the Zookeeper pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-zookeeper-client</code></dt>
<dd>
<p>Service used by Kafka brokers to connect to Zookeeper nodes as clients.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-zookeeper-config</code></dt>
<dd>
<p>ConfigMap which contains the Zookeeper ancillary configuration and is mounted as a volume by the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-zookeeper-nodes</code></dt>
<dd>
<p>Secret with Zookeeper node keys.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-entity-operator</code></dt>
<dd>
<p>Deployment with Topic and User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-entity-topic-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for Topic Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-entity-user-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-entity-operator-certs</code></dt>
<dd>
<p>Secret with Entitiy operators keys for communication with Kafka and Zookeeper. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-entity-operator</code></dt>
<dd>
<p>Service account used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>&lt;cluster-name&gt;</em>-topic-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>&lt;cluster-name&gt;</em>-user-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-cluster-ca</code></dt>
<dd>
<p>Secret with the Cluster CA used to encrypt the cluster communication.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-cluster-ca-cert</code></dt>
<dd>
<p>Secret with the Cluster CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-clients-ca</code></dt>
<dd>
<p>Secret with the Clients CA used to encrypt the communication between Kafka brokers and Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>&lt;cluster-name&gt;</em>-clients-ca-cert</code></dt>
<dd>
<p>Secret with the Clients CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>data-<em>&lt;cluster-name&gt;</em>-kafka-<em>&lt;idx&gt;</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code>&lt;idx&gt;</code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
<dt class="hdlist1"><code>data-<em>&lt;cluster-name&gt;</em>-zookeeper-<em>&lt;idx&gt;</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code>&lt;idx&gt;</code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnect</code> resource is described in the <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnect</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect">Configuring the number of broker nodes</h5>
<div class="paragraph">
<p>Number of Kafka broker nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>&lt;cluster-name&gt;</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code>&lt;hostname&gt;:&lt;port&gt;</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-bootstrap-servers-deployment-configuration-kafka-connect">Configuring bootstrap servers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect">TLS support in Kafka Connect</h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect">Configuring TLS in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect">Authentication support in Kafka Connect</h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_2">TLS Client Authentication</h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication">SCRAM-SHA-512 authentication</h6>
<div class="paragraph">
<p>To use the authentication using the SCRAM-SHA-512 SASL mechanism, set the <code>type</code> property to the value <code>scram-sha-512</code>.
SCRAM-SHA-512 uses a username and password to authenticate.
Specify the username in the <code>username</code> property.
Specify the password as a link to a <code>Secret</code> containing the password in the <code>passwordSecret</code> property.
It has to specify the name of the <code>Secret</code> containing the password and the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: password
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect">Configuring TLS client authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect">Configuring SCRAM-SHA-512 authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password.txt&gt;</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _&lt;my-username&gt;_
    passwordSecret:
      secretName: _&lt;my-secret&gt;_
      password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/11/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect">Kafka Connect configuration</h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/11/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
<li>
<p><code>internal.value.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect">Configuring Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_2">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_2">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_2">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_2">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_2">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>&lt;logger.name&gt;</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xmx</div>
<p><code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default value used for <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory request</a> configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory request, the JVM&#8217;s maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>When there is no memory request, the JVM&#8217;s maximum memory will be set according to the RAM available to the container.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<div class="title">-Xms</div>
<p><code>-Xms</code> configures the initial heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Setting the same value for initial and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka-connect" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-cluster-resources-deployment-configuration-kafka-connect">3.2.13. List of resources created as part of Kafka Connect cluster</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect</dt>
<dd>
<p>Deployment which is in charge to create the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnectS2I</code> resource is described in the <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnectS2I</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster with Source2Image support.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">Configuring the number of broker nodes</h5>
<div class="paragraph">
<p>Number of Kafka broker nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>&lt;cluster-name&gt;</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code>&lt;hostname&gt;:&lt;port&gt;</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-bootstrap-servers-deployment-configuration-kafka-connect-s2i">Configuring bootstrap servers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">TLS support in Kafka Connect</h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect-s2i">Authentication support in Kafka Connect</h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_3">TLS Client Authentication</h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication_2">SCRAM-SHA-512 authentication</h6>
<div class="paragraph">
<p>To use the authentication using the SCRAM-SHA-512 SASL mechanism, set the <code>type</code> property to the value <code>scram-sha-512</code>.
SCRAM-SHA-512 uses a username and password to authenticate.
Specify the username in the <code>username</code> property.
Specify the password as a link to a <code>Secret</code> containing the password in the <code>passwordSecret</code> property.
It has to specify the name of the <code>Secret</code> containing the password and the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: password
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS client authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect-s2i">Configuring SCRAM-SHA-512 authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password.txt&gt;</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _&lt;my-username&gt;_
    passwordSecret:
      secretName: _&lt;my-secret&gt;_
      password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/11/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">Kafka Connect configuration</h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/11/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
<li>
<p><code>internal.value.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect-s2i">Configuring Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_3">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_3">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_3">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_3">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_3">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect-s2i">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>&lt;logger.name&gt;</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect-s2i">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect-s2i">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect-s2i">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect-s2i">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect-s2i">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect-s2i">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect-s2i">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xmx</div>
<p><code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default value used for <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory request</a> configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory request, the JVM&#8217;s maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>When there is no memory request, the JVM&#8217;s maximum memory will be set according to the RAM available to the container.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<div class="title">-Xms</div>
<p><code>-Xms</code> configures the initial heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Setting the same value for initial and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect-s2i">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect-s2i">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect-s2i">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka-connect-s2i" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-s2i-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-s2i-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>&lt;your-node&gt;</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>&lt;your-node&gt;</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-cluster-resources-deployment-configuration-kafka-connect-s2i">3.3.13. List of resources created as part of Kafka Connect cluster with Source2Image support</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect-source</dt>
<dd>
<p>ImageStream which is used as the base image for the newly-built Docker images.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect</dt>
<dd>
<p>BuildConfig which is responsible for building the new Kafka Connect Docker images.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect</dt>
<dd>
<p>ImageStream where the newly built Docker images will be pushed.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect</dt>
<dd>
<p>DeploymentConfig which is in charge of creating the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>&lt;connect-cluster-name&gt;</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.14. Using OpenShift builds and S2I to create new images</h4>
<div class="paragraph">
<p>OpenShift supports <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a>, which can be used together with the <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images.
An OpenShift build takes a builder image with S2I support together with source code and binaries provided by the user and uses them to build a new container image.
The newly created container image is stored in OpenShift&#8217;s local container image repository and can be used in deployments.
Strimzi provides a Kafka Connect builder image, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.7.0</code> with this S2I support.
It takes user-provided binaries (with plugins and connectors) and creates a new Kafka Connect image.
This enhanced Kafka Connect image can be used with the Kafka Connect deployment.</p>
</div>
<div class="paragraph">
<p>The S2I deployment provided as an OpenShift template. It can be deployed from the template using the command-line
or the OpenShift console.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a Kafka Connect S2I cluster from the command-line</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Once the cluster is deployed, a new build can be triggered from the command-line by creating a directory
with Kafka Connect plugins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>&lt;my-plugins&gt;</em>/
./<em>&lt;my-plugins&gt;</em>/
├── debezium-connector-mongodb
│   ├── bson-3.4.2.jar
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mongodb-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mongodb-driver-3.4.2.jar
│   ├── mongodb-driver-core-3.4.2.jar
│   └── README.md
├── debezium-connector-mysql
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mysql-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mysql-binlog-connector-java-0.13.0.jar
│   ├── mysql-connector-java-5.1.40.jar
│   ├── README.md
│   └── wkb-1.0.2.jar
└── debezium-connector-postgres
    ├── CHANGELOG.md
    ├── CONTRIBUTE.md
    ├── COPYRIGHT.txt
    ├── debezium-connector-postgres-0.7.1.jar
    ├── debezium-core-0.7.1.jar
    ├── LICENSE.txt
    ├── postgresql-42.0.0.jar
    ├── protobuf-java-2.6.1.jar
    └── README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Start a new image build using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>&lt;my-connect-cluster-connect&gt;</em> --from-dir ./<em>&lt;my-plugins&gt;</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build will be changed according to the cluster name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build is finished, the new image will be used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-operators-str">4. Operators</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="assembly-operators-cluster-operator-str">4.1. Cluster Operator</h3>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 2. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka or Kafka Connect cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, or <code>KafkaConnectS2I</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka or Kafka Connect cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka or Kafka Connect cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka or Kafka Connect cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-namespace&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f examples/install/cluster-operator -n _&lt;my-namespace&gt;_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-project&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/install/cluster-operator -n _&lt;my-project&gt;_
oc apply -f examples/templates/cluster-operator -n _&lt;my-project&gt;_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>&lt;my-namespace&gt;</em>/' examples/install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>examples/install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>&lt;my-namespace&gt;</em></code> or <code><em>&lt;my-project&gt;</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>&lt;my-namespace&gt;</em>
kubectl apply -f examples/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>&lt;my-namespace&gt;</em>
kubectl apply -f examples/install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>&lt;my-namespace&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>&lt;my-project&gt;</em>
oc apply -f examples/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>&lt;my-project&gt;</em>
oc apply -f examples/install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>&lt;my-project&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/cluster-operator -n <em>&lt;my-namespace&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/cluster-operator -n <em>&lt;my-project&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-deploying-co">4.1.5. Deploying the Cluster Operator using Helm Chart</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi https://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-reconciliation-deploying-co">4.1.6. Reconciliation</h4>
<div class="paragraph">
<p>Although the operator reacts to all notifications about the desired cluster resources received from the OpenShift or Kubernetes cluster,
if the operator is not running, or if a notification is not received for any reason, the desired resources will get out of sync with the state of the running OpenShift or Kubernetes cluster.</p>
</div>
<div class="paragraph">
<p>In order to handle failovers properly, a periodic reconciliation process is executed by the Cluster Operator so that it can compare the state of the desired resources with the current cluster deployments in order to have a consistent state across all of them.
You can set the time interval for the periodic reconciliations using the <a href="#STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></a> variable.</p>
</div>
</div>
<div class="sect3">
<h4 id="ref-operators-cluster-operator-configuration-deploying-co">4.1.7. Cluster Operator Configuration</h4>
<div class="paragraph">
<p>The Cluster Operator can be configured through the following supported environment variables:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_NAMESPACE</code></dt>
<dd>
<p>Required. A comma-separated list of namespaces that the operator should
operate in. The Cluster Operator deployment might use the <a href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api" target="_blank" rel="noopener">Kubernetes Downward API</a>
to set this automatically to the namespace the Cluster Operator is deployed in. See the example below:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">env:
  - name: STRIMZI_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1"><a id="STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"></a> <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>Optional, default: 120000 ms. The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>Optional, default <code>INFO</code>.
The level for printing logging messages. The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_OPERATION_TIMEOUT_MS</code></dt>
<dd>
<p>Optional, default: 300000 ms. The timeout for internal operations, in milliseconds. This value should be
increased when using Strimzi on clusters where regular OpenShift or Kubernetes operations take longer than usual (because of slow downloading of Docker images, for example).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka:latest</code>.
The image name to use as the default when deploying Kafka, if
no image is specified as the <code>Kafka.spec.kafka.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_INIT_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-init:latest</code>.
The image name to use as default for the init container started before the broker for initial configuration work (that is, rack support), if no image is specified as the <code>kafka-init-image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Kafka,
if no image is specified as the <code>Kafka.spec.kafka.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper:latest</code>.
The image name to use as the default when deploying Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-connect:latest</code>.
The image name to use as the default when deploying Kafka Connect,
if no image is specified as the <code>image</code> in the Kafka Connect cluster ConfigMap</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-connect-s2i:latest</code>.
The image name to use as the default when deploying Kafka Connect S2I,
if no image is specified as the <code>image</code> in the cluster ConfigMap.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/topic-operator:latest</code>.
The image name to use as the default when deploying the topic operator,
if no image is specified as the <code>Kafka.spec.entityOperator.topicOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/user-operator:latest</code>.
The image name to use as the default when deploying the user operator,
if no image is specified as the <code>Kafka.spec.entityOperator.userOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/entity-operator-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for the Entity Operator, if
no image is specified as the <code>Kafka.spec.entityOperator.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-rbac-deploying-co">4.1.8. Role-Based Access Control (RBAC)</h4>
<div class="sect4">
<h5 id="provisioning_role_based_access_control_rbac_for_the_cluster_operator">Provisioning Role-Based Access Control (RBAC) for the Cluster Operator</h5>
<div class="paragraph">
<p>For the Cluster Operator to function it needs permission within the OpenShift or Kubernetes cluster to interact with resources such as <code>Kafka</code>, <code>KafkaConnect</code>, and so on, as well as the managed resources, such as <code>ConfigMaps</code>, <code>Pods</code>, <code>Deployments</code>, <code>StatefulSets</code>, <code>Services</code>, and so on.
Such permission is described in terms of OpenShift or Kubernetes role-based access control (RBAC) resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ServiceAccount</code>,</p>
</li>
<li>
<p><code>Role</code> and <code>ClusterRole</code>,</p>
</li>
<li>
<p><code>RoleBinding</code> and <code>ClusterRoleBinding</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In addition to running under its own <code>ServiceAccount</code> with a <code>ClusterRoleBinding</code>, the Cluster Operator manages some RBAC resources for the components that need access to OpenShift or Kubernetes resources.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes also includes privilege escalation protections that prevent components operating under one <code>ServiceAccount</code> from granting other <code>ServiceAccounts</code> privileges that the granting <code>ServiceAccount</code> does not have.
Because the Cluster Operator must be able to create the <code>ClusterRoleBindings</code>, and <code>RoleBindings</code> needed by resources it manages, the Cluster Operator must also have those same privileges.</p>
</div>
</div>
<div class="sect4">
<h5 id="delegated-privileges-deploying-co">Delegated privileges</h5>
<div class="paragraph">
<p>When the Cluster Operator deploys resources for a desired <code>Kafka</code> resource it also creates <code>ServiceAccounts</code>, <code>RoleBindings</code>, and <code>ClusterRoleBindings</code>, as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The Kafka broker pods use a <code>ServiceAccount</code> called <code><em>&lt;cluster-name&gt;</em>-kafka</code></p>
<div class="ulist">
<ul>
<li>
<p>When the rack feature is used, the <code>strimzi-<em>&lt;cluster-name&gt;</em>-kafka-init</code> <code>ClusterRoleBinding</code> is used to grant this <code>ServiceAccount</code> access to the nodes within the cluster via a <code>ClusterRole</code> called <code>strimzi-kafka-broker</code></p>
</li>
<li>
<p>When the rack feature is not used no binding is created.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The Zookeeper pods use the default <code>ServiceAccount</code>, as they do not need access to the OpenShift or Kubernetes resources.</p>
</li>
<li>
<p>The Topic Operator pod uses a <code>ServiceAccount</code> called <code><em>&lt;cluster-name&gt;</em>-topic-operator</code></p>
<div class="ulist">
<ul>
<li>
<p>The Topic Operator produces OpenShift or Kubernetes events with status information, so the <code>ServiceAccount</code> is bound to a <code>ClusterRole</code> called <code>strimzi-topic-operator</code> which grants this access via the <code>strimzi-topic-operator-role-binding</code> <code>RoleBinding</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The pods for <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources use the default <code>ServiceAccount</code>, as they do not require access to the OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect4">
<h5 id="serviceaccount"><code>ServiceAccount</code></h5>
<div class="paragraph">
<p>The Cluster Operator is best run using a <code>ServiceAccount</code>:</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ServiceAccount</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Deployment</code> of the operator then needs to specify this in its <code>spec.template.spec.serviceAccountName</code>:</p>
</div>
<div class="listingblock">
<div class="title">Partial example of <code>Deployment</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
    spec:
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note line 12, where the the <code>strimzi-cluster-operator</code> <code>ServiceAccount</code> is specified as the <code>serviceAccountName</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="clusterroles"><code>ClusterRoles</code></h5>
<div class="paragraph">
<p>The Cluster Operator needs to operate using <code>ClusterRoles</code> that gives access to the necessary resources.
Depending on the OpenShift or Kubernetes cluster setup, a cluster administrator might be needed to create the <code>ClusterRoles</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Cluster administrator rights are only needed for the creation of the <code>ClusterRoles</code>.
The Cluster Operator will not run under the cluster admin account.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <code>ClusterRoles</code> follow the <em>principle of least privilege</em> and contain only those privileges needed by the Cluster Operator to operate Kafka, Kafka Connect, and Zookeeper clusters. The first set of assigned privileges allow the Cluster Operator to manage OpenShift or Kubernetes resources such as <code>StatefulSets</code>, <code>Deployments</code>, <code>Pods</code>, and <code>ConfigMaps</code>.</p>
</div>
<div class="paragraph">
<p>Cluster Operator uses ClusterRoles to grant permission at the namespace-scoped resources level and cluster-scoped resources level:</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with namespaced resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - serviceaccounts
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - rolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkas
  - kafkaconnects
  - kafkaconnects2is
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
  - delete
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - deployments
  - deployments/scale
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps
  resources:
  - deployments
  - deployments/scale
  - deployments/status
  - statefulsets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - extensions
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps.openshift.io
  resources:
  - deploymentconfigs
  - deploymentconfigs/scale
  - deploymentconfigs/status
  - deploymentconfigs/finalizers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - build.openshift.io
  resources:
  - buildconfigs
  - builds
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - watch
  - update
- apiGroups:
  - image.openshift.io
  resources:
  - imagestreams
  - imagestreams/status
  verbs:
  - create
  - delete
  - get
  - list
  - watch
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - extensions
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
  - routes
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The second includes the permissions needed for cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with cluster-scoped resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
rules:
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - clusterrolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-kafka-broker</code> <code>ClusterRole</code> represents the access needed by the init container in Kafka pods that is used for the rack feature. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to OpenShift or Kubernetes nodes to the Kafka broker pods</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-topic-operator</code> <code>ClusterRole</code> represents the access needed by the Topic Operator. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to events to the Topic Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
rules:
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkatopics
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkausers
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - patch
  - update
  - delete</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="clusterrolebindings"><code>ClusterRoleBindings</code></h5>
<div class="paragraph">
<p>The operator needs <code>ClusterRoleBindings</code> and <code>RoleBindings</code> which associates its <code>ClusterRole</code> with its <code>ServiceAccount</code>:
<code>ClusterRoleBindings</code> are needed for <code>ClusterRoles</code> containing cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ClusterRoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoleBindings</code> are also needed for the <code>ClusterRoles</code> needed for delegation:</p>
</div>
<div class="listingblock">
<div class="title">Examples <code>RoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoles</code> containing only namespaced resources are bound using <code>RoleBindings</code> only.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-the-topic-operator-str">4.2. Topic Operator</h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will create the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</h4>
<div class="paragraph">
<p>A fundamental problem that the operator has to solve is that there is no single source of truth:
Both the <code>KafkaTopic</code> resource and the topic within Kafka can be modified independently of the operator.
Complicating this, the Topic Operator might not always be able to observe changes at each end in real time (for example, the operator might be down).</p>
</div>
<div class="paragraph">
<p>To resolve this, the operator maintains its own private copy of the information about each topic.
When a change happens either in the Kafka cluster, or in OpenShift or Kubernetes, it looks at both the state of the other system and at its private copy in order to determine what needs to change to keep everything in sync.
The same thing happens whenever the operator starts, and periodically while it is running.</p>
</div>
<div class="paragraph">
<p>For example, suppose the Topic Operator is not running, and a <code>KafkaTopic</code> <code>my-topic</code> gets created.
When the operator starts it will lack a private copy of "my-topic", so it can infer that the <code>KafkaTopic</code> has been created since it was last running.
The operator will create the topic corresponding to "my-topic" and also store a private copy of the metadata for "my-topic".</p>
</div>
<div class="paragraph">
<p>The private copy allows the operator to cope with scenarios where the topic configuration gets changed both in Kafka and in OpenShift or Kubernetes, so long as the changes are not incompatible (for example, both changing the same topic config key, but to different values).
In the case of incompatible changes, the Kafka configuration wins, and the <code>KafkaTopic</code> will be updated to reflect that.</p>
</div>
<div class="paragraph">
<p>The private copy is held in the same ZooKeeper ensemble used by Kafka itself.
This mitigates availability concerns, because if ZooKeeper is not running then Kafka itself cannot run, so the operator will be no less available than it would even if it was stateless.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Topic Operator can be included in the Entity Operator.
Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator</code> object that configures the Entity Operator.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource specifying in the <code>Kafka.spec.entityOperator.topicOperator.resources</code> property the resource requests and limits you want the Topic Operator to have.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  # kafka and zookeeper sections...
  topicOperator:
    resources:
      request:
        cpu: "1"
        memory: 500Mi
      limit:
        cpu: "1"
        memory: 500Mi</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the <code>Kafka</code> resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema of the resources object, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</h4>
<div class="paragraph">
<p>Deploying the Topic Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance is can operate <em>with</em> any Kafka cluster, not necessarily one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the Topic Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>examples/install/topic-operator/05-Deployment-strimzi-topic-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of bootstrap brokers in your Kafka cluster, given as a comma-separated list of <code><em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em></code> pairs.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaTopic</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/topic-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the Topic Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Topic Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the environment variables used to configure the Topic Operator, see <a href="#topic-operator-environment-deploying">Topic Operator environment</a>.</p>
</li>
<li>
<p>For more information about getting the Cluster Operator to deploy the Topic Operator for you, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="topic-operator-environment-deploying">4.2.6. Topic Operator environment</h4>
<div class="paragraph">
<p>When deployed standalone the Topic Operator can be configured using environment variables.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The Topic Operator should be configured using the <code>Kafka.spec.entityOperator.topicOperator</code> property when deployed by the Cluster Operator.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_RESOURCE_LABELS</code></dt>
<dd>
<p>The label selector used to identify <code>KafkaTopics</code> to be managed by the operator.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_SESSION_TIMEOUT_MS</code></dt>
<dd>
<p>The Zookeeper session timeout, in milliseconds.
For example, <code>10000</code>.
Default: <code>20000</code> (20 seconds).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code></dt>
<dd>
<p>The list of Kafka bootstrap servers.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_CONNECT</code></dt>
<dd>
<p>The Zookeeper connection information.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TOPIC_METADATA_MAX_ATTEMPTS</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its larger size (that is, many partitions/replicas).
Default <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>The level for printing logging messages.
The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.
Default <code>INFO</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TLS_ENABLED</code></dt>
<dd>
<p>For enabling the TLS support so encrypting the communication with Kafka brokers.
Default <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_LOCATION</code></dt>
<dd>
<p>The path to the truststore containing certificates for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the truststore defined by <code>STRIMZI_TRUSTSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_LOCATION</code></dt>
<dd>
<p>The path to the keystore containing private keys for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the keystore defined by <code>STRIMZI_KEYSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-user-operator-str">4.3. User Operator</h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</h4>
<div class="paragraph">
<p>Deploying the User Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance it can operate <em>with</em> any Kafka cluster, not only the one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the User Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>examples/install/user-operator/05-Deployment-strimzi-user-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_CA_NAME</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to point to an OpenShift or Kubernetes <code>Secret</code> which should contain the Certificate Authority for signing new user certificates for TLS Client Authentication.
The <code>Secret</code> should contain the public key of the Certificate Authority under the key <code>clients-ca.crt</code> and the private key under <code>clients-ca.key</code>.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaUser</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/install/user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/install/user-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the User Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The User Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about getting the Cluster Operator to deploy the User Operator for you, see <a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">Deploying the User Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-the-topic-operator-str">5. Using the Topic Operator</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</h3>
<div class="ulist">
<ul>
<li>
<p>Be consistent and always operate on <code>KafkaTopic</code> resources or always operate on topics directly. Avoid routinely using both methods for a given topic.</p>
</li>
<li>
<p>When creating a <code>KafkaTopic</code> resource:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>Choose a name for the <code>KafkaTopic</code> resource that reflects the name of the topic it describes.</p>
</li>
<li>
<p>Ideally the <code>KafkaTopic.metadata.name</code> should be the same as its <code>spec.topicName</code>. To do this, the topic name will have to be a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>When creating a topic:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>It is best to use a name that is a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>, otherwise the operator will have to modify the name when creating the corresponding <code>KafkaTopic</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="creating-a-topic-str">5.2. Creating a topic</h3>
<div class="paragraph">
<p>This procedure describes how to create a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the <code>KafkaTopic</code> to be created</p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 10
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
It is recommended to use a topic name that is a valid OpenShift or Kubernetes resource name. Doing this means that it is not necessary to set the <code>KafkaTopic.spec.topicName</code> property. In any case the <code>KafkaTopic.spec.topicName</code> cannot be changed after creation.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The <code>KafkaTopic.spec.partitions</code> cannot be decreased.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Create the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the standalone Topic Operator, see <a href="#deploying-the-topic-operator-standalone-deploying">Deploying the standalone Topic Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="changing-a-topic-str">5.3. Changing a topic</h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka topic by using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be changed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the desired <code>KafkaTopic</code></p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 16
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
You can get the current version of the resource using <code>oc get kafkatopic orders -o yaml</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Changing topic names using the <code>KafkaTopic.spec.topicName</code> variable and decreasing partition size using the <code>KafkaTopic.spec.partitions</code> variable is not supported by Kafka.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
Increasing <code>spec.partitions</code> for topics with keys will change how records are partitioned, which can be particularly problematic when the topic uses <em>semantic partitioning</em>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Update the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-a-topic-str">5.4. Deleting a topic</h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkatopic <em>&lt;your-topic-name&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkatopic <em>&lt;your-topic-name&gt;</em></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Whether the topic can actually be deleted depends on the value of the <code>delete.topic.enable</code> Kafka broker configuration, specified in the <code>Kafka.spec.kafka.config</code> property.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-using-the-user-operator-str">6. Using the User Operator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect2">
<h3 id="con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</h3>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect2">
<h3 id="con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</h3>
<div class="sect3">
<h4 id="mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</h4>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</h4>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using TLS authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using TLS see <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">Kafka broker listeners</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</h3>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRMA-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</h4>
<div class="paragraph">
<p>Strimzi supports SCRMA-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</h4>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using SCRAM SHA authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using SCRAM SHA see <a href="assembly-configuring-kafka-broker-listeners&.html#8212;&#8203;deployment-configuration-kafka">assembly-configuring-kafka-broker-listeners&.html</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka user by using a <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be changed</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the desired <code>KafkaUser</code>.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Update the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the updated credentials from the <code>my-user</code> secret in your application.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka user created with <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkauser <em>&lt;your-user-name&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkauser <em>&lt;your-user-name&gt;</em></code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="ref-kafka-user-using-uo">6.8. Kafka User resource</h3>
<div class="paragraph">
<p>The <code>KafkaUser</code> resource is used to declare a user with its authentication mechanism, authorization mechanism, and access rights.</p>
</div>
<div class="sect3">
<h4 id="authentication">6.8.1. Authentication</h4>
<div class="paragraph">
<p>Authentication is configured using the <code>authentication</code> property in <code>KafkaUser.spec</code>.
The authentication mechanism enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authentication mechanism is the TLS Client Authentication mechanism.</p>
</div>
<div class="paragraph">
<p>When no authentication mechanism is specified, User Operator will not create the user or its credentials.</p>
</div>
<div class="sect4">
<h5 id="tls_client_authentication_4">TLS Client Authentication</h5>
<div class="paragraph">
<p>To use TLS client authentication, set the <code>type</code> field to <code>tls</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>KafkaUser</code> with enabled TLS Client Authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the user is created by the User Operator, it will create a new secret with the same name as the <code>KafkaUser</code> resource.
The secret will contain a public and private key which should be used for the TLS Client Authentication.
Bundled with them will be the public key of the client certification authority which was used to sign the user certificate.
All keys will be in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example of the <code>Secret</code> with user credentials</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: my-user
  labels:
    strimzi.io/kind: KafkaUser
    strimzi.io/cluster: my-cluster
type: Opaque
data:
  ca.crt: # Public key of the Clients CA
  user.crt: # Public key of the user
  user.key: # Private key of the user</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="authorization">6.8.2. Authorization</h4>
<div class="paragraph">
<p>Authorization is configured using the <code>authorization</code> property in <code>KafkaUser.spec</code>.
The authorization type enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authorization type is the Simple authorization.</p>
</div>
<div class="paragraph">
<p>When no authorization is specified, the User Operator will not provision any access rights for the user.</p>
</div>
<div class="sect4">
<h5 id="simple_authorization_2">Simple Authorization</h5>
<div class="paragraph">
<p>To use Simple Authorization, set the <code>type</code> property to <code>simple</code>.
Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
Simple Authorization allows you to specify list of ACL rules in the <code>acls</code> property.</p>
</div>
<div class="paragraph">
<p>The <code>acls</code> property should contain a list of <code>AclRule</code> objects.
<code>AclRule</code> specifies the access rights whcih will be granted to the user.
The <code>AclRule</code> object contains following properties:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>type</code></dt>
<dd>
<p>Specifies the type of the ACL rule.
The type can be either <code>allow</code> or <code>deny</code>.
The <code>type</code> field is optional and when not specified, the ACL rule will be treated as <code>allow</code> rule.</p>
</dd>
<dt class="hdlist1"><code>operation</code></dt>
<dd>
<p>Specifies the operation which will be allowed or denied.
Following operations are supported:</p>
<div class="ulist">
<ul>
<li>
<p>Read</p>
</li>
<li>
<p>Write</p>
</li>
<li>
<p>Delete</p>
</li>
<li>
<p>Alter</p>
</li>
<li>
<p>Describe</p>
</li>
<li>
<p>All</p>
</li>
<li>
<p>IdempotentWrite</p>
</li>
<li>
<p>ClusterAction</p>
</li>
<li>
<p>Create</p>
</li>
<li>
<p>AlterConfigs</p>
</li>
<li>
<p>DescribeConfigs</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Not every operation can be combined with every resource.
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><code>host</code></dt>
<dd>
<p>Specifies a remote host from which is the rule allowed or denied.
Use <code>*</code> to allow or deny the operation from all hosts.
The <code>host</code> field is optional and when not specified, the value <code>*</code> will be used as default.</p>
</dd>
<dt class="hdlist1"><code>resource</code></dt>
<dd>
<p>Specifies the resource for which does the rule apply.
Simple Authorization supports 3 different resource types:</p>
<div class="ulist">
<ul>
<li>
<p>Topics</p>
</li>
<li>
<p>Consumer Groups</p>
</li>
<li>
<p>Clusters</p>
<div class="paragraph">
<p>The resource type can be specified in the <code>type</code> property.
Use <code>topic</code> for Topics, <code>group</code> for Consumer Groups and <code>cluster</code> for clusters.</p>
</div>
<div class="paragraph">
<p>Topic and Group resources additionally allow to specify the name of the resource for which the rule applies.
The name can be specified in the <code>name</code> property.
The name can be either specified as literal or as a prefix.
To specify the name as literal, set the <code>patternType</code> property to the value <code>literal</code>.
Literal names will be taken exactly as they are specified in the <code>name</code> field.
To specify the name as a prefix, set the <code>patternType</code> property to the value <code>prefix</code>.
Prefix type names will use the value from the <code>name</code> only a prefix and will apply the rule to all resources with names starting with the value.
The cluster type resources have no name.</p>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>For more details about <code>SimpleAclAuthorizer</code>, its ACL rules and the allowed combinations of resources and operations, see <a href="http://kafka.apache.org/documentation/#security_authz" target="_blank" rel="noopener">Authorization and ACLs</a>.</p>
</div>
<div class="paragraph">
<p>For more information about the <code>AclRule</code> object, see <a href="#type-AclRule-reference"><code>AclRule</code> schema reference</a>.</p>
</div>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  # ...
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: prefix
        operation: Read</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="additional_resources_4">6.8.3. Additional resources</h4>
<div class="ulist">
<ul>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="security">7. Security</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Strimzi project supports data encryption of communication between the different Kafka and Strimzi components by means of the SSL/TLS protocol.
This makes it possible to encrypt data transferred between Kafka brokers (interbroker communication), between Zookeeper nodes (internodal communication), and between clients and Kafka brokers.
For the Kafka and Strimzi components, TLS certificates are also used for authentication.</p>
</div>
<div class="paragraph">
<p>The Cluster Operator sets up the SSL/TLS certificates to provide this encryption and authentication.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/secure_communication.png" alt="Secure Communication">
</div>
<div class="title">Figure 3. Example Architecture diagram of the communication secured by TLS.</div>
</div>
<div class="sect2">
<h3 id="certificates">7.1. Certificates</h3>
<div class="paragraph">
<p>Each component needs its own private and public keys in order to support encryption.
The public key has to be signed by a certificate authority (CA) in order to have a related X.509 certificate for providing server authentication and encrypting the communication channel with the client (which could be another broker as well).
All component certificates are signed by a Certification Authority (CA) called <em>cluster CA</em>.
Another CA is used for authentication of Kafka clients connecting to Kafka brokers.
This CA is called <em>clients CA</em>.
The CAs themselves use self-signed certificates.</p>
</div>
<div class="paragraph">
<p>All of the generated certificates are saved as Secrets in the OpenShift or Kubernetes cluster, named as follows:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-cluster-ca</code></dt>
<dd>
<p>Contains the private and public keys of the cluster CA which is used for signing server certificates for the Kafka and Strimzi components (Kafka brokers, Zookeeper nodes, and so on).</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-cluster-ca-cert</code></dt>
<dd>
<p>Contains only the public key of the cluster CA.
The public key used by Kafka clients to verify the identity of the Kafka brokers they are connecting to (TLS server authentication).</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-clients-ca</code></dt>
<dd>
<p>Contains the private and public keys of the clients CA.
The clients CA is used for TLS client authentication of Kafka clients when connecting to Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-clients-ca-cert</code></dt>
<dd>
<p>Contains only the public key of the client CA.
The public key is used by the Kafka brokers to verify the identity of Kafka clients when TLS client authentication is used.</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-kafka-brokers</code></dt>
<dd>
<p>Contains all the Kafka broker private and public keys (certificates signed with the cluster CA).</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-zookeeper-nodes</code></dt>
<dd>
<p>Contains all the Zookeeper node private and public keys (certificates signed with the cluster CA).</p>
</dd>
<dt class="hdlist1"><code>&lt;cluster-name&gt;-topic-operator-certs</code></dt>
<dd>
<p>Contains the private and public keys (certificates signed with the cluster CA) used for encrypting communication between the Topic Operator and Kafka or Zookeeper.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>All the keys are 2048 bits in size and are valid for 365 days from initial generation.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
"certificates rotation" for generating new ones on their expiration will be supported in future releases.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="interbroker_kafka_communication">7.2. Interbroker Kafka Communication</h3>
<div class="paragraph">
<p>Communication between brokers is done through the <code>REPLICATION</code> listener on port 9091, which is encrypted by default.</p>
</div>
</div>
<div class="sect2">
<h3 id="zookeeper_communication">7.3. Zookeeper Communication</h3>
<div class="paragraph">
<p>By deploying an <code>stunnel</code> sidecar within every Zookeeper pod, the Cluster Operator is able to provide data encryption and authentication between Zookeeper nodes in a cluster.
The <code>stunnel</code> sidecar proxies all Zookeeper traffic, TLS decrypting data upon entry into a Zookeeper pod and TLS encrypting data upon departure from a Zookeeper pod.
This TLS encrypting <code>stunnel</code> proxy is instantiated from the <code>spec.zookeeper.stunnelImage</code> specified in the Kafka resource.</p>
</div>
</div>
<div class="sect2">
<h3 id="kafka_client_connections_via_tls">7.4. Kafka Client connections via TLS</h3>
<div class="paragraph">
<p>Encrypted communication between Kafka brokers and clients is provided through the <code>CLIENTTLS</code> listener on port 9093.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
You can use the <code>CLIENT</code> listener on port 9092 for unencrypted communication with brokers.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If a Kafka client wants to connect to the encrypted listener (<code>CLIENTTLS</code>) on port 9093, it needs to trust the cluster CA certificate in order to verify the broker certificate received during the SSL/TLS handshake.
The cluster CA certificate can be extracted from the generated <code>&lt;cluster-name&gt;-cluster-ca-cert</code> <code>Secret</code>.</p>
</div>
<div class="paragraph">
<p>On Kubernetes, the certificate can be extracted with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret &lt;cluster-name&gt;-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, the certificate can be extracted with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get secret &lt;cluster-name&gt;-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Kafka client has to be configured to trust certificates signed by this CA.
For the Java-based Kafka Producer, Consumer and Streams APIs, you can do this by importing the CA certificate into the JVM&#8217;s truststore using the following keytool command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">keytool -keystore client.truststore.jks -alias CARoot -import -file ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, in order to configure the Kafka client, following properties should be specified:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>security.protocol</code>: SSL is the value for using encryption.</p>
</li>
<li>
<p><code>ssl.truststore.location</code>: the truststore location where the certificates were imported.</p>
</li>
<li>
<p><code>ssl.truststore.password</code>: password for accessing the truststore. This property can be omitted if it is not needed by the truststore.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The current implementation does not support Subject Alternative Names (SAN) so the hostname verification should be disabled on the client side.
For doing so the <code>ssl.endpoint.identification.algorithm</code> property needs to be set as empty.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="frequently_asked_questions">Appendix A: Frequently Asked Questions</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="cluster_operator">A.1. Cluster Operator</h3>
<div class="sect3">
<h4 id="log_contains_warnings_about_failing_to_acquire_lock">A.1.1. Log contains warnings about failing to acquire lock</h4>
<div class="paragraph">
<p>For each cluster, the Cluster Operator always executes only one operation at a time. The Cluster Operator uses locks
to make sure that there are never two parallel operations running for the same cluster. In case an operation requires
more time to complete, other operations will wait until it is completed and the lock is released.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">INFO</dt>
<dd>
<p>Examples of cluster operations are <em>cluster creation</em>, <em>rolling update</em>, <em>scale down</em> or <em>scale up</em> and so on.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>If the wait for the lock takes too long, the operation times out and the following warning message will be printed to
the log:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">2018-03-04 17:09:24 WARNING AbstractClusterOperations:290 - Failed to acquire lock for kafka cluster lock::kafka::myproject::my-cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p>Depending on the exact configuration of <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code> and <code>STRIMZI_OPERATION_TIMEOUT_MS</code>, this
warning message may appear regularly without indicating any problems. The operations which time out will be picked up by
the next periodic reconciliation. It will try to acquire the lock again and execute.</p>
</div>
<div class="paragraph">
<p>Should this message appear periodically even in situations when there should be no other operations running for a given
cluster, it might indicate that due to some error the lock was not properly released. In such cases it is recommended to
restart the cluster operator.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The easiest way to get started with OpenShift or Kubernetes is using the <code>Minikube</code>, <code>Minishift</code> or <code>oc cluster up</code>
utilities. This section provides basic guidance on how to use them. More details are provided on the websites of
the tools themselves.</p>
</div>
<div class="sect2">
<h3 id="kubernetes">B.1. Kubernetes</h3>
<div class="paragraph">
<p>In order to interact with a Kubernetes cluster the <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"><code>kubectl</code></a>
utility needs to be installed.</p>
</div>
<div class="paragraph">
<p>The easiest way to get a running Kubernetes cluster is using <code>Minikube</code>. <code>Minikube</code> can be downloaded and installed
from the <a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Kubernetes website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minikube</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, it can be started using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minikube start --memory 4096</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="openshift">B.2. OpenShift</h3>
<div class="paragraph">
<p>In order to interact with an OpenShift cluster, the <a href="https://github.com/openshift/origin/releases"><code>oc</code></a> utility is needed.</p>
</div>
<div class="paragraph">
<p>An OpenShift cluster can be started in two different ways. The <code>oc</code> utility can start a cluster locally using the
command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc cluster up</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command requires Docker to be installed. More information about this way can be found
<a href="https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md">here</a>.</p>
</div>
<div class="paragraph">
<p>Another option is to use <code>Minishift</code>. <code>Minishift</code> is an OpenShift installation within a VM. It can be downloaded and
installed from the <a href="https://docs.openshift.org/latest/minishift/index.html">Minishift website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minishift</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, <code>Minishift</code> can be started using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minishift start --memory 4GB</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="api_reference-str">Appendix C: Custom Resource API Reference</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="type-Kafka-reference">C.1. <code>Kafka</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka and Zookeeper clusters, and Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaSpec-reference">C.2. <code>KafkaSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-Kafka-reference"><code>Kafka</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kafka</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Zookeeper cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">entityOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Entity Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaClusterSpec-reference">C.3. <code>KafkaClusterSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">listeners</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures listeners of Kafka brokers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization configuration for Kafka brokers. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaAuthorizationSimple-reference"><code>KafkaAuthorizationSimple</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The kafka broker config. Properties with the following prefixes cannot be set: listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer., super.user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rack</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the <code>broker.rack</code> broker config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Rack-reference"><code>Rack</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokerRackInitImage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image of the init container used for initializing the <code>broker.rack</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Sidecar-reference"><code>Sidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EphemeralStorage-reference">C.4. <code>EphemeralStorage</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>EphemeralStorage</code> from <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a>.
It must have the value <code>ephemeral</code> for the type <code>EphemeralStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>ephemeral</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PersistentClaimStorage-reference">C.5. <code>PersistentClaimStorage</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>PersistentClaimStorage</code> from <a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>.
It must have the value <code>persistent-claim</code> for the type <code>PersistentClaimStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">class</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The storage class to use for dynamic volume allocation.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteClaim</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">selector</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies a specific persistent volume to use. It contains a matchLabels field which defines an inner JSON object with key:value representing labels for selecting such a volume.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>persistent-claim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListeners-reference">C.6. <code>KafkaListeners</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">plain</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures plain listener on port 9092.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures TLS listener on port 9093.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">external</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures external listener on port 9094. The type depends on the value of the <code>external.type</code> property within the given object, which must be one of [route, loadbalancer, nodeport].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerPlain-reference">C.7. <code>KafkaListenerPlain</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with <code>type: tls</code>. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationTls-reference">C.8. <code>KafkaListenerAuthenticationTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationTls</code> from <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaListenerAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationScramSha512-reference">C.9. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationScramSha512</code> from <a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaListenerAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerTls-reference">C.10. <code>KafkaListenerTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalRoute-reference">C.11. <code>KafkaListenerExternalRoute</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalRoute</code> from <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>route</code> for the type <code>KafkaListenerExternalRoute</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>route</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalLoadBalancer-reference">C.12. <code>KafkaListenerExternalLoadBalancer</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalLoadBalancer</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>loadbalancer</code> for the type <code>KafkaListenerExternalLoadBalancer</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>loadbalancer</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalNodePort-reference">C.13. <code>KafkaListenerExternalNodePort</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalNodePort</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>.
It must have the value <code>nodeport</code> for the type <code>KafkaListenerExternalNodePort</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>nodeport</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaAuthorizationSimple-reference">C.14. <code>KafkaAuthorizationSimple</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">superUsers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of super users. Should contain list of user principals which should get unlimited access rights.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Rack-reference">C.15. <code>Rack</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topologyKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A key that matches labels assigned to the OpenShift or Kubernetes cluster nodes. The value of the label is used to set the broker&#8217;s <code>broker.rack</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Probe-reference">C.16. <code>Probe</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">initialDelaySeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The initial delay before first the health is first checked.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">timeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The timeout for each attempted health check.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-JvmOptions-reference">C.17. <code>JvmOptions</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-XX</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A map of -XX options to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xms</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xms option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xmx</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xmx option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Resources-reference">C.18. <code>Resources</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-Sidecar-reference"><code>Sidecar</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">limits</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource limits applied at runtime.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">requests</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource requests applied during pod scheduling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CpuMemory-reference">C.19. <code>CpuMemory</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-Resources-reference"><code>Resources</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">cpu</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">CPU.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">memory</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Memory.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-InlineLogging-reference">C.20. <code>InlineLogging</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>InlineLogging</code> from <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a>.
It must have the value <code>inline</code> for the type <code>InlineLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">loggers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A Map from logger name to logger level.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>inline</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalLogging-reference">C.21. <code>ExternalLogging</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>ExternalLogging</code> from <a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>.
It must have the value <code>external</code> for the type <code>ExternalLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the <code>ConfigMap</code> from which to get the logging configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>external</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Sidecar-reference">C.22. <code>Sidecar</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the container.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ZookeeperClusterSpec-reference">C.23. <code>ZookeeperClusterSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The zookeeper broker config. Properties with the following prefixes cannot be set: server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Zookeeper. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Sidecar-reference"><code>Sidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-TopicOperatorSpec-reference">C.24. <code>TopicOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Sidecar-reference"><code>Sidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityOperatorSpec-reference">C.25. <code>EntityOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">userOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Sidecar-reference"><code>Sidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityTopicOperatorSpec-reference">C.26. <code>EntityTopicOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityUserOperatorSpec-reference">C.27. <code>EntityUserOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the User Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnect-reference">C.28. <code>KafkaConnect</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectSpec-reference">C.29. <code>KafkaConnectSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationTls-reference">C.30. <code>KafkaConnectAuthenticationTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationTls</code> from <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaConnectAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateAndKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Certificate and private key pair for TLS authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertAndKeySecretSource-reference"><code>CertAndKeySecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertAndKeySecretSource-reference">C.31. <code>CertAndKeySecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">key</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the private key in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationScramSha512-reference">C.32. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationScramSha512</code> from <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaConnectAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">passwordSecret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Password used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PasswordSecretSource-reference"><code>PasswordSecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">username</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Username used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PasswordSecretSource-reference">C.33. <code>PasswordSecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">password</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the key in the Secret under which the password is stored.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the password.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectTls-reference">C.34. <code>KafkaConnectTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">trustedCertificates</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Trusted certificates for TLS connection.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertSecretSource-reference"><code>CertSecretSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertSecretSource-reference">C.35. <code>CertSecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2I-reference">C.36. <code>KafkaConnectS2I</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2ISpec-reference">C.37. <code>KafkaConnectS2ISpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">insecureSourceRepository</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When true this configures the source repository with the 'Local' reference policy and an import policy that accepts insecure source tags.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopic-reference">C.38. <code>KafkaTopic</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the topic.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaTopicSpec-reference"><code>KafkaTopicSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopicSpec-reference">C.39. <code>KafkaTopicSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">partitions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of partitions the topic should have. This cannot be decreased after topic creation. It can be increased after topic creation, but it is important to understand the consequences that has, especially for topics with semantic partitioning. If unspecified this will default to the broker&#8217;s <code>num.partitions</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of replicas the topic should have. If unspecified this will default to the broker&#8217;s <code>default.replication.factor</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The topic configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the topic. When absent this will default to the metadata.name of the topic. It is recommended to not set this unless the topic name is not a valid Kubernetes resource name.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUser-reference">C.40. <code>KafkaUser</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserSpec-reference">C.41. <code>KafkaUserSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUser-reference"><code>KafkaUser</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication mechanism enabled for this Kafka user. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>, <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization rules for this Kafka user. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserTlsClientAuthentication-reference">C.42. <code>KafkaUserTlsClientAuthentication</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserTlsClientAuthentication</code> from <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaUserTlsClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserScramSha512ClientAuthentication-reference">C.43. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserScramSha512ClientAuthentication</code> from <a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaUserScramSha512ClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserAuthorizationSimple-reference">C.44. <code>KafkaUserAuthorizationSimple</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaUserAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">acls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of ACL rules which should be applied to this user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRule-reference"><code>AclRule</code></a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRule-reference">C.45. <code>AclRule</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">host</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host from which the action described in the ACL rule is allowed or denied.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">operation</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Operation which will be allowed or denied. Supported operations are: Read, Write, Create, Delete, Alter, Describe, ClusterAction, AlterConfigs, DescribeConfigs, IdempotentWrite and All.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [Read, Write, Delete, Alter, Describe, All, IdempotentWrite, ClusterAction, Create, AlterConfigs, DescribeConfigs])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resource</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Indicates the resource for which given ACL rule applies. The type depends on the value of the <code>resource.type</code> property within the given object, which must be one of [topic, group, cluster].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The type of the rule.Currently the only supported type is <code>allow</code>.ACL rules with type <code>allow</code> are used to allow user to execute the specified operations. Default value is <code>allow</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [allow, deny])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleTopicResource-reference">C.46. <code>AclRuleTopicResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleTopicResource</code> from <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>.
It must have the value <code>topic</code> for the type <code>AclRuleTopicResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>topic</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleGroupResource-reference">C.47. <code>AclRuleGroupResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleGroupResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>.
It must have the value <code>group</code> for the type <code>AclRuleGroupResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>group</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleClusterResource-reference">C.48. <code>AclRuleClusterResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleClusterResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>.
It must have the value <code>cluster</code> for the type <code>AclRuleClusterResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>cluster</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="metrics-str">Appendix D: Metrics</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section describes how to deploy a Prometheus server for scraping metrics from the Kafka cluster and showing them using a Grafana dashboard. The resources provided are examples to show how Kafka metrics can be stored in Prometheus: They are not a recommended configuration, and further support should be available from the Prometheus and Grafana communities.</p>
</div>
<div class="paragraph">
<p>When adding Prometheus and Grafana servers to an Apache Kafka deployment using <code>minikube</code> or <code>minishift</code>, the memory available to the virtual machine should be increased (to 4 GB of RAM, for example, instead of the default 2 GB). Information on how to increase the default amount of memory can be found in the following section <a href="#installing_kubernetes_and_openshift_cluster">Installing OpenShift or Kubernetes cluster</a>.</p>
</div>
<div class="sect2">
<h3 id="deploying_on_openshift">D.1. Deploying on OpenShift</h3>
<div class="sect3">
<h4 id="prometheus">D.1.1. Prometheus</h4>
<div class="paragraph">
<p>The Prometheus server configuration uses a service discovery feature in order to discover the pods in the cluster from which it gets metrics.
In order to have this feature working, it is necessary for the service account used for running the Prometheus service pod to have access to the API server to get the pod list. By default the service account <code>prometheus-server</code> is used.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export NAMESPACE=[namespace]
oc login -u system:admin
oc create sa prometheus-server
oc adm policy add-cluster-role-to-user cluster-reader system:serviceaccount:${NAMESPACE}:prometheus-server
oc login -u developer</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>[namespace]</code> is the namespace/project where the Apache Kafka cluster was deployed.</p>
</div>
<div class="paragraph">
<p>Finally, create the Prometheus service by running</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/prometheus/kubernetes.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="grafana">D.1.2. Grafana</h4>
<div class="paragraph">
<p>A Grafana server is necessary only to get a visualisation of the Prometheus metrics.</p>
</div>
<div class="paragraph">
<p>To deploy Grafana on OpenShift, the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/grafana/kubernetes.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying_on_kubernetes">D.2. Deploying on Kubernetes</h3>
<div class="sect3">
<h4 id="prometheus_2">D.2.1. Prometheus</h4>
<div class="paragraph">
<p>The Prometheus server configuration uses a service discovery feature in order to discover the pods in the cluster from which it gets metrics.
If the RBAC is enabled in your Kubernetes deployment then in order to have this feature working, it is necessary for the service account used for running the Prometheus service pod to have access to the API server to get the pod list. By default the service account <code>prometheus-server</code> is used.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export NAMESPACE=[namespace]
kubectl create sa prometheus-server
kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/prometheus/cluster-reader.yaml
kubectl create clusterrolebinding read-pods-binding --clusterrole=cluster-reader --serviceaccount=${NAMESPACE}:prometheus-server</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>[namespace]</code> is the namespace/project where the Apache Kafka cluster was deployed.</p>
</div>
<div class="paragraph">
<p>Finally, create the Prometheus service by running</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/prometheus/kubernetes.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="grafana_2">D.2.2. Grafana</h4>
<div class="paragraph">
<p>A Grafana server is necessary only to get a visualisation of Prometheus metrics.</p>
</div>
<div class="paragraph">
<p>To deploy Grafana on Kubernetes, the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/grafana/kubernetes.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="grafana_dashboard">D.3. Grafana dashboard</h3>
<div class="paragraph">
<p>As an example, and in order to visualize the exported metrics in Grafana, the simple dashboard <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/master/metrics/examples/grafana/kafka-dashboard.json"><code>kafka-dashboard.json</code></a> file is provided.
The Prometheus data source, and the above dashboard, can be set up in Grafana by following these steps.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For accessing the dashboard, you can use the <code>port-forward</code> command for forwarding traffic from the Grafana pod to the host. For example, you can access the Grafana UI by running <code>oc port-forward grafana-1-fbl7s 3000:3000</code> (or using <code>kubectl</code> instead of <code>oc</code>) and then pointing a browser to <code><a href="http://localhost:3000" class="bare">http://localhost:3000</a></code>.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Access to the Grafana UI using <code>admin/admin</code> credentials.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_login.png" alt="Grafana login">
</div>
</div>
</li>
<li>
<p>Click on the "Add data source" button from the Grafana home in order to add Prometheus as data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_home.png" alt="Grafana home">
</div>
</div>
</li>
<li>
<p>Fill in the information about the Prometheus data source, specifying a name and "Prometheus" as type. In the URL field, the connection string to the Prometheus server (that is, <code><a href="http://prometheus:9090" class="bare">http://prometheus:9090</a></code>) should be specified. After "Add" is clicked, Grafana will test the connection to the data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_prometheus_data_source.png" alt="Add Prometheus data source">
</div>
</div>
</li>
<li>
<p>From the top left menu, click on "Dashboards" and then "Import" to open the "Import Dashboard" window where the provided <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/master/metrics/examples/grafana/kafka-dashboard.json"><code>kafka-dashboard.json</code></a> file can be imported or its content pasted.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_import_dashboard.png" alt="Add Grafana dashboard">
</div>
</div>
</li>
<li>
<p>After importing the dashboard, the Grafana home should show with some initial metrics about CPU and JVM memory usage. When the Kafka cluster is used (creating topics and exchanging messages) the other metrics, like messages in and bytes in/out per topic, will be shown.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_kafka_dashboard.png" alt="Kafka dashboard">
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2018-09-03 20:37:30 CEST
</div>
</div>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlighting()</script>
</body>
</html>