<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#overview-str">1. Overview of Strimzi</a>
<ul class="sectlevel2">
<li><a href="#key-features-str">1.1. Kafka Key Features</a></li>
<li><a href="#document-conventions-str">1.2. Document Conventions</a></li>
</ul>
</li>
<li><a href="#getting-started-str">2. Getting started with Strimzi</a>
<ul class="sectlevel2">
<li><a href="#downloads-str">2.1. Strimzi downloads</a></li>
<li><a href="#cluster-operator-str">2.2. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-str">2.2.5. Deploying the Cluster Operator using Helm Chart</a></li>
</ul>
</li>
<li><a href="#kafka-cluster-str">2.3. Kafka cluster</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</a></li>
<li><a href="#deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</a></li>
</ul>
</li>
<li><a href="#kafka-connect-str">2.4. Kafka Connect</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to Kubernetes</a></li>
<li><a href="#deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to OpenShift</a></li>
<li><a href="#using-kafka-connect-with-plugins-str">2.4.3. Using Kafka Connect with plugins</a></li>
</ul>
</li>
<li><a href="#kafka-mirror-maker-str">2.5. Kafka Mirror Maker</a>
<ul class="sectlevel3">
<li><a href="#deploying-kafka-mirror-maker-kubernetes-str">2.5.1. Deploying Kafka Connect to Kubernetes</a></li>
<li><a href="#deploying-kafka-mirror-maker-openshift-str">2.5.2. Deploying Kafka Mirror Maker to OpenShift</a></li>
</ul>
</li>
<li><a href="#deploying-example-clients-str">2.6. Deploying example clients</a></li>
<li><a href="#assembly-getting-started-topic-operator-str">2.7. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-str">2.7.1. Overview of the Topic Operator component</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-str">2.7.2. Deploying the Topic Operator using the Cluster Operator</a></li>
</ul>
</li>
<li><a href="#assembly-getting-started-user-operator-str">2.8. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-str">2.8.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">2.8.2. Deploying the User Operator using the Cluster Operator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-str">3. Deployment configuration</a>
<ul class="sectlevel2">
<li><a href="#assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</a></li>
<li><a href="#assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Replicas</a></li>
<li><a href="#assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</a></li>
<li><a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</a></li>
<li><a href="#assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</a></li>
<li><a href="#assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Replicas</a></li>
<li><a href="#assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</a></li>
<li><a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka">3.1.10. Logging</a></li>
<li><a href="#assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</a></li>
<li><a href="#assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</a></li>
<li><a href="#proc-manual-rolling-update-kafka-deployment-configuration-kafka">3.1.18. Performing a rolling update of a Kafka cluster</a></li>
<li><a href="#proc-manual-rolling-update-zookeeper-deployment-configuration-kafka">3.1.19. Performing a rolling update of a Zookeeper cluster</a></li>
<li><a href="#proc-manual-delete-pod-pvc-kafka-deployment-configuration-kafka">3.1.20. Deleting Kafka nodes manually</a></li>
<li><a href="#proc-manual-delete-pod-pvc-zookeeper-deployment-configuration-kafka">3.1.21. Deleting Zookeeper nodes manually</a></li>
<li><a href="#ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.22. List of resources created as part of Kafka cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</a></li>
<li><a href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-connect-resources-deployment-configuration-kafka-connect">3.2.13. List of resources created as part of Kafka Connect cluster</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</a></li>
<li><a href="#assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</a></li>
<li><a href="#assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-connect-s2i-resources-deployment-configuration-kafka-connect-s2i">3.3.13. List of resources created as part of Kafka Connect cluster with Source2Image support</a></li>
<li><a href="#using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.14. Using OpenShift builds and S2I to create new images</a></li>
</ul>
</li>
<li><a href="#assembly-deployment-configuration-kafka-mirror-maker-str">3.4. Kafka Mirror Maker configuration</a>
<ul class="sectlevel3">
<li><a href="#assembly-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">3.4.1. Replicas</a></li>
<li><a href="#assembly-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">3.4.2. Bootstrap servers</a></li>
<li><a href="#assembly-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">3.4.3. Whitelist</a></li>
<li><a href="#assembly-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">3.4.4. Consumer group identifier</a></li>
<li><a href="#assembly-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">3.4.5. Number of consumer streams</a></li>
<li><a href="#assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">3.4.6. Connecting to Kafka brokers using TLS</a></li>
<li><a href="#assembly-kafka-mirror-maker-authentication-deployment-configuration-kafka-mirror-maker">3.4.7. Connecting to Kafka brokers with Authentication</a></li>
<li><a href="#assembly-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">3.4.8. Kafka Mirror Maker configuration</a></li>
<li><a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">3.4.9. CPU and memory resources</a></li>
<li><a href="#assembly-logging-deployment-configuration-kafka-mirror-maker">3.4.10. Logging</a></li>
<li><a href="#assembly-metrics-deployment-configuration-kafka-mirror-maker">3.4.11. Prometheus metrics</a></li>
<li><a href="#assembly-jvm-options-deployment-configuration-kafka-mirror-maker">3.4.12. JVM Options</a></li>
<li><a href="#assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker">3.4.13. Container images</a></li>
<li><a href="#assembly-scheduling-deployment-configuration-kafka-mirror-maker">3.4.14. Configuring pod scheduling</a></li>
<li><a href="#ref-list-of-kafka-mirror-maker-resources-deployment-configuration-kafka-mirror-maker">3.4.15. List of resources created as part of Kafka Mirror Maker</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#assembly-operators-str">4. Operators</a>
<ul class="sectlevel2">
<li><a href="#assembly-operators-cluster-operator-str">4.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</a></li>
<li><a href="#deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</a></li>
<li><a href="#deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</a></li>
<li><a href="#deploying-cluster-operator-helm-chart-deploying-co">4.1.5. Deploying the Cluster Operator using Helm Chart</a></li>
<li><a href="#con-cluster-operator-reconciliation-deploying-co">4.1.6. Reconciliation</a></li>
<li><a href="#ref-operators-cluster-operator-configuration-deploying-co">4.1.7. Cluster Operator Configuration</a></li>
<li><a href="#con-cluster-operator-rbac-deploying-co">4.1.8. Role-Based Access Control (RBAC)</a></li>
</ul>
</li>
<li><a href="#deploying-the-topic-operator-str">4.2. Topic Operator</a>
<ul class="sectlevel3">
<li><a href="#what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</a></li>
<li><a href="#how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</a></li>
<li><a href="#deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</a></li>
<li><a href="#proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</a></li>
<li><a href="#deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</a></li>
<li><a href="#topic-operator-environment-deploying">4.2.6. Topic Operator environment</a></li>
</ul>
</li>
<li><a href="#assembly-user-operator-str">4.3. User Operator</a>
<ul class="sectlevel3">
<li><a href="#con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</a></li>
<li><a href="#proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</a></li>
<li><a href="#proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#using-the-topic-operator-str">5. Using the Topic Operator</a>
<ul class="sectlevel2">
<li><a href="#topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</a></li>
<li><a href="#creating-a-topic-str">5.2. Creating a topic</a></li>
<li><a href="#changing-a-topic-str">5.3. Changing a topic</a></li>
<li><a href="#deleting-a-topic-str">5.4. Deleting a topic</a></li>
</ul>
</li>
<li><a href="#assembly-using-the-user-operator-str">6. Using the User Operator</a>
<ul class="sectlevel2">
<li><a href="#con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</a></li>
<li><a href="#con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</a>
<ul class="sectlevel3">
<li><a href="#mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</a></li>
<li><a href="#when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</a></li>
<li><a href="#con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</a>
<ul class="sectlevel3">
<li><a href="#supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</a></li>
<li><a href="#when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</a></li>
</ul>
</li>
<li><a href="#proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</a></li>
<li><a href="#proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</a></li>
<li><a href="#deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</a></li>
<li><a href="#ref-kafka-user-using-uo">6.8. Kafka User resource</a>
<ul class="sectlevel3">
<li><a href="#authentication">6.8.1. Authentication</a></li>
<li><a href="#authorization">6.8.2. Authorization</a></li>
<li><a href="#additional_resources_5">6.8.3. Additional resources</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#security-str">7. Security</a>
<ul class="sectlevel2">
<li><a href="#certificate-authorities-str">7.1. Certificate Authorities</a>
<ul class="sectlevel3">
<li><a href="#ca_certificates">7.1.1. CA certificates</a></li>
</ul>
</li>
<li><a href="#certificates-and-secrets-str">7.2. Certificates and <code>Secrets</code></a>
<ul class="sectlevel3">
<li><a href="#cluster_ca_secrets">7.2.1. Cluster CA <code>Secrets</code></a></li>
<li><a href="#client_ca_secrets">7.2.2. Client CA <code>Secrets</code></a></li>
<li><a href="#user_secrets">7.2.3. User <code>Secrets</code></a></li>
</ul>
</li>
<li><a href="#installing-your-own-ca-certificates-str">7.3. Installing your own CA certificates</a></li>
<li><a href="#con-certificate-renewal-str">7.4. Certificate renewal</a>
<ul class="sectlevel3">
<li><a href="#renewal_process_with_generated_cas">7.4.1. Renewal process with generated CAs</a></li>
<li><a href="#renewal_process_with_your_own_ca_certificates">7.4.2. Renewal process with your own CA certificates</a></li>
<li><a href="#client_applications">7.4.3. Client applications</a></li>
</ul>
</li>
<li><a href="#renewing-your-own-ca-certificates-str">7.5. Renewing your own CA certificates</a></li>
<li><a href="#tls-connections-str">7.6. TLS connections</a>
<ul class="sectlevel3">
<li><a href="#zookeeper_communication">7.6.1. Zookeeper communication</a></li>
<li><a href="#kafka_interbroker_communication">7.6.2. Kafka interbroker communication</a></li>
<li><a href="#topic_and_user_operators">7.6.3. Topic and User Operators</a></li>
<li><a href="#kafka_client_connections">7.6.4. Kafka Client connections</a></li>
</ul>
</li>
<li><a href="#configuring-internal-clients-to-trust-cluster-ca-str">7.7. Configuring internal clients to trust the cluster CA</a></li>
<li><a href="#configuring-external-clients-to-trust-cluster-ca-str">7.8. Configuring external clients to trust the cluster CA</a></li>
</ul>
</li>
<li><a href="#frequently_asked_questions">Appendix A: Frequently Asked Questions</a>
<ul class="sectlevel2">
<li><a href="#cluster_operator">A.1. Cluster Operator</a>
<ul class="sectlevel3">
<li><a href="#log_contains_warnings_about_failing_to_acquire_lock">A.1.1. Log contains warnings about failing to acquire lock</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</a>
<ul class="sectlevel2">
<li><a href="#kubernetes">B.1. Kubernetes</a></li>
<li><a href="#openshift">B.2. OpenShift</a></li>
</ul>
</li>
<li><a href="#api_reference-str">Appendix C: Custom Resource API Reference</a>
<ul class="sectlevel2">
<li><a href="#type-Kafka-reference">C.1. <code>Kafka</code> schema reference</a></li>
<li><a href="#type-KafkaSpec-reference">C.2. <code>KafkaSpec</code> schema reference</a></li>
<li><a href="#type-KafkaClusterSpec-reference">C.3. <code>KafkaClusterSpec</code> schema reference</a></li>
<li><a href="#type-EphemeralStorage-reference">C.4. <code>EphemeralStorage</code> schema reference</a></li>
<li><a href="#type-PersistentClaimStorage-reference">C.5. <code>PersistentClaimStorage</code> schema reference</a></li>
<li><a href="#type-KafkaListeners-reference">C.6. <code>KafkaListeners</code> schema reference</a></li>
<li><a href="#type-KafkaListenerPlain-reference">C.7. <code>KafkaListenerPlain</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationTls-reference">C.8. <code>KafkaListenerAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerAuthenticationScramSha512-reference">C.9. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-KafkaListenerTls-reference">C.10. <code>KafkaListenerTls</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalRoute-reference">C.11. <code>KafkaListenerExternalRoute</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalLoadBalancer-reference">C.12. <code>KafkaListenerExternalLoadBalancer</code> schema reference</a></li>
<li><a href="#type-KafkaListenerExternalNodePort-reference">C.13. <code>KafkaListenerExternalNodePort</code> schema reference</a></li>
<li><a href="#type-KafkaAuthorizationSimple-reference">C.14. <code>KafkaAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-Rack-reference">C.15. <code>Rack</code> schema reference</a></li>
<li><a href="#type-Probe-reference">C.16. <code>Probe</code> schema reference</a></li>
<li><a href="#type-JvmOptions-reference">C.17. <code>JvmOptions</code> schema reference</a></li>
<li><a href="#type-Resources-reference">C.18. <code>Resources</code> schema reference</a></li>
<li><a href="#type-CpuMemory-reference">C.19. <code>CpuMemory</code> schema reference</a></li>
<li><a href="#type-InlineLogging-reference">C.20. <code>InlineLogging</code> schema reference</a></li>
<li><a href="#type-ExternalLogging-reference">C.21. <code>ExternalLogging</code> schema reference</a></li>
<li><a href="#type-TlsSidecar-reference">C.22. <code>TlsSidecar</code> schema reference</a></li>
<li><a href="#type-ZookeeperClusterSpec-reference">C.23. <code>ZookeeperClusterSpec</code> schema reference</a></li>
<li><a href="#type-TopicOperatorSpec-reference">C.24. <code>TopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-CertificateAuthority-reference">C.25. <code>CertificateAuthority</code> schema reference</a></li>
<li><a href="#type-EntityOperatorSpec-reference">C.26. <code>EntityOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityTopicOperatorSpec-reference">C.27. <code>EntityTopicOperatorSpec</code> schema reference</a></li>
<li><a href="#type-EntityUserOperatorSpec-reference">C.28. <code>EntityUserOperatorSpec</code> schema reference</a></li>
<li><a href="#type-KafkaConnect-reference">C.29. <code>KafkaConnect</code> schema reference</a></li>
<li><a href="#type-KafkaConnectSpec-reference">C.30. <code>KafkaConnectSpec</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationTls-reference">C.31. <code>KafkaConnectAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-CertAndKeySecretSource-reference">C.32. <code>CertAndKeySecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectAuthenticationScramSha512-reference">C.33. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-PasswordSecretSource-reference">C.34. <code>PasswordSecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectTls-reference">C.35. <code>KafkaConnectTls</code> schema reference</a></li>
<li><a href="#type-CertSecretSource-reference">C.36. <code>CertSecretSource</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2I-reference">C.37. <code>KafkaConnectS2I</code> schema reference</a></li>
<li><a href="#type-KafkaConnectS2ISpec-reference">C.38. <code>KafkaConnectS2ISpec</code> schema reference</a></li>
<li><a href="#type-KafkaTopic-reference">C.39. <code>KafkaTopic</code> schema reference</a></li>
<li><a href="#type-KafkaTopicSpec-reference">C.40. <code>KafkaTopicSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUser-reference">C.41. <code>KafkaUser</code> schema reference</a></li>
<li><a href="#type-KafkaUserSpec-reference">C.42. <code>KafkaUserSpec</code> schema reference</a></li>
<li><a href="#type-KafkaUserTlsClientAuthentication-reference">C.43. <code>KafkaUserTlsClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserScramSha512ClientAuthentication-reference">C.44. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</a></li>
<li><a href="#type-KafkaUserAuthorizationSimple-reference">C.45. <code>KafkaUserAuthorizationSimple</code> schema reference</a></li>
<li><a href="#type-AclRule-reference">C.46. <code>AclRule</code> schema reference</a></li>
<li><a href="#type-AclRuleTopicResource-reference">C.47. <code>AclRuleTopicResource</code> schema reference</a></li>
<li><a href="#type-AclRuleGroupResource-reference">C.48. <code>AclRuleGroupResource</code> schema reference</a></li>
<li><a href="#type-AclRuleClusterResource-reference">C.49. <code>AclRuleClusterResource</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMaker-reference">C.50. <code>KafkaMirrorMaker</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerSpec-reference">C.51. <code>KafkaMirrorMakerSpec</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerConsumerSpec-reference">C.52. <code>KafkaMirrorMakerConsumerSpec</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerAuthenticationTls-reference">C.53. <code>KafkaMirrorMakerAuthenticationTls</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference">C.54. <code>KafkaMirrorMakerAuthenticationScramSha512</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerTls-reference">C.55. <code>KafkaMirrorMakerTls</code> schema reference</a></li>
<li><a href="#type-KafkaMirrorMakerProducerSpec-reference">C.56. <code>KafkaMirrorMakerProducerSpec</code> schema reference</a></li>
</ul>
</li>
<li><a href="#metrics-str">Appendix D: Metrics</a>
<ul class="sectlevel2">
<li><a href="#kafka_metrics_configuration">D.1. Kafka Metrics Configuration</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift">D.1.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes">D.1.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#prometheus">D.2. Prometheus</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift_2">D.2.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes_2">D.2.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#grafana">D.3. Grafana</a>
<ul class="sectlevel3">
<li><a href="#deploying_on_openshift_3">D.3.1. Deploying on OpenShift</a></li>
<li><a href="#deploying_on_kubernetes_3">D.3.2. Deploying on Kubernetes</a></li>
</ul>
</li>
<li><a href="#grafana_dashboard">D.4. Grafana dashboard</a>
<ul class="sectlevel3">
<li><a href="#kafka_dashboard">D.4.1. Kafka Dashboard</a></li>
<li><a href="#zookeeper_dashboard">D.4.2. ZooKeeper Dashboard</a></li>
<li><a href="#metrics_references">D.4.3. Metrics References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="sect1">
<h2 id="overview-str">1. Overview of Strimzi</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi makes it easy to run Apache Kafka on OpenShift or Kubernetes. Apache Kafka is a popular platform for streaming data delivery and processing. For more information about Apache Kafka, see the <a href="http://kafka.apache.org" target="_blank" rel="noopener">Apache Kafka website</a>.</p>
</div>
<div class="paragraph">
<p>Strimzi is based on Apache Kafka 2.0.0 and consists of three main components:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Cluster Operator</dt>
<dd>
<p>Responsible for deploying and managing Apache Kafka clusters within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">Topic Operator</dt>
<dd>
<p>Responsible for managing Kafka topics within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
<dt class="hdlist1">User Operator</dt>
<dd>
<p>Responsible for managing Kafka users within a Kafka cluster running within OpenShift or Kubernetes cluster.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>This guide describes how to install and use Strimzi.</p>
</div>
<div class="sect2">
<h3 id="key-features-str">1.1. Kafka Key Features</h3>
<div class="ulist">
<ul>
<li>
<p>Scalability and performance</p>
<div class="ulist">
<ul>
<li>
<p>Designed for horizontal scalability</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message ordering guarantee</p>
<div class="ulist">
<ul>
<li>
<p>At partition level</p>
</li>
</ul>
</div>
</li>
<li>
<p>Message rewind/replay</p>
<div class="ulist">
<ul>
<li>
<p>"Long term" storage</p>
</li>
<li>
<p>Allows to reconstruct application state by replaying the messages</p>
</li>
<li>
<p>Combined with compacted topics allows to use Kafka as key-value store</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="document-conventions-str">1.2. Document Conventions</h3>
<div class="paragraph">
<div class="title">Replaceables</div>
<p>In this document, replaceable text is styled in monospace and italics.</p>
</div>
<div class="paragraph">
<p>For example, in the following code, you will want to replace <code><em>my-namespace</em></code> with the name of your namespace:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="getting-started-str">2. Getting started with Strimzi</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi works on all types of clusters, from public and private clouds on to local deployments intended for development.
This guide expects that an OpenShift or Kubernetes cluster is available and the
<code>kubectl</code> and
<code>oc</code> command-line tools are installed and configured to connect to the running cluster.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Supported Versions</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Product</th>
<th class="tableblock halign-left valign-top">Version</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.9 and later</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenShift Origin</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.9 and later</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Apache Kafka</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.0.0</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>When no existing OpenShift or Kubernetes cluster is available, <code>Minikube</code> or <code>Minishift</code> can be used to create a local
cluster. More details can be found in <a href="#installing_kubernetes_and_openshift_cluster">Installing Kubernetes and OpenShift clusters</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
To run the commands in this guide, your
Kubernetes and
OpenShift Origin user must have the rights to manage role-based access control (RBAC).
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="downloads-str">2.1. Strimzi downloads</h3>
<div class="paragraph">
<p>Strimzi releases are available to download from <a href="https://github.com/strimzi/strimzi-kafka-operator/releases" target="_blank" rel="noopener">GitHub</a>. The release artefacts contain documentation, installation, and example <code>.yaml</code> files for deployment on OpenShift or Kubernetes. The installation, and example files are used throughout this documentation. Additionally, a Helm Chart is provided for deploying the Cluster Operator using <a href="https://helm.sh/" target="_blank" rel="noopener">Helm</a>. The container images are available through the <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="cluster-operator-str">2.2. Cluster Operator</h3>
<div class="paragraph">
<p>Strimzi uses the Cluster Operator to deploy and manage Kafka (including Zookeeper) and Kafka Connect clusters.
The Cluster Operator is deployed inside of the
Kubernetes or
OpenShift cluster.
To deploy a Kafka cluster, a <code>Kafka</code> resource with the cluster configuration has to be created within the
Kubernetes or
OpenShift cluster.
Based on what is declared inside of the <code>Kafka</code> resource, the Cluster Operator deploys a corresponding Kafka cluster.
For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Strimzi contains example YAML files, which make deploying a Cluster Operator easier.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-str">2.2.1. Overview of the Cluster Operator component</h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 1. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka or Kafka Connect cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, or <code>KafkaConnectS2I</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka or Kafka Connect cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka or Kafka Connect cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka or Kafka Connect cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-str">2.2.2. Deploying the Cluster Operator to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f install/cluster-operator -n _my-namespace_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-str">2.2.3. Deploying the Cluster Operator to OpenShift</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f install/cluster-operator -n _my-project_
oc apply -f examples/templates/cluster-operator -n _my-project_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesstr">2.2.4. Deploying the Cluster Operator to watch multiple namespaces</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>my-namespace</em></code> or <code><em>my-project</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-project</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-str">2.2.5. Deploying the Cluster Operator using Helm Chart</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi https://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-cluster-str">2.3. Kafka cluster</h3>
<div class="paragraph">
<p>When installing Kafka, Strimzi also installs a Zookeeper cluster and adds the necessary configuration to connect Kafka with Zookeeper.</p>
</div>
<div class="paragraph">
<p>Strimzi provides two options for Kafka cluster deployment:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Ephemeral</dt>
<dd>
<p>is suitable only for development and testing purposes and not for production. This deployment uses <code>emptyDir</code> volumes for storing broker information (Zookeeper) and topics or partitions
(Kafka). Using an <code>emptyDir</code> volume means that its content is strictly related to the pod life cycle and is deleted when the pod goes down.</p>
</dd>
<dt class="hdlist1">Persistent</dt>
<dd>
<p>uses <code>PersistentVolumes</code> to store Zookeeper and Kafka data. The <code>PersistentVolume</code> is
acquired using a <code>PersistentVolumeClaim</code> to make it independent of the actual type of the <code>PersistentVolume</code>. For example, it can use
HostPath volumes on Minikube or
Amazon EBS volumes in Amazon AWS deployments without any changes in the YAML files. The <code>PersistentVolumeClaim</code> can use a <code>StorageClass</code> to trigger automatic volume provisioning.</p>
</dd>
</dl>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-kubernetes-str">2.3.1. Deploying the Kafka cluster to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying a Kafka cluster, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you are planning to use the Kafka broker for development or testing, create an ephemeral cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you are planning to use the Kafka cluster in production, create a persistent cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
<li>
<p>For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-cluster-openshift-str">2.3.2. Deploying the Kafka cluster to OpenShift</h4>
<div class="paragraph">
<p>OpenShift provides a template for deploying the Kafka cluster either in the OpenShift console or on the command-line.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying a Kafka cluster, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>If you are planning to use the Kafka cluster for development or testing, create an ephemeral cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-ephemeral.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>If you are planning to use the Kafka cluster in production, create a persistent cluster</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka/kafka-persistent.yaml</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>
For more information about the different configuration options supported by the <code>Kafka</code> resource, see <a href="#assembly-deployment-configuration-kafka-str">Kafka cluster configuration</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-connect-str">2.4. Kafka Connect</h3>
<div class="paragraph">
<p>The Cluster Operator deploys a <a href="https://kafka.apache.org/documentation/#connect" target="_blank" rel="noopener">Kafka Connect</a> cluster, which can be used with your Kafka broker deployment.
It is implemented as a <code>Deployment</code> with a configurable number of workers.
The default image currently contains only the <code>FileStreamSinkConnector</code> and <code>FileStreamSourceConnector</code> connectors.
The REST interface for managing the Kafka Connect cluster is exposed internally within the OpenShift or Kubernetes cluster as a <code>kafka-connect</code> service on port <code>8083</code>.</p>
</div>
<div class="paragraph">
<p>Example <code>KafkaConnect</code> resources and the details about the <code>KafkaConnect</code> format for deploying Kafka Connect can be found in
<a href="#assembly-deployment-configuration-kafka-connect-str">Kafka Connect cluster configuration</a>
and
<a href="#assembly-deployment-configuration-kafka-connect-s2i-str">Kafka Connect cluster with Source2Image support</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-kubernetes-str">2.4.1. Deploying Kafka Connect to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Connect, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Deploy Kafka Connect on Kubernetes by creating the corresponding <code>KafkaConnect</code> resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-connect-openshift-str">2.4.2. Deploying Kafka Connect to OpenShift</h4>
<div class="paragraph">
<p>On OpenShift, Kafka Connect is provided in the form of a template. It can be deployed from the template using the command-line or through the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Connect, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Create a Kafka Connect cluster from the command-line:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka-connect/kafka-connect.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="using-kafka-connect-with-plugins-str">2.4.3. Using Kafka Connect with plugins</h4>
<div class="paragraph">
<p>Strimzi container images for Kafka Connect contain, by default, only the <code>FileStreamSinkConnector</code> and <code>FileStreamSourceConnector</code> connectors which are part of Apache Kafka.</p>
</div>
<div class="paragraph">
<p>To facilitate deployment with 3rd party connectors, Kafka Connect is configured to automatically load all plugins or connectors that are present in the <code>/opt/kafka/plugins</code> directory during startup.</p>
</div>
<div class="paragraph">
<p>There are two ways of adding custom plugins into this directory:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Using a custom Docker image</p>
</li>
<li>
<p>Using the OpenShift build system with the Strimzi S2I</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="creating-new-image-from-base-str">Create a new image based on our base image</h5>
<div class="paragraph">
<p>Strimzi provides its own Docker image for running Kafka Connect, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as
<code>strimzi/kafka-connect:0.8.0</code>.
This image can be used as a base image for building a new custom image with additional plugins.</p>
</div>
<div class="paragraph">
<p>The following procedure describes the process for creating such a custom image.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a new <code>Dockerfile</code> using <code>strimzi/kafka-connect:0.8.0</code> as the base image:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>FROM strimzi/kafka-connect:0.8.0
USER root:root
COPY ./<em>my-plugins</em>/ /opt/kafka/plugins/
USER kafka:kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Build the container image and upload it to the appropriate container image repository.</p>
</li>
<li>
<p>Set the <code>KafkaConnect.spec.image</code> property of the KafkaConnect custom resource or the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable to point to the new container image.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> variable, see <a href="#ref-operators-cluster-operator-configuration-deploying-co">Cluster Operator Configuration</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaConnect.spec.image property</code>, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka-connect">Container images</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="using-openshift-s2i-create-image-str">Using OpenShift builds and S2I to create new images</h5>
<div class="paragraph">
<p>OpenShift supports <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a>, which can be used together with the <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images.
An OpenShift build takes a builder image with S2I support together with source code and binaries provided by the user and uses them to build a new container image.
The newly created container image is stored in OpenShift&#8217;s local container image repository and can be used in deployments.
Strimzi provides a Kafka Connect builder image, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.8.0</code> with this S2I support.
It takes user-provided binaries (with plugins and connectors) and creates a new Kafka Connect image.
This enhanced Kafka Connect image can be used with the Kafka Connect deployment.</p>
</div>
<div class="paragraph">
<p>The S2I deployment provided as an OpenShift template. It can be deployed from the template using the command-line
or the OpenShift console.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a Kafka Connect S2I cluster from the command-line</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Once the cluster is deployed, a new build can be triggered from the command-line by creating a directory
with Kafka Connect plugins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>my-plugins</em>/
./<em>my-plugins</em>/
├── debezium-connector-mongodb
│   ├── bson-3.4.2.jar
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mongodb-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mongodb-driver-3.4.2.jar
│   ├── mongodb-driver-core-3.4.2.jar
│   └── README.md
├── debezium-connector-mysql
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mysql-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mysql-binlog-connector-java-0.13.0.jar
│   ├── mysql-connector-java-5.1.40.jar
│   ├── README.md
│   └── wkb-1.0.2.jar
└── debezium-connector-postgres
    ├── CHANGELOG.md
    ├── CONTRIBUTE.md
    ├── COPYRIGHT.txt
    ├── debezium-connector-postgres-0.7.1.jar
    ├── debezium-core-0.7.1.jar
    ├── LICENSE.txt
    ├── postgresql-42.0.0.jar
    ├── protobuf-java-2.6.1.jar
    └── README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Start a new image build using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>my-connect-cluster-connect</em> --from-dir ./<em>my-plugins</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build will be changed according to the cluster name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build is finished, the new image will be used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="kafka-mirror-maker-str">2.5. Kafka Mirror Maker</h3>
<div class="paragraph">
<p>The Cluster Operator deploys one or more Kafka Mirror Maker replicas to replicate data between Kafka clusters.
This process is called mirroring to avoid confusion with the Kafka partitions replication concept.
The Mirror Maker consumes messages from the source cluster and republishes those messages to the target cluster.</p>
</div>
<div class="paragraph">
<p>For information about example resources and the format for deploying Kafka Mirror Maker, see <a href="#assembly-deployment-configuration-kafka-mirror-maker-str">Kafka Mirror Maker configuration</a>.</p>
</div>
<div class="sect3">
<h4 id="deploying-kafka-mirror-maker-kubernetes-str">2.5.1. Deploying Kafka Connect to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Mirror Maker, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Deploy Kafka Mirror Maker on Kubernetes by creating the corresponding <code>KafkaMirrorMaker</code> resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f examples/kafka-mirror-maker/kafka-mirror-maker.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-kafka-mirror-maker-openshift-str">2.5.2. Deploying Kafka Mirror Maker to OpenShift</h4>
<div class="paragraph">
<p>On OpenShift, Kafka Mirror Maker is provided in the form of a template. It can be deployed from the template using the command-line or through the OpenShift console.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Before deploying Kafka Mirror Maker, the Cluster Operator must be deployed.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Procedure</div>
<ul>
<li>
<p>Create a Kafka Mirror Maker cluster from the command-line:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f examples/kafka-mirror-maker/kafka-mirror-maker.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-example-clients-str">2.6. Deploying example clients</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the client to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the producer.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc run kafka-producer -ti --image=strimzi/kafka:0.8.0 --restart=Never \-- bin/kafka-console-producer.sh --broker-list <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em></code></pre>
</div>
</div>
</li>
<li>
<p>Type your message into the console where the producer is running.</p>
</li>
<li>
<p>Press Enter to send the message.</p>
</li>
<li>
<p>Deploy the consumer.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc run kafka-consumer -ti --image=strimzi/kafka:0.8.0 --restart=Never \-- bin/kafka-console-consumer.sh --bootstrap-server <em>cluster-name</em>-kafka-bootstrap:9092 --topic <em>my-topic</em> --from-beginning</code></pre>
</div>
</div>
</li>
<li>
<p>Confirm that you see the incoming messages in the consumer console.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-topic-operator-str">2.7. Topic Operator</h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-str">2.7.1. Overview of the Topic Operator component</h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will create the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-str">2.7.2. Deploying the Topic Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Topic Operator can be included in the Entity Operator.
Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator</code> object that configures the Entity Operator.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-getting-started-user-operator-str">2.8. User Operator</h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-str">2.8.1. Overview of the User Operator component</h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-str">2.8.2. Deploying the User Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-deployment-configuration-str">3. Deployment configuration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This chapter describes how to configure different aspects of the supported deployments:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka clusters</p>
</li>
<li>
<p>Kafka Connect clusters</p>
</li>
<li>
<p>Kafka Connect clusters with <em>Source2Image</em> support</p>
</li>
<li>
<p>Kafka Mirror Maker</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-str">3.1. Kafka cluster configuration</h3>
<div class="paragraph">
<p>The full schema of the <code>Kafka</code> resource is described in the <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.
All labels that are applied to the desired <code>Kafka</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-storage-deployment-configuration-kafka">3.1.1. Kafka and Zookeeper storage</h4>
<div class="paragraph">
<p>Kafka brokers and Zookeeper are stateful applications.
They need to store data on disks.
Strimzi allows you to configure the type of storage, which they want to use for Kafka and Zookeeper.
Storage configuration is mandatory and has to be specified in every <code>Kafka</code> resource.</p>
</div>
<div class="paragraph">
<p>Storage can be configured using the <code>storage</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi supports two types of storage:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Ephemeral</p>
</li>
<li>
<p>Persistent</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The type of storage is specified in the <code>type</code> field.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Once the Kafka cluster is deployed, the storage cannot be changed.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="ref-ephemeral-storage-deployment-configuration-kafka">Ephemeral storage</h5>
<div class="paragraph">
<p>Ephemeral storage uses the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir" target="_blank" rel="noopener">`emptyDir` volumes</a> to store data.
To use ephemeral storage, the <code>type</code> field should be set to <code>ephemeral</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<code>EmptyDir</code> volumes are not persistent and the data stored in them will be lost when the Pod is restarted.
After the new pod is started, it has to recover all data from other nodes of the cluster.
Ephemeral storage is not suitable for use with single node Zookeeper clusters and for Kafka topics with replication factor 1, because it will lead to data loss.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example of Ephemeral storage</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: ephemeral
    # ...
  zookeeper:
    # ...
    storage:
      type: ephemeral
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="ref-persistent-storage-deployment-configuration-kafka">Persistent storage</h5>
<div class="paragraph">
<p>Persistent storage uses <a href="https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/" target="_blank" rel="noopener">Persistent Volume Claims</a> to provision persistent volumes for storing data.
Persistent Volume Claims can be used to provision volumes of many different types, depending on the <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> which will provision the volume.
The data types which can be used with persistent volume claims include many types of SAN storage as well as <a href="https://kubernetes.io/docs/concepts/storage/volumes/#local" target="_blank" rel="noopener">Local persistent volumes</a>.</p>
</div>
<div class="paragraph">
<p>To use persistent storage, the <code>type</code> has to be set to <code>persistent-claim</code>.
Persistent storage supports additional configuration options:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>size</code> (required)</dt>
<dd>
<p>Defines the size of the persistent volume claim, for example, "1000Gi".</p>
</dd>
<dt class="hdlist1"><code>class</code> (optional)</dt>
<dd>
<p>The OpenShift or Kubernetes <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">Storage Class</a> to use for dynamic volume provisioning.</p>
</dd>
<dt class="hdlist1"><code>selector</code> (optional)</dt>
<dd>
<p>Allows selecting a specific persistent volume to use.
It contains a <code>matchLabels</code> field which contains key:value pairs representing labels for selecting such a volume.</p>
</dd>
<dt class="hdlist1"><code>delete-claim</code> (optional)</dt>
<dd>
<p>Boolean value which specifies if the Persistent Volume Claim has to be deleted when the cluster is undeployed.
Default is <code>false</code>.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Resizing persistent storage for existing Strimzi clusters is not currently supported.
You must decide the necessary storage size before deploying the cluster.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with 1000Gi <code>size</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1000Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following example demonstrates the use of a storage class.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with specific Storage Class</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  class: my-storage-class
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, a <code>selector</code> can be used to select a specific labeled persistent volume to provide needed features such as an SSD.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment of persistent storage configuration with selector</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
storage:
  type: persistent-claim
  size: 1Gi
  selector:
    matchLabels:
      "hdd-type": "ssd"
  deleteClaim: true
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">Persistent Volume Claim naming</div>
<p>When the persistent storage is used, it will create Persistent Volume Claims with the following names:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code><em>idx</em></code>.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-zookeeper-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code><em>idx</em></code>.</p>
</dd>
</dl>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about ephemeral storage, see <a href="#type-EphemeralStorage-reference">ephemeral storage schema reference</a>.</p>
</li>
<li>
<p>For more information about persistent storage, see <a href="#type-PersistentClaimStorage-reference">persistent storage schema reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-replicas-deployment-configuration-kafka">3.1.2. Replicas</h4>
<div class="paragraph">
<p>Kafka cluster can run with many brokers and Kafka brokers can run with various numbers of nodes.
The number of brokers used for the Kafka cluster is defined in the Kafka resource.
The best number of brokers for your cluster has to be determined based on your specific use case.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-broker-replicas-deployment-configuration-kafka">Configuring the number of broker nodes</h5>
<div class="paragraph">
<p>Number of Kafka broker nodes is configured using the <code>replicas</code> property in <code>Kafka.spec.kafka</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    replicas: 3
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-broker-configuration-deployment-configuration-kafka">3.1.3. Kafka broker configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka brokers.
You can specify and configure most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Broker ID configuration</p>
</li>
<li>
<p>Configuration of log data directories</p>
</li>
<li>
<p>Inter-broker communication</p>
</li>
<li>
<p>Zookeeper connectivity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-broker-configuration-deployment-configuration-kafka">Kafka broker configuration</h5>
<div class="paragraph">
<p>Kafka broker can be configured using the <code>config</code> property in <code>Kafka.spec.kafka</code>.</p>
</div>
<div class="paragraph">
<p>This property should contain the Kafka broker configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://kafka.apache.org/20/documentation.html#brokerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>advertised.</code></p>
</li>
<li>
<p><code>broker.</code></p>
</li>
<li>
<p><code>listener.</code></p>
</li>
<li>
<p><code>host.name</code></p>
</li>
<li>
<p><code>port</code></p>
</li>
<li>
<p><code>inter.broker.listener.name</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>password.</code></p>
</li>
<li>
<p><code>principal.builder.class</code></p>
</li>
<li>
<p><code>log.dir</code></p>
</li>
<li>
<p><code>zookeeper.connect</code></p>
</li>
<li>
<p><code>zookeeper.set.acl</code></p>
</li>
<li>
<p><code>authorizer.</code></p>
</li>
<li>
<p><code>super.user</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Cluster Operator log file.
All other options will be passed to Kafka.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Kafka cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.kafka.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka brokers.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka broker configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    config:
      num.partitions: 1
      num.recovery.threads.per.data.dir: 1
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      num.network.threads: 3
      num.io.threads: 8
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      group.initial.rebalance.delay.ms: 0
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-brokers-deployment-configuration-kafka">Configuring Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    config:
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 1
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">3.1.4. Kafka broker listeners</h4>
<div class="paragraph">
<p>Strimzi allows users to configure the listeners which will be enabled in Kafka brokers.
Two types of listeners are supported:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Plain listener on port 9092 (without encryption)</p>
</li>
<li>
<p>TLS listener on port 9093 (with encryption)</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="con-mutual-tls-authentication-deployment-configuration-kafka">Mutual TLS authentication for clients</h5>
<div class="sect5">
<h6 id="mutual_tls_authentication">Mutual TLS authentication</h6>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_mutual_tls_authentication_for_clients">When to use mutual TLS authentication for clients</h6>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-scram-sha-authentication-deployment-configuration-kafka">SCRAM-SHA authentication</h5>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRMA-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="supported_scram_credentials">Supported SCRAM credentials</h6>
<div class="paragraph">
<p>Strimzi supports SCRMA-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect5">
<h6 id="when_to_use_scram_sha_authentication_for_clients">When to use SCRAM-SHA authentication for clients</h6>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="con-kafka-listeners-deployment-configuration-kafka">Kafka listeners</h5>
<div class="paragraph">
<p>You can configure Kafka broker listeners using the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
The <code>listeners</code> property contains three sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>plain</code></p>
</li>
<li>
<p><code>tls</code></p>
</li>
<li>
<p><code>external</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When none of these properties are defined, the listener will be disabled.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with all listeners enabled</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
  tls: {}
# ...</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">An example of <code>listeners</code> property with only the plain listener enabled</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain: {}
# ...</code></pre>
</div>
</div>
<div class="sect5">
<h6 id="external_listener">External listener</h6>
<div class="paragraph">
<p>The external listener is used to connect to a Kafka cluster from outside of an OpenShift or Kubernetes environment.
Strimzi supports three types of external listeners:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>route</code></p>
</li>
<li>
<p><code>loadbalancer</code></p>
</li>
<li>
<p><code>nodeport</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using OpenShift Routes</div>
<p>An external listener of type <code>route</code> exposes Kafka by using OpenShift <code>Routes</code> and the HAProxy router.
A dedicated <code>Route</code> is created for every Kafka broker pod.
An additional <code>Route</code> is created to serve as a Kafka bootstrap address.
Kafka clients can use these <code>Routes</code> to connect to Kafka on port 443.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code>Routes</code> are available only on OpenShift. External listeners of type <code>route</code> cannot be used on Kubernetes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When exposing Kafka using OpenShift <code>Routes</code>, TLS encryption is always used.</p>
</div>
<div class="paragraph">
<p>For more information on using <code>Routes</code> to access Kafka, see <a href="#proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using loadbalancers</div>
<p>External listeners of type <code>loadbalancer</code> expose Kafka by using <code>Loadbalancer</code> type <code>Services</code>.
A new loadbalancer service is created for every Kafka broker pod.
An additional loadbalancer is created to serve as a Kafka <em>bootstrap</em> address.
Loadbalancers listen to connections on port 9094.</p>
</div>
<div class="paragraph">
<p>By default, TLS encryption is enabled.
To disable it, set the <code>tls</code> field to <code>false</code>.</p>
</div>
<div class="paragraph">
<p>For more information on using loadbalancers to access Kafka, see <a href="#proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers routes</a>.</p>
</div>
<div class="paragraph">
<div class="title">Exposing Kafka using node ports</div>
<p>External listeners of type <code>nodeport</code> expose Kafka by using <code>NodePort</code> type <code>Services</code>.
When exposing Kafka in this way, Kafka clients connect directly to the nodes of OpenShift or Kubernetes.
You must enable access to the ports on the OpenShift or Kubernetes nodes for each client (for example, in firewalls or security groups).
Each Kafka broker pod is then accessible on a separate port.
Additional <code>NodePort</code> type <code>Service</code> is created to serve as a Kafka bootstrap address.</p>
</div>
<div class="paragraph">
<p>When configuring the advertised addresses for the Kafka broker pods, Strimzi uses the address of the node on which the given pod is running.
When selecting the node address, the different address types are used with the following priority:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>By default, TLS encryption is enabled.
To disable it, set the <code>tls</code> field to <code>false</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS hostname verification is not currently supported when exposing Kafka clusters using node ports.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more information on using node ports to access Kafka, see <a href="#proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="listener_authentication">Listener authentication</h6>
<div class="paragraph">
<p>The listener sub-properties can also contain additional configuration.
Both listeners support the <code>authentication</code> property. This is used to specify an authentication mechanism specific to that listener:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>mutual TLS authentication (only on the listeners with TLS encryption)</p>
</li>
<li>
<p>SCRAM-SHA authentication</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If no <code>authentication</code> property is specified then the listener does not authenticate clients which connect though that listener.</p>
</div>
<div class="listingblock">
<div class="title">An example where the plain listener is configured for SCRAM-SHA authentication and the <code>tls</code> listener with mutual TLS authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
listeners:
  plain:
    authentication:
      type: scram-sha-512
  tls:
    authentication:
      type: tls
  external:
    type: loadbalancer
    tls: true
    authentication:
      type: tls
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Authentication must be configured when using the User Operator to manage <code>KafkaUsers</code>.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-listeners-deployment-configuration-kafka">Configuring Kafka listeners</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>An example configuration of the plain (unencrypted) listener without authentication:</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      plain: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-routes-deployment-configuration-kafka">Accessing Kafka using OpenShift routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>route</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use <code>Routes</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: route
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the address of the bootstrap <code>Route</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get routes _cluster-name_-kafka-bootstrap -o=jsonpath='{.status.ingress[0].host}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the address together with port 443 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Extract the public certificate of the broker certification authority</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/_cluster-name_-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-loadbalancers-deployment-configuration-kafka">Accessing Kafka using loadbalancers routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>loadbalancer</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use loadbalancers:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: loadbalancer
        tls: true
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the hostname of the bootstrap loadbalancer.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If no hostname was found (nothing was returned by the command), use the loadbalancer IP address.</p>
</div>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.status.loadBalancer.ingress[0].ip}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the hostname or IP address together with port 9094 in your Kafka client as the <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Unless TLS encryption was disabled, extract the public certificate of the broker certification authority.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>cluster-name</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>cluster-name</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="proc-accessing-kafka-using-nodeports-deployment-configuration-kafka">Accessing Kafka using node ports routes</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy Kafka cluster with an external listener enabled and configured to the type <code>nodeport</code>.</p>
<div class="paragraph">
<p>An example configuration with an external listener configured to use node ports:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      external:
        type: nodeport
        tls: true
        # ...
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Find the port number of the bootstrap service.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get service <em>cluster-name</em>-kafka-external-bootstrap -o=jsonpath='{.spec.ports[0].nodePort}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>The port should be used in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
<li>
<p>Find the address of the OpenShift or Kubernetes node.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get node <em>node-name</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc get node <em>node-name</em> -o=jsonpath='{range .status.addresses[*]}{.type}{"\t"}{.address}{"\n"}'</code></pre>
</div>
</div>
<div class="paragraph">
<p>If several different addresses are returned, select the address type you want based on the following order:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>ExternalDNS</p>
</li>
<li>
<p>ExternalIP</p>
</li>
<li>
<p>Hostname</p>
</li>
<li>
<p>InternalDNS</p>
</li>
<li>
<p>InternalIP</p>
<div class="paragraph">
<p>Use the address with the port found in the previous step in the Kafka <em>bootstrap</em> address.</p>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>Unless TLS encryption was disabled, extract the public certificate of the broker certification authority.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl get</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>cluster-name</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc extract</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>cluster-name</em>-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Use the extracted certificate in your Kafka client to configure TLS connection.
If you enabled any authentication, you will also need to configure SASL or TLS authentication.</p>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-authentication-and-authorization-deployment-configuration-kafka">3.1.5. Authentication and Authorization</h4>
<div class="paragraph">
<p>Strimzi supports authentication and authorization.
Authentication can be configured independently for each <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener</a>.
Authorization is always configured for the whole Kafka cluster.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-authentication-deployment-configuration-kafka">Authentication</h5>
<div class="paragraph">
<p>Authentication is configured as part of the <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listener configuration</a> in the <code>authentication</code> property.
When the <code>authentication</code> property is missing, no authentication will be enabled on given listener.
The authentication mechanism which will be used is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>The supported authentication mechanisms are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL SCRAM-SHA-512</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication">TLS client authentication</h6>
<div class="paragraph">
<p>TLS Client authentication can be enabled by specifying the <code>type</code> as <code>tls</code>.
The TLS client authentication is supported only on the <code>tls</code> listener.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>authentication</code> with type <code>tls</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authentication:
  type: tls
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authentication-deployment-configuration-kafka">Configuring authentication in Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>listeners</code> property in the <code>Kafka.spec.kafka</code> resource.
Add the <code>authentication</code> field to the listeners where you want to enable authentication.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    listeners:
      tls:
        authentication:
          type: tls
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authentication mechanisms, see <a href="#ref-kafka-authentication-deployment-configuration-kafka">authentication reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="ref-kafka-authorization-deployment-configuration-kafka">Authorization</h5>
<div class="paragraph">
<p>Authorization can be configured using the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
When the <code>authorization</code> property is missing, no authorization will be enabled.
When authorization is enabled it will be applied for all enabled <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">listeners</a>.
The authorization method is defined by the <code>type</code> field.</p>
</div>
<div class="paragraph">
<p>Currently, the only supported authorization method is the Simple authorization.</p>
</div>
<div class="sect5">
<h6 id="simple_authorization">Simple authorization</h6>
<div class="paragraph">
<p>Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
To enable simple authorization, the <code>type</code> field should be set to <code>simple</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of Simple authorization</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
authorization:
  type: simple
# ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-kafka-authorization-deployment-configuration-kafka">Configuring authorization in Kafka brokers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add or edit the <code>authorization</code> property in the <code>Kafka.spec.kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    authorization:
      type: simple
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the supported authorization methods, see <a href="#ref-kafka-authorization-deployment-configuration-kafka">authorization reference</a>.</p>
</li>
<li>
<p>For more information about the schema for <code>Kafka</code>, see <a href="#type-Kafka-reference"><code>Kafka</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-replicas-deployment-configuration-kafka">3.1.6. Replicas</h4>
<div class="paragraph">
<p>Zookeeper clusters or ensembles usually run with an odd number of nodes and always requires the majority of the nodes to be available in order to maintain a quorum.
Maintaining a quorum is important because when the Zookeeper cluster loses a quorum, it will stop responding to clients.
As a result, a Zookeeper cluster without a quorum will cause the Kafka brokers to stop working as well.
This is why having a stable and highly available Zookeeper cluster is very important for Strimzi.</p>
</div>
<div class="paragraph">
<p>A Zookeeper cluster is usually deployed with three, five, or seven nodes.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Three nodes</dt>
<dd>
<p>Zookeeper cluster consisting of three nodes requires at least two nodes to be up and running in order to maintain the quorum.
It can tolerate only one node being unavailable.</p>
</dd>
<dt class="hdlist1">Five nodes</dt>
<dd>
<p>Zookeeper cluster consisting of five nodes requires at least three nodes to be up and running in order to maintain the quorum.
It can tolerate two nodes being unavailable.</p>
</dd>
<dt class="hdlist1">Seven nodes</dt>
<dd>
<p>Zookeeper cluster consisting of seven nodes requires at least four nodes to be up and running in order to maintain the quorum.
It can tolerate three nodes being unavailable.</p>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For development purposes, it is also possible to run Zookeeper with a single node.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Having more nodes does not necessarily mean better performance, as the costs to maintain the quorum will rise with the number of nodes in the cluster.
Depending on your availability requirements, you can decide for the number of nodes to use.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-replicas-deployment-configuration-kafka">Number of Zookeeper nodes</h5>
<div class="paragraph">
<p>The number of Zookeeper nodes can be configured using the <code>replicas</code> property in <code>Kafka.spec.zookeeper</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing replicas configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-replicas-deployment-configuration-kafka">Changing number of replicas</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    replicas: 3
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-zookeeper-node-configuration-deployment-configuration-kafka">3.1.7. Zookeeper configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Zookeeper nodes.
You can specify and configure most of the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener configuration</p>
</li>
<li>
<p>Configuration of data directories</p>
</li>
<li>
<p>Zookeeper cluster composition</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-zookeeper-node-configuration-deployment-configuration-kafka">Zookeeper configuration</h5>
<div class="paragraph">
<p>Zookeeper nodes can be configured using the <code>config</code> property in <code>Kafka.spec.zookeeper</code>.
This property should contain the Zookeeper configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in <a href="http://zookeeper.apache.org/doc/r3.4.13/zookeeperAdmin.html" target="_blank" rel="noopener">Zookeeper documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>server.</code></p>
</li>
<li>
<p><code>dataDir</code></p>
</li>
<li>
<p><code>dataLogDir</code></p>
</li>
<li>
<p><code>clientPort</code></p>
</li>
<li>
<p><code>authProvider</code></p>
</li>
<li>
<p><code>quorum.auth</code></p>
</li>
<li>
<p><code>requireClientAuthScheme</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Zookeeper.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When invalid configuration is provided, the Zookeeper cluster might not start or might become unstable.
In such cases, the configuration in the <code>Kafka.spec.zookeeper.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Zookeeper nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>timeTick</code> with default value <code>2000</code></p>
</li>
<li>
<p><code>initLimit</code> with default value <code>5</code></p>
</li>
<li>
<p><code>syncLimit</code> with default value <code>2</code></p>
</li>
<li>
<p><code>autopurge.purgeInterval</code> with default value <code>1</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured when they are not present in the <code>Kafka.spec.zookeeper.config</code> property.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Zookeeper configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-zookeeper-nodes-deployment-configuration-kafka">Configuring Zookeeper</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>Kafka</code> resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    config:
      autopurge.snapRetainCount: 3
      autopurge.purgeInterval: 1
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-entity-operator-deployment-configuration-kafka">3.1.8. Entity Operator</h4>
<div class="paragraph">
<p>The Entity Operator is responsible for managing different entities in a running Kafka cluster.
The currently supported entities are:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Kafka topics</dt>
<dd>
<p>managed by the Topic Operator.</p>
</dd>
<dt class="hdlist1">Kafka users</dt>
<dd>
<p>managed by the User Operator</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Both Topic and User Operators can be deployed on their own.
But the easiest way to deploy them is together with the Kafka cluster as part of the Entity Operator.
The Entity Operator can include either one or both of them depending on the configuration.
They will be automatically configured to manage the topics and users of the Kafka cluster with which they are deployed.</p>
</div>
<div class="paragraph">
<p>For more information about Topic Operator, see <a href="#deploying-the-topic-operator-str">Topic Operator</a>.
For more information about how to use Topic Operator to create or delete topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-entity-operator-deployment-configuration-kafka">Configuration</h5>
<div class="paragraph">
<p>The Entity Operator can be configured using the <code>entityOperator</code> property in <code>Kafka.spec</code></p>
</div>
<div class="paragraph">
<p>The <code>entityOperator</code> property supports several sub-properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tlsSidecar</code></p>
</li>
<li>
<p><code>affinity</code></p>
</li>
<li>
<p><code>tolerations</code></p>
</li>
<li>
<p><code>topicOperator</code></p>
</li>
<li>
<p><code>userOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>tlsSidecar</code> property can be used to configure the TLS sidecar container which is used to communicate with Zookeeper.
For more details about configuring the TLS sidecar, see <a href="#assembly-tls-sidecar-deployment-configuration-kafka">TLS sidecar</a>.</p>
</div>
<div class="paragraph">
<p>The <code>affinity</code> and <code>tolerations</code> properties can be used to configure how OpenShift or Kubernetes schedules the Entity Operator pod.
For more details about pod scheduling, see <a href="#assembly-scheduling-deployment-configuration-kafka">Configuring pod scheduling</a>.</p>
</div>
<div class="paragraph">
<p>The <code>topicOperator</code> property contains the configuration of the Topic Operator.
When this option is missing, the Entity Operator will be deployed without the Topic Operator.</p>
</div>
<div class="paragraph">
<p>The <code>userOperator</code> property contains the configuration of the User Operator.
When this option is missing, the Entity Operator will be deployed without the User Operator.</p>
</div>
<div class="listingblock">
<div class="title">Example of basic configuration enabling both operators</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator: {}
    userOperator: {}</code></pre>
</div>
</div>
<div class="paragraph">
<p>When both <code>topicOperator</code> and <code>userOperator</code> properties are missing, the Entity Operator will be not deployed.</p>
</div>
<div class="sect5">
<h6 id="topic_operator">Topic Operator</h6>
<div class="paragraph">
<p>Topic Operator deployment can be configured using additional options inside the <code>topicOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaTopics</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 90.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 20 seconds.</p>
</dd>
<dt class="hdlist1"><code>topicMetadataMaxAttempts</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its many partitions or replicas. Default is <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the Topic Operator
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the Topic Operator
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="user_operator">User Operator</h6>
<div class="paragraph">
<p>User Operator deployment can be configured using additional options inside the <code>userOperator</code> object.
Following options are supported:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>watchedNamespace</code></dt>
<dd>
<p>The OpenShift or Kubernetes namespace in which the topic operator watches for <code>KafkaUsers</code>.
Default is the namespace where the Kafka cluster is deployed.</p>
</dd>
<dt class="hdlist1"><code>reconciliationIntervalSeconds</code></dt>
<dd>
<p>The interval between periodic reconciliations in seconds. Default is 120.</p>
</dd>
<dt class="hdlist1"><code>zookeeperSessionTimeoutSeconds</code></dt>
<dd>
<p>The Zookeeper session timeout in seconds. Default is 6 seconds.</p>
</dd>
<dt class="hdlist1"><code>image</code></dt>
<dd>
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>resources</code></dt>
<dd>
<p>The <code>resources</code> property configures the amount of resources allocated to the User Operator.
For more details about resource request and limit configuration, see <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">CPU and memory resources</a>.</p>
</dd>
<dt class="hdlist1"><code>logging</code></dt>
<dd>
<p>The <code>logging</code> property configures the logging of the User Operator.
For more details about logging configuration, see <a href="#assembly-logging-deployment-configuration-kafka">Logging</a>.</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">Example of Topic Operator configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    # ...
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60
    # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-entity-operator-deployment-configuration-kafka">Configuring Entity Operator</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>entityOperator</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
  entityOperator:
    topicOperator:
      watchedNamespace: my-topic-namespace
      reconciliationIntervalSeconds: 60
    userOperator:
      watchedNamespace: my-user-namespace
      reconciliationIntervalSeconds: 60</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka">3.1.9. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka">3.1.10. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-rack-deployment-configuration-kafka">3.1.11. Kafka rack awareness</h4>
<div class="paragraph">
<p>The rack awareness feature in Strimzi helps to spread the Kafka broker pods and Kafka topic replicas across different racks.
Enabling rack awareness helps to improve availability of Kafka brokers and the topics they are hosting.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
"Rack" might represent an availability zone, data center, or an actual rack in your data center.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-rack-awareness-deployment-configuration-kafka">Configuring rack awareness in Kafka brokers</h5>
<div class="paragraph">
<p>Kafka rack awareness can be configured in the <code>rack</code> property of <code>Kafka.spec.kafka</code>.
The <code>rack</code> object has one mandatory field named <code>topologyKey</code>.
This key needs to match one of the labels assigned to the OpenShift or Kubernetes cluster nodes.
The label is used by OpenShift or Kubernetes when scheduling the Kafka broker pods to nodes.
If the OpenShift or Kubernetes cluster is running on a cloud provider platform, that label should represent the availability zone where the node is running.
Usually, the nodes are labeled with <code>failure-domain.beta.kubernetes.io/zone</code> that can be easily used as the <code>topologyKey</code> value.
This has the effect of spreading the broker pods across zones, and also setting the brokers' <code>broker.rack</code> configuration parameter inside Kafka broker.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Consult your OpenShift or Kubernetes administrator regarding the node label that represent the zone / rack into which the node is deployed.</p>
</li>
<li>
<p>Edit the <code>rack</code> property in the <code>Kafka</code> resource using the label as the topology key.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    rack:
      topologyKey: failure-domain.beta.kubernetes.io/zone
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional Resources</div>
<ul>
<li>
<p>For information about Configuring init container image for Kafka rack awareness, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka">3.1.12. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka">3.1.13. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka">3.1.14. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka">3.1.15. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-tls-sidecar-deployment-configuration-kafka">3.1.16. TLS sidecar</h4>
<div class="paragraph">
<p>Sidecar is a container which is running in a pod and serves an auxiliary purpose.
The purpose of the TLS sidecar is to encrypt or decrypt the communication between Strimzi components and Zookeeper since Zookeeper does not support TLS encryption natively.
Zookeeper does not support TLS encryption natively.
Therefore Strimzi uses the sidecar to add the TLS support.</p>
</div>
<div class="paragraph">
<p>The TLS sidecar is currrently being used in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka brokers</p>
</li>
<li>
<p>Zookeeper</p>
</li>
<li>
<p>Entity Operator</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="ref-tls-sidecar-deployment-configuration-kafka">TLS sidecar configuration</h5>
<div class="paragraph">
<p>The TLS sidecar can be configured using the <code>tlsSidecar</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The TLS sidecar supports three additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>image</code></p>
</li>
<li>
<p><code>resources</code></p>
</li>
<li>
<p><code>logLevel</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>resources</code> property can be used to specify the <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka">memory and CPU resources</a> allocated for the TLS sidecar.</p>
</div>
<div class="paragraph">
<p>The <code>image</code> property can be used to configure the container image which will be used.
For more details about configuring custom container images, see <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</div>
<div class="paragraph">
<p>The <code>logLevel</code> property is used to specify the logging level.
Following logging levels are supported:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>emerg</p>
</li>
<li>
<p>alert</p>
</li>
<li>
<p>crit</p>
</li>
<li>
<p>err</p>
</li>
<li>
<p>warning</p>
</li>
<li>
<p>notice</p>
</li>
<li>
<p>info</p>
</li>
<li>
<p>debug</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The default value is <em>notice</em>.</p>
</div>
<div class="listingblock">
<div class="title">Example of TLS sidecar configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      image: my-org/my-image:latest
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
      logLevel: debug
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-tls-sidecar-deployment-configuration-kafka">Configuring TLS sidecar</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>tlsSidecar</code> property in the <code>Kafka</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    tlsSidecar:
      resources:
        requests:
          cpu: 200m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 128Mi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka">3.1.17. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-rolling-update-kafka-deployment-configuration-kafka">3.1.18. Performing a rolling update of a Kafka cluster</h4>
<div class="paragraph">
<p>This procedure describes how to manually trigger a rolling update of an existing Kafka cluster by using an OpenShift or Kubernetes annotation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>StatefulSet</code> that controls the Kafka pods you want to manually update.</p>
<div class="paragraph">
<p>For example, if your Kafka cluster is named <em>my-cluster</em>, the corresponding <code>StatefulSet</code> is named <em>my-cluster-kafka</em>.</p>
</div>
</li>
<li>
<p>Annotate a <code>StatefulSet</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate statefulset <em>cluster-name</em>-kafka operator.strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate statefulset <em>cluster-name</em>-kafka operator.strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation to occur (every two minutes by default).
A rolling update of all pods within the annotated <code>StatefulSet</code> is triggered, as long as the annotation was detected by the reconciliation process.
Once the rolling update of all the pods is complete, the annotation is removed from the <code>StatefulSet</code>.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a> and <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-rolling-update-zookeeper-deployment-configuration-kafka">3.1.19. Performing a rolling update of a Zookeeper cluster</h4>
<div class="paragraph">
<p>This procedure describes how to manually trigger a rolling update of an existing Zookeeper cluster by using an OpenShift or Kubernetes annotation.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Zookeeper cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>StatefulSet</code> that controls the Zookeeper pods you want to manually update.</p>
<div class="paragraph">
<p>For example, if your Kafka cluster is named <em>my-cluster</em>, the corresponding <code>StatefulSet</code> is named <em>my-cluster-zookeeper</em>.</p>
</div>
</li>
<li>
<p>Annotate a <code>StatefulSet</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes, use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate statefulset <em>cluster-name</em>-zookeeper operator.strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate statefulset <em>cluster-name</em>-zookeeper operator.strimzi.io/manual-rolling-update=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation to occur (every two minutes by default).
A rolling update of all pods within the annotated <code>StatefulSet</code> is triggered, as long as the annotation was detected by the reconciliation process.
Once the rolling update of all the pods is complete, the annotation is removed from the <code>StatefulSet</code>.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Zookeeper cluster, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-delete-pod-pvc-kafka-deployment-configuration-kafka">3.1.20. Deleting Kafka nodes manually</h4>
<div class="paragraph">
<p>This procedure describes how to delete an existing Kafka node by using an OpenShift or Kubernetes annotation.
Deleting a Kafka node consists of deleting both the <code>Pod</code> on which the Kafka broker is running and the related <code>PersistentVolumeClaim</code> (if the cluster was deployed with persistent storage).
After deletion, the <code>Pod</code> and its related <code>PersistentVolumeClaim</code> are recreated automatically.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Deleting a <code>PersistentVolumeClaim</code> can cause permanent data loss. The following procedure should only be performed if you have encountered storage issues.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>Pod</code> that you want to delete.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, if the cluster is named <em>cluster-name</em>, the pods are named <em>cluster-name</em>-kafka-<em>index</em>, where <em>index</em> starts at zero and ends at the total number of replicas.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Annotate the <code>Pod</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate pod <em>cluster-name</em>-kafka-<em>index</em> operator.strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate pod <em>cluster-name</em>-kafka-<em>index</em> operator.strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation, when the annotated pod with the underlying persistent volume claim will be deleted and then recreated.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Kafka cluster, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a> and <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-manual-delete-pod-pvc-zookeeper-deployment-configuration-kafka">3.1.21. Deleting Zookeeper nodes manually</h4>
<div class="paragraph">
<p>This procedure describes how to delete an existing Zookeeper node by using an OpenShift or Kubernetes annotation.
Deleting a Zookeeper node consists of deleting both the <code>Pod</code> on which Zookeeper is running and the related <code>PersistentVolumeClaim</code> (if the cluster was deployed with persistent storage).
After deletion, the <code>Pod</code> and its related <code>PersistentVolumeClaim</code> are recreated automatically.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Deleting a <code>PersistentVolumeClaim</code> can cause permanent data loss. The following procedure should only be performed if you have encountered storage issues.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Zookeeper cluster.</p>
</li>
<li>
<p>A running Cluster Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find the name of the <code>Pod</code> that you want to delete.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>For example, if the cluster is named <em>cluster-name</em>, the pods are named <em>cluster-name</em>-zookeeper-<em>index</em>, where <em>index</em> starts at zero and ends at the total number of replicas.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Annotate the <code>Pod</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes use <code>kubectl annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl annotate pod <em>cluster-name</em>-zookeeper-<em>index</em> operator.strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift use <code>oc annotate</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc annotate pod <em>cluster-name</em>-zookeeper-<em>index</em> operator.strimzi.io/delete-pod-and-pvc=true</code></pre>
</div>
</div>
</li>
<li>
<p>Wait for the next reconciliation, when the annotated pod with the underlying persistent volume claim will be deleted and then recreated.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Zookeeper cluster, see <a href="#deploying-kafka-cluster-openshift-str">Deploying the Kafka cluster to OpenShift</a> and <a href="#deploying-kafka-cluster-kubernetes-str">Deploying the Kafka cluster to Kubernetes</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-cluster-resources-deployment-configuration-kafka">3.1.22. List of resources created as part of Kafka cluster</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-brokers</code></dt>
<dd>
<p>Service needed to have DNS resolve the Kafka broker pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-bootstrap</code></dt>
<dd>
<p>Service can be used as bootstrap servers for Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap service for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-<em>pod-id</em></code></dt>
<dd>
<p>Service used to route traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-external-bootstrap</code></dt>
<dd>
<p>Bootstrap route for clients connecting from outside of the OpenShift or Kubernetes cluster. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-<em>pod-id</em></code></dt>
<dd>
<p>Route for traffic from outside of the OpenShift or Kubernetes cluster to individual pods. This resource will be created only when external listener is enabled and set to type <code>route</code>.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-config</code></dt>
<dd>
<p>ConfigMap which contains the Kafka ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka-brokers</code></dt>
<dd>
<p>Secret with Kafka broker keys.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-kafka</code></dt>
<dd>
<p>Service account used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>namespace-name</em>-<em>cluster-name</em>-kafka-init</code></dt>
<dd>
<p>Cluster role binding used by the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper</code></dt>
<dd>
<p>StatefulSet which is in charge of managing the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-nodes</code></dt>
<dd>
<p>Service needed to have DNS resolve the Zookeeper pods IP addresses directly.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-client</code></dt>
<dd>
<p>Service used by Kafka brokers to connect to Zookeeper nodes as clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-config</code></dt>
<dd>
<p>ConfigMap which contains the Zookeeper ancillary configuration and is mounted as a volume by the Zookeeper node pods.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-zookeeper-nodes</code></dt>
<dd>
<p>Secret with Zookeeper node keys.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator</code></dt>
<dd>
<p>Deployment with Topic and User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-topic-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for Topic Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-user-operator-config</code></dt>
<dd>
<p>Configmap with ancillary configuration for User Operators. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator-certs</code></dt>
<dd>
<p>Secret with Entitiy operators keys for communication with Kafka and Zookeeper. This resource will be created only if Cluster Operator deployed Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-entity-operator</code></dt>
<dd>
<p>Service account used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>cluster-name</em>-topic-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code>strimzi-<em>cluster-name</em>-user-operator</code></dt>
<dd>
<p>Role binding used by the Entity Operator.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-cluster-ca</code></dt>
<dd>
<p>Secret with the Cluster CA used to encrypt the cluster communication.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-cluster-ca-cert</code></dt>
<dd>
<p>Secret with the Cluster CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-clients-ca</code></dt>
<dd>
<p>Secret with the Clients CA used to encrypt the communication between Kafka brokers and Kafka clients.</p>
</dd>
<dt class="hdlist1"><code><em>cluster-name</em>-clients-ca-cert</code></dt>
<dd>
<p>Secret with the Clients CA public key. This key can be used to verify the identity of the Kafka brokers.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-kafka-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Kafka broker pod <code><em>idx</em></code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
<dt class="hdlist1"><code>data-<em>cluster-name</em>-zookeeper-<em>idx</em></code></dt>
<dd>
<p>Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod <code><em>idx</em></code>. This resource will be created only if persistent storage is selected for provisioning persistent volumes to store data.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-str">3.2. Kafka Connect cluster configuration</h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnect</code> resource is described in the <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnect</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect">3.2.1. Replicas</h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect">Configuring the number of nodes</h5>
<div class="paragraph">
<p>Number of Kafka Connect nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">3.2.2. Bootstrap servers</h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>cluster-name</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code><em>hostname</em>:_port_</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect">Configuring bootstrap servers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect">3.2.3. Connecting to Kafka brokers using TLS</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect">TLS support in Kafka Connect</h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect">Configuring TLS in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect">3.2.4. Connecting to Kafka brokers with Authentication</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect">Authentication support in Kafka Connect</h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_2">TLS Client Authentication</h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication">SCRAM-SHA-512 authentication</h6>
<div class="paragraph">
<p>To use the authentication using the SCRAM-SHA-512 SASL mechanism, set the <code>type</code> property to the value <code>scram-sha-512</code>.
SCRAM-SHA-512 uses a username and password to authenticate.
Specify the username in the <code>username</code> property.
Specify the password as a link to a <code>Secret</code> containing the password in the <code>passwordSecret</code> property.
It has to specify the name of the <code>Secret</code> containing the password and the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: password
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect">Configuring TLS client authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect">Configuring SCRAM-SHA-512 authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>password</em>' &gt; <em>my-password.txt</em>
kubectl create secret generic <em>my-secret</em> --from-file=<em>my-password.txt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>my-password.txt</em>
oc create secret generic <em>my-secret</em> --from-file=<em>my-password.txt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _my-username_
    passwordSecret:
      secretName: _my-secret_
      password: _my-password.txt_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect">3.2.5. Kafka Connect configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect">Kafka Connect configuration</h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
<li>
<p><code>internal.value.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect">Configuring Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">3.2.6. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_2">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_2">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_2">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_2">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_2">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect">3.2.7. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect">3.2.8. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect">3.2.9. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect">3.2.10. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect">3.2.11. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect">3.2.12. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka-connect" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-connect-resources-deployment-configuration-kafka-connect">3.2.13. List of resources created as part of Kafka Connect cluster</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>Deployment which is in charge to create the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-connect-s2i-str">3.3. Kafka Connect cluster with Source2Image support</h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaConnectS2I</code> resource is described in the <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code> schema reference</a>.
All labels that are applied to the desired <code>KafkaConnectS2I</code> resource will also be applied to the OpenShift or Kubernetes resources making up the Kafka Connect cluster with Source2Image support.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">3.3.1. Replicas</h4>
<div class="paragraph">
<p>Kafka Connect clusters can run with a different number of nodes.
The number of nodes is defined in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.
Running Kafka Connect cluster with multiple nodes can provide better availability and scalability.
However, when running Kafka Connect on OpenShift or Kubernetes it is not absolutely necessary to run multiple nodes of Kafka Connect for high availability.
When the node where Kafka Connect is deployed to crashes, OpenShift or Kubernetes will automatically take care of rescheduling the Kafka Connect pod to a different node.
However, running Kafka Connect with multiple nodes can provide faster failover times, because the other nodes will be already up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-replicas-deployment-configuration-kafka-connect-s2i">Configuring the number of nodes</h5>
<div class="paragraph">
<p>Number of Kafka Connect nodes can be configured using the <code>replicas</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">3.3.2. Bootstrap servers</h4>
<div class="paragraph">
<p>Kafka Connect cluster always works together with a Kafka cluster.
The Kafka cluster is specified in the form of a list of bootstrap servers.
On OpenShift or Kubernetes, the list must ideally contain the Kafka cluster bootstrap service which is named <code><em>cluster-name</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>bootstrapServers</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>. The servers should be a comma-separated list containing one or more Kafka brokers or a service pointing to Kafka brokers specified as a <code><em>hostname</em>:_port_</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Connect with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of a given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-bootstrap-servers-deployment-configuration-kafka-connect-s2i">Configuring bootstrap servers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>bootstrapServers</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  bootstrapServers: my-cluster-kafka-bootstrap:9092
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">3.3.3. Connecting to Kafka brokers using TLS</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers using a plain text connection.
If you would prefer to use TLS additional configuration will be necessary.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">TLS support in Kafka Connect</h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-other-secret
        certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnectS2I
metadata:
  name: my-cluster
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-secret
        certificate: ca.crt
      - secretName: my-secret
        certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-file.crt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>tls</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  tls:
    trustedCertificates:
      - secretName: my-cluster-cluster-cert
        certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-authentication-deployment-configuration-kafka-connect-s2i">3.3.4. Connecting to Kafka brokers with Authentication</h4>
<div class="paragraph">
<p>By default, Kafka Connect will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-connect-authenticationdeployment-configuration-kafka-connect-s2i">Authentication support in Kafka Connect</h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>authentication</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
The <code>authentication</code> property specifies the type of the authentication mechanisms which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_3">TLS Client Authentication</h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
TLS client authentication is using TLS certificate to authenticate.
The certificate has to be specified in the <code>certificateAndKey</code> property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X509 format under two different keys: for public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Connect see <a href="#assembly-kafka-connect-tls-deployment-configuration-kafka-connect-s2i">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: public.crt
      key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication_2">SCRAM-SHA-512 authentication</h6>
<div class="paragraph">
<p>To use the authentication using the SCRAM-SHA-512 SASL mechanism, set the <code>type</code> property to the value <code>scram-sha-512</code>.
SCRAM-SHA-512 uses a username and password to authenticate.
Specify the username in the <code>username</code> property.
Specify the password as a link to a <code>Secret</code> containing the password in the <code>passwordSecret</code> property.
It has to specify the name of the <code>Secret</code> containing the password and the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-cluster
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: my-connect-user
    passwordSecret:
      secretName: my-connect-user
      password: password
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-tls-deployment-configuration-kafka-connect-s2i">Configuring TLS client authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>my-secret</em> --from-file=<em>my-public.crt</em> --from-file=<em>my-private.key</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: tls
    certificateAndKey:
      secretName: my-secret
      certificate: my-public.crt
      key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-authentication-scram-sha-512-deployment-configuration-kafka-connect-s2i">Configuring SCRAM-SHA-512 authentication in Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>Username of the user which should be used for authentication</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>password</em>' &gt; <em>my-password.txt</em>
kubectl create secret generic <em>my-secret</em> --from-file=<em>my-password.txt</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>my-password.txt</em>
oc create secret generic <em>my-secret</em> --from-file=<em>my-password.txt</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>authentication</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  authentication:
    type: scram-sha-512
    username: _my-username_
    passwordSecret:
      secretName: _my-secret_
      password: _my-password.txt_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">3.3.5. Kafka Connect configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of Apache Kafka Connect nodes by editing most of the options listed in <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Listener / REST interface configuration</p>
</li>
<li>
<p>Plugin path configuration</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-connect-configuration-deployment-configuration-kafka-connect-s2i">Kafka Connect configuration</h5>
<div class="paragraph">
<p>Kafka Connect can be configured using the <code>config</code> property in <code>KafkaConnect.spec</code> and <code>KafkaConnectS2I.spec</code>.
This property should contain the Kafka Connect configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#connectconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>listeners</code></p>
</li>
<li>
<p><code>plugin.path</code></p>
</li>
<li>
<p><code>rest.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Connect.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Connect cluster might not start or might become unstable.
In such cases, the configuration in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> object should be fixed and the cluster operator will roll out the new configuration to all Kafka Connect nodes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Selected options have default values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>group.id</code> with default value <code>connect-cluster</code></p>
</li>
<li>
<p><code>offset.storage.topic</code> with default value <code>connect-cluster-offsets</code></p>
</li>
<li>
<p><code>config.storage.topic</code> with default value <code>connect-cluster-configs</code></p>
</li>
<li>
<p><code>status.storage.topic</code> with default value <code>connect-cluster-status</code></p>
</li>
<li>
<p><code>key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.value.converter</code> with default value <code>org.apache.kafka.connect.json.JsonConverter</code></p>
</li>
<li>
<p><code>internal.key.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
<li>
<p><code>internal.value.converter.schemas.enable</code> with default value <code>false</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options will be automatically configured in case they are not present in the <code>KafkaConnect.spec.config</code> or <code>KafkaConnectS2I.spec.config</code> properties.</p>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Connect configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-connect-deployment-configuration-kafka-connect-s2i">Configuring Kafka Connect</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>config</code> property in the <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaConnect
metadata:
  name: my-connect
spec:
  # ...
  config:
    group.id: my-connect-cluster
    offset.storage.topic: my-connect-cluster-offsets
    config.storage.topic: my-connect-cluster-configs
    status.storage.topic: my-connect-cluster-status
    key.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    key.converter.schemas.enable: true
    value.converter.schemas.enable: true
    internal.key.converter: org.apache.kafka.connect.json.JsonConverter
    internal.value.converter: org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable: false
    internal.value.converter.schemas.enable: false
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">3.3.6. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_3">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_3">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_3">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_3">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_3">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-connect-s2i">3.3.7. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-connect-s2i">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-connect-s2i">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-connect-s2i">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-healthchecks-deployment-configuration-kafka-connect-s2i">3.3.8. Healthchecks</h4>
<div class="paragraph">
<p>Healthchecks are periodical tests which verify that the application&#8217;s health.
When the Healthcheck fails, OpenShift or Kubernetes can assume that the application is not healthy and attempt to fix it.
OpenShift or Kubernetes supports two types of Healthcheck probes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Liveness probes</p>
</li>
<li>
<p>Readiness probes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more details about the probes, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">Configure Liveness and Readiness Probes</a>.
Both types of probes are used in Strimzi components.</p>
</div>
<div class="paragraph">
<p>Users can configure selected options for liveness and readiness probes</p>
</div>
<div class="sect4">
<h5 id="ref-healthchecks-deployment-configuration-kafka-connect-s2i">Healthcheck configurations</h5>
<div class="paragraph">
<p>Liveness and readiness probes can be configured using the <code>livenessProbe</code> and <code>readinessProbe</code> properties in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both <code>livenessProbe</code> and <code>readinessProbe</code> support two additional options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>initialDelaySeconds</code></p>
</li>
<li>
<p><code>timeoutSeconds</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>initialDelaySeconds</code> property defines the initial delay before the probe is tried for the first time.
Default is 15 seconds.</p>
</div>
<div class="paragraph">
<p>The <code>timeoutSeconds</code> property defines timeout of the probe.
Default is 5 seconds.</p>
</div>
<div class="listingblock">
<div class="title">An example of liveness and readiness probe configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
readinessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
livenessProbe:
  initialDelaySeconds: 15
  timeoutSeconds: 5
# ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-healthchecks-deployment-configuration-kafka-connect-s2i">Configuring healthchecks</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>livenessProbe</code> or <code>readinessProbe</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-connect-s2i">3.3.9. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-connect-s2i">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-connect-s2i">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-connect-s2i">3.3.10. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-connect-s2i">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-connect-s2i">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-connect-s2i">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-connect-s2i">3.3.11. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-connect-s2i">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-connect-s2i">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-connect-s2i">3.3.12. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka-connect-s2i" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-connect-s2i-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-connect-s2i-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-connect-s2i-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-connect-s2i-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-connect-s2i-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-connect-s2i-resources-deployment-configuration-kafka-connect-s2i">3.3.13. List of resources created as part of Kafka Connect cluster with Source2Image support</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-source</dt>
<dd>
<p>ImageStream which is used as the base image for the newly-built Docker images.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>BuildConfig which is responsible for building the new Kafka Connect Docker images.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>ImageStream where the newly built Docker images will be pushed.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect</dt>
<dd>
<p>DeploymentConfig which is in charge of creating the Kafka Connect worker node pods.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-connect-api</dt>
<dd>
<p>Service which exposes the REST interface for managing the Kafka Connect cluster.</p>
</dd>
<dt class="hdlist1"><em>connect-cluster-name</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Connect ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="using-openshift-s2i-create-image-deployment-configuration-kafka-connect-s2i">3.3.14. Using OpenShift builds and S2I to create new images</h4>
<div class="paragraph">
<p>OpenShift supports <a href="https://docs.openshift.org/3.9/dev_guide/builds/index.html" target="_blank" rel="noopener">builds</a>, which can be used together with the <a href="https://docs.openshift.org/3.9/creating_images/s2i.html#creating-images-s2i" target="_blank" rel="noopener">Source-to-Image (S2I)</a> framework to create new container images.
An OpenShift build takes a builder image with S2I support together with source code and binaries provided by the user and uses them to build a new container image.
The newly created container image is stored in OpenShift&#8217;s local container image repository and can be used in deployments.
Strimzi provides a Kafka Connect builder image, which can be found on <a href="https://hub.docker.com/u/strimzi" target="_blank" rel="noopener">Docker Hub</a> as <code>strimzi/kafka-connect-s2i:0.8.0</code> with this S2I support.
It takes user-provided binaries (with plugins and connectors) and creates a new Kafka Connect image.
This enhanced Kafka Connect image can be used with the Kafka Connect deployment.</p>
</div>
<div class="paragraph">
<p>The S2I deployment provided as an OpenShift template. It can be deployed from the template using the command-line
or the OpenShift console.</p>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Create a Kafka Connect S2I cluster from the command-line</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f examples/kafka-connect/kafka-connect-s2i.yaml</code></pre>
</div>
</div>
</li>
<li>
<p>Once the cluster is deployed, a new build can be triggered from the command-line by creating a directory
with Kafka Connect plugins:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>$ tree ./<em>my-plugins</em>/
./<em>my-plugins</em>/
├── debezium-connector-mongodb
│   ├── bson-3.4.2.jar
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mongodb-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mongodb-driver-3.4.2.jar
│   ├── mongodb-driver-core-3.4.2.jar
│   └── README.md
├── debezium-connector-mysql
│   ├── CHANGELOG.md
│   ├── CONTRIBUTE.md
│   ├── COPYRIGHT.txt
│   ├── debezium-connector-mysql-0.7.1.jar
│   ├── debezium-core-0.7.1.jar
│   ├── LICENSE.txt
│   ├── mysql-binlog-connector-java-0.13.0.jar
│   ├── mysql-connector-java-5.1.40.jar
│   ├── README.md
│   └── wkb-1.0.2.jar
└── debezium-connector-postgres
    ├── CHANGELOG.md
    ├── CONTRIBUTE.md
    ├── COPYRIGHT.txt
    ├── debezium-connector-postgres-0.7.1.jar
    ├── debezium-core-0.7.1.jar
    ├── LICENSE.txt
    ├── postgresql-42.0.0.jar
    ├── protobuf-java-2.6.1.jar
    └── README.md</code></pre>
</div>
</div>
</li>
<li>
<p>Start a new image build using the prepared directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc start-build <em>my-connect-cluster-connect</em> --from-dir ./<em>my-plugins</em>/</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The name of the build will be changed according to the cluster name of the deployed Kafka Connect cluster.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once the build is finished, the new image will be used automatically by the Kafka Connect deployment.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-deployment-configuration-kafka-mirror-maker-str">3.4. Kafka Mirror Maker configuration</h3>
<div class="paragraph">
<p>The full schema of the <code>KafkaMirrorMaker</code> resource is described in the <a href="#type-KafkaMirrorMaker-reference"><code>KafkaMirrorMaker</code> schema reference</a>.
All labels that apply to the desired <code>KafkaMirrorMaker</code> resource will also be applied to the OpenShift or Kubernetes resources making up Mirror Maker.
This provides a convenient mechanism for those resources to be labelled in whatever way the user requires.</p>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">3.4.1. Replicas</h4>
<div class="paragraph">
<p>It is possible to run multiple Mirror Maker replicas.
The number of replicas is defined in the <code>KafkaMirrorMaker</code> resource.
You can run multiple Mirror Maker replicas to provide better availability and scalability.
However, when running Kafka Mirror Maker on OpenShift or Kubernetes it is not absolutely necessary to run multiple replicas of the Kafka Mirror Maker for high availability.
When the node where the Kafka Mirror Maker has deployed crashes, OpenShift or Kubernetes will automatically reschedule the Kafka Mirror Maker pod to a different node.
However, running Kafka Mirror Maker with multiple replicas can provide faster failover times as the other nodes will be up and running.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-replicas-deployment-configuration-kafka-mirror-maker">Configuring the number of replicas</h5>
<div class="paragraph">
<p>The number of Kafka Mirror Maker replicas can be configured using the <code>replicas</code> property in <code>KafkaMirrorMaker.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>replicas</code> property in the <code>KafkaMirrorMaker</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  replicas: 3
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">3.4.2. Bootstrap servers</h4>
<div class="paragraph">
<p>Kafka Mirror Maker always works together with two Kafka clusters (source and target).
The source and the target Kafka clusters are specified in the form of two lists of comma-separated list of <code><em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em></code> pairs.
The bootstrap server lists can refer to Kafka clusters which do not need to be deployed in the same OpenShift or Kubernetes cluster.
They can even refer to any Kafka cluster not deployed by Strimzi or even deployed by Strimzi but on a different OpenShift or Kubernetes cluster and accessible from outside.</p>
</div>
<div class="paragraph">
<p>If on the same OpenShift or Kubernetes cluster, each list must ideally contain the Kafka cluster bootstrap service which is named <code><em>&lt;cluster-name&gt;</em>-kafka-bootstrap</code> and a port of 9092 for plain traffic or 9093 for encrypted traffic.
If deployed by Strimzi but on different OpenShift or Kubernetes clusters, the list content depends on the way used for exposing the clusters (routes, nodeports or loadbalancers).</p>
</div>
<div class="paragraph">
<p>The list of bootstrap servers can be configured in the <code>KafkaMirrorMaker.spec.consumer.bootstrapServers</code> and <code>KafkaMirrorMaker.spec.producer.bootstrapServers</code> properties. The servers should be a comma-separated list containing one or more Kafka brokers or a <code>Service</code> pointing to Kafka brokers specified as a <code>&lt;hostname&gt;:&lt;port&gt;</code> pairs.</p>
</div>
<div class="paragraph">
<p>When using Kafka Mirror Maker with a Kafka cluster not managed by Strimzi, you can specify the bootstrap servers list according to the configuration of the given cluster.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-bootstrap-servers-deployment-configuration-kafka-mirror-maker">Configuring bootstrap servers</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.bootstrapServers</code> and <code>KafkaMirrorMaker.spec.producer.bootstrapServers</code> properties.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    bootstrapServers: my-source-cluster-kafka-bootstrap:9092
  # ...
  producer:
    bootstrapServers: my-target-cluster-kafka-bootstrap:9092</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">3.4.3. Whitelist</h4>
<div class="paragraph">
<p>You specify the list topics that the Kafka Mirror Maker has to mirror from the source to the target Kafka cluster in the KafkaMirrorMaker resource using the <em>whitelist</em> option.
It allows any regular expression from the simplest case with a single topic name to complex patterns.
For example, you can mirror topics A and B using "A|B" or all topics using "*".
You can also pass multiple regular expressions separated by commas to the Kafka Mirror Maker.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-whitelist-deployment-configuration-kafka-mirror-maker">Configuring the topics whitelist</h5>
<div class="paragraph">
<p>Specify the list topics that have to be mirrored by the Kafka Mirror Maker from source to target Kafka cluster using the <code>whitelist</code> property in <code>KafkaMirrorMaker.spec</code>.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>whitelist</code> property in the <code>KafkaMirrorMaker</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  whitelist: "my-topic|other-topic"
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">3.4.4. Consumer group identifier</h4>
<div class="paragraph">
<p>The Kafka Mirror Maker uses Kafka consumer to consume messages and it behaves like any other Kafka consumer client.
It is in charge to consume the messages from the source Kafka cluster which will be mirrored to the target Kafka cluster.
The consumer needs to be part of a <em>consumer group</em> for being assigned partitions.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-groupid-deployment-configuration-kafka-mirror-maker">Configuring the consumer group identifier</h5>
<div class="paragraph">
<p>The consumer group identifier can be configured in the <code>KafkaMirrorMaker.spec.consumer.groupId</code> property.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.groupId</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    groupId: "my-group"
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">3.4.5. Number of consumer streams</h4>
<div class="paragraph">
<p>You can increase the throughput in mirroring topics by increase the number of consumer threads.
More consumer threads will belong to the same configured <em>consumer group</em>.
The topic partitions will be assigned across these consumer threads which will consume messages in parallel.</p>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-numstreams-deployment-configuration-kafka-mirror-maker">Configuring the number of consumer streams</h5>
<div class="paragraph">
<p>The number of consumer streams can be configured using the <code>KafkaMirrorMaker.spec.consumer.numStreams</code> property.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.numStreams</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    numStreams: 2
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">3.4.6. Connecting to Kafka brokers using TLS</h4>
<div class="paragraph">
<p>By default, Kafka Mirror Maker will try to connect to Kafka brokers, in the source and target clusters, using a plain text connection.
You must make additional configurations to use TLS.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">TLS support in Kafka Mirror Maker</h5>
<div class="paragraph">
<p>TLS support is configured in the <code>tls</code> sub-property of <code>consumer</code> and <code>producer</code> properties in <code>KafkaMirrorMaker.spec</code>.
The <code>tls</code> property contains a list of secrets with key names under which the certificates are stored.
The certificates should be stored in X.509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-source-secret
          certificate: ca.crt
        - secretName: my-other-source-secret
          certificate: certificate.crt
  # ...
  producer:
    tls:
      trustedCertificates:
        - secretName: my-target-secret
          certificate: ca.crt
        - secretName: my-other-target-secret
          certificate: certificate.crt
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When multiple certificates are stored in the same secret, it can be listed multiple times.</p>
</div>
<div class="listingblock">
<div class="title">An example showing TLS configuration with multiple certificates from the same secret</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-source-secret
          certificate: ca.crt
        - secretName: my-source-secret
          certificate: ca2.crt
  # ...
  producer:
    tls:
      trustedCertificates:
        - secretName: my-target-secret
          certificate: ca.crt
        - secretName: my-target-secret
          certificate: ca2.crt
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">Configuring TLS encryption in Kafka Mirror Maker</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure TLS for one or both the clusters.
The following steps describe how to configure TLS on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the secret with the certificate which should be used for TLS Server Authentication and the key under which the certificate is stored in the secret.
If such secret does not exist yet, prepare the certificate in a file and create the secret.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-file.crt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.tls</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    tls:
      trustedCertificates:
        - secretName: my-cluster-cluster-cert
          certificate: ca.crt
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring TLS on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.tls</code> property.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-authentication-deployment-configuration-kafka-mirror-maker">3.4.7. Connecting to Kafka brokers with Authentication</h4>
<div class="paragraph">
<p>By default, Kafka Mirror Maker will try to connect to Kafka brokers without any authentication.
Authentication can be enabled in the <code>KafkaMirrorMaker</code> resource.</p>
</div>
<div class="sect4">
<h5 id="con-kafka-mirror-maker-authenticationdeployment-configuration-kafka-mirror-maker">Authentication support in Kafka Mirror Maker</h5>
<div class="paragraph">
<p>Authentication can be configured in the <code>KafkaMirrorMaker.spec.consumer.authentication</code> and <code>KafkaMirrorMaker.spec.producer.authentication</code> properties.
The <code>authentication</code> property specifies the type of the authentication method which should be used and additional configuration details depending on the mechanism.
The currently supported authentication types are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>TLS client authentication</p>
</li>
<li>
<p>SASL based authentication using SCRAM-SHA-512 mechanism</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="tls_client_authentication_4">TLS Client Authentication</h6>
<div class="paragraph">
<p>To use the TLS client authentication, set the <code>type</code> property to the value <code>tls</code>.
The TLS client authentication uses TLS certificate to authenticate.
The certificate has to be specified in the certificateAndKey property.
It is always loaded from an OpenShift or Kubernetes secret.
Inside the secret, it has to be stored in the X.509 format separately as public and private keys.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
TLS client authentication can be used only with TLS connections.
For more details about TLS configuration in Kafka Mirror Maker see <a href="#assembly-kafka-mirror-maker-tls-deployment-configuration-kafka-mirror-maker">Connecting to Kafka brokers using TLS</a>.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing TLS client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-source-secret
        certificate: public.crt
        key: private.key
  # ...
  producer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-target-secret
        certificate: public.crt
        key: private.key
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="scram_sha_512_authentication_3">SCRAM-SHA-512 authentication</h6>
<div class="paragraph">
<p>To use the authentication using the SCRAM-SHA-512 SASL mechanism, set the <code>type</code> property to the value <code>scram-sha-512</code>.
It is possible to use it only if the broker listener, clients are connecting to, is configured to use it.
SCRAM-SHA-512 uses a username and password to authenticate.
Specify the username in the <code>username</code> property.
Specify the password as a link to a <code>Secret</code> containing the password in the <code>passwordSecret</code> property.
It has to specify the name of the <code>Secret</code> containing the password and the name of the key under which the password is stored inside the <code>Secret</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing SCRAM-SHA-512 client authentication configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: scram-sha-512
      username: my-source-user
      passwordSecret:
        secretName: my-source-user
        password: password
  # ...
  producer:
    authentication:
      type: scram-sha-512
      username: my-producer-user
      passwordSecret:
        secretName: my-producer-user
        password: password
  # ...</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-authentication-tls-deployment-configuration-kafka-mirror-maker">Configuring TLS client authentication in Kafka Mirror Maker</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator with a <code>tls</code> listener with <code>tls</code> authentication enabled</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure TLS client authentication for one or both the clusters.
The following steps describe how to configure TLS client authentication on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the public and private keys which should be used for TLS Client Authentication and the keys under which they are stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare the keys in a file and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-public.crt&gt;</em> --from-file=<em>&lt;my-private.key&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.authentication</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: tls
      certificateAndKey:
        secretName: my-secret
        certificate: my-public.crt
        key: my-private.key
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring TLS client authentication on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.authentication</code> property.</p>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-authentication-scram-sha-512-deployment-configuration-kafka-mirror-maker">Configuring SCRAM-SHA-512 authentication in Kafka Mirror Maker</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator with a <code>listener</code> configured for SCRAM-SHA-512 authentication</p>
</li>
<li>
<p>Username to be used for authentication</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">Procedure</div>
<p>As the Kafka Mirror Maker connects to two Kafka clusters (source and target), you can choose to configure SCRAM-SHA-512 authentication for one or both the clusters.
The following steps describe how to configure SCRAM-SHA-512 authentication on the consumer side for connecting to the source Kafka cluster:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Find out the name of the <code>Secret</code> with the password which should be used for authentication and the key under which the password is stored in the <code>Secret</code>.
If such a <code>Secret</code> does not exist yet, prepare a file with the password and create the <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '<em>&lt;password&gt;</em>' &gt; <em>&lt;my-password.txt&gt;</em>
kubectl create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc create</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">echo -n '1f2d1e2e67df' &gt; <em>&lt;my-password.txt&gt;</em>
oc create secret generic <em>&lt;my-secret&gt;</em> --from-file=<em>&lt;my-password.txt&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.authentication</code> property.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirrorMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    authentication:
      type: scram-sha-512
      username: _&lt;my-username&gt;_
      passwordSecret:
        secretName: _&lt;my-secret&gt;_
        password: _&lt;my-password.txt&gt;_
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Repeat the above steps for configuring SCRAM-SHA-512 authentication on the target Kafka cluster.
In this case, the secret containing the certificate has to be configured in the <code>KafkaMirrorMaker.spec.producer.authentication</code> property.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">3.4.8. Kafka Mirror Maker configuration</h4>
<div class="paragraph">
<p>Strimzi allows you to customize the configuration of the Kafka Mirror Maker by editing most of the options for the related consumer and producer.
Producer options are listed in <a href="http://kafka.apache.org/20/documentation.html#producerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.
Consumer options are listed in <a href="http://kafka.apache.org/20/documentation.html#newconsumerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a>.</p>
</div>
<div class="paragraph">
<p>The only options which cannot be configured are those related to the following areas:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka cluster bootstrap address</p>
</li>
<li>
<p>Security (Encryption, Authentication, and Authorization)</p>
</li>
<li>
<p>Consumer group identifier</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These options are automatically configured by Strimzi.</p>
</div>
<div class="sect4">
<h5 id="ref-kafka-mirror-maker-configuration-deployment-configuration-kafka-mirror-maker">Kafka Mirror Maker configuration</h5>
<div class="paragraph">
<p>Kafka Mirror Maker can be configured using the <code>config</code> sub-property in <code>KafkaMirrorMaker.spec.consumer</code> and <code>KafkaMirrorMaker.spec.producer</code>.
This property should contain the Kafka Mirror Maker consumer and producer configuration options as keys.
The values could be in one of the following JSON types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>String</p>
</li>
<li>
<p>Number</p>
</li>
<li>
<p>Boolean</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users can specify and configure the options listed in the <a href="http://kafka.apache.org/20/documentation.html#producerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> and <a href="http://kafka.apache.org/20/documentation.html#newconsumerconfigs" target="_blank" rel="noopener">Apache Kafka documentation</a> with the exception of those options which are managed directly by Strimzi.
Specifically, all configuration options with keys equal to or starting with one of the following strings are forbidden:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ssl.</code></p>
</li>
<li>
<p><code>sasl.</code></p>
</li>
<li>
<p><code>security.</code></p>
</li>
<li>
<p><code>bootstrap.servers</code></p>
</li>
<li>
<p><code>group.id</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When one of the forbidden options is present in the <code>config</code> property, it will be ignored and a warning message will be printed to the Custer Operator log file.
All other options will be passed to Kafka Mirror Maker.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The Cluster Operator does not validate keys or values in the provided <code>config</code> object.
When an invalid configuration is provided, the Kafka Mirror Maker might not start or might become unstable.
In such cases, the configuration in the <code>KafkaMirrorMaker.spec.consumer.config</code> or <code>KafkaMirrorMaker.spec.producer.config</code> object should be fixed and the cluster operator will roll out the new configuration for Kafka Mirror Maker.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">An example showing Kafka Mirror Maker configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirroMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    config:
      max.poll.records: 100
      receive.buffer.bytes: 32768
  producer:
    config:
      compression.type: gzip
      batch.size: 8192
  # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-kafka-mirror-maker-deployment-configuration-kafka-mirror-maker">Configuring Kafka Mirror Maker</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Two OpenShift or Kubernetes clusters (source and target)</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>KafkaMirrorMaker.spec.consumer.config</code> and <code>KafkaMirrorMaker.spec.producer.config</code> properties.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaMirroMaker
metadata:
  name: my-mirror-maker
spec:
  # ...
  consumer:
    config:
      max.poll.records: 100
      receive.buffer.bytes: 32768
  producer:
    config:
      compression.type: gzip
      batch.size: 8192
  # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>&lt;your-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">3.4.9. CPU and memory resources</h4>
<div class="paragraph">
<p>For every deployed container, Strimzi allows you to specify the resources which should be reserved for it and the maximum resources that can be consumed by it.
Strimzi supports two types of resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>CPU</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Strimzi is using the OpenShift or Kubernetes syntax for specifying CPU and memory resources.</p>
</div>
<div class="sect4">
<h5 id="ref-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">Resource limits and requests</h5>
<div class="paragraph">
<p>Resource limits and requests can be configured using the <code>resources</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="resource_requests_4">Resource requests</h6>
<div class="paragraph">
<p>Requests specify the resources that will be reserved for a given container.
Reserving the resources will ensure that they are always available.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
If the resource request is for more than the available free resources in the OpenShift or Kubernetes cluster, the pod will not be scheduled.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Resource requests can be specified in the <code>request</code> property.
The resource requests currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify a resource request just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource request configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="resource_limits_4">Resource limits</h6>
<div class="paragraph">
<p>Limits specify the maximum resources that can be consumed by a given container.
The limit is not reserved and might not be always available.
The container can use the resources up to the limit only when they are available.
The resource limits should be always higher than the resource requests.</p>
</div>
<div class="paragraph">
<p>Resource limits can be specified in the <code>limits</code> property.
The resource limits currently supported by Strimzi are memory and CPU.
Memory is specified under the property <code>memory</code>.
CPU is specified under the property <code>cpu</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    cpu: 12
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to specify the resource limit just for one of the resources:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limit configuration with memory request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  limits:
    memory: 64Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or:</p>
</div>
<div class="listingblock">
<div class="title">An example showing resource limits configuration with CPU request only</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 12
# ...</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="supported_cpu_formats_4">Supported CPU formats</h6>
<div class="paragraph">
<p>CPU requests and limits are supported in the following formats:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Number of CPU cores as integer (<code>5</code> CPU core) or decimal (<code>2.5</code> CPU core).</p>
</li>
<li>
<p>Number or <em>millicpus</em> / <em>millicores</em> (<code>100m</code>) where 1000 <em>millicores</em> is the same <code>1</code> CPU core.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different CPU units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    cpu: 500m
  limits:
    cpu: 2.5
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The amount of computing power of 1 CPU core might differ depending on the platform where the OpenShift or Kubernetes is deployed.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For more details about the CPU specification, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu" target="_blank" rel="noopener">Meaning of CPU</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="supported_memory_formats_4">Supported memory formats</h6>
<div class="paragraph">
<p>Memory requests and limits are specified in megabytes, gigabytes, mebibytes, and gibibytes.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To specify memory in megabytes, use the <code>M</code> suffix. For example <code>1000M</code>.</p>
</li>
<li>
<p>To specify memory in gigabytes, use the <code>G</code> suffix. For example <code>1G</code>.</p>
</li>
<li>
<p>To specify memory in mebibytes, use the <code>Mi</code> suffix. For example <code>1000Mi</code>.</p>
</li>
<li>
<p>To specify memory in gibibytes, use the <code>Gi</code> suffix. For example <code>1Gi</code>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">An example of using different memory units</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
resources:
  requests:
    memory: 512Mi
  limits:
    memory: 2Gi
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more details about the memory specification and additional supported units, see the <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory" target="_blank" rel="noopener">Meaning of memory</a> website.</p>
</div>
</div>
<div class="sect5">
<h6 id="additional_resources_4">Additional resources</h6>
<div class="ulist">
<ul>
<li>
<p>For more information about managing computing resources on OpenShift or Kubernetes, see <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">Configuring resource requests and limits</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>resources</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "8"
        memory: 64Gi
      limits:
        cpu: "12"
        memory: 128Gi
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-logging-deployment-configuration-kafka-mirror-maker">3.4.10. Logging</h4>
<div class="paragraph">
<p>Logging enables you to diagnose error and performance issues of Strimzi.
For the logging, various logger implementations are used.
Kafka and Zookeeper use <code>log4j</code> logger and Topic Operator, User Operator, and other components use <code>log4j2</code> logger.</p>
</div>
<div class="paragraph">
<p>This section provides information about different loggers and describes how to configure log levels.</p>
</div>
<div class="paragraph">
<p>You can set the log levels by specifying the loggers and their levels directly (inline) or by using a custom (external) config map.</p>
</div>
<div class="sect4">
<h5 id="kafka-inline-logging-deployment-configuration-kafka-mirror-maker">Using inline logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the loggers and their level for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: inline
      loggers:
       <em>logger.name</em>: "INFO"
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the log level is set to INFO.
You can set the log level to INFO, ERROR, WARN, TRACE, DEBUG, FATAL or OFF. For more information about the log levels, see link: <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html" target="_blank" rel="noopener">log4j manual</a>.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-external-logging-deployment-configuration-kafka-mirror-maker">Using external ConfigMap for logging setting</h5>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the YAML file to specify the name of the <code>ConfigMap</code> which should be used for the required components. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: {KafkaApiVersion}
kind: Kafka
spec:
  kafka:
    # ...
    logging:
      type: external
      name: customConfigMap
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember to place your custom ConfigMap under <code>log4j.properties</code> eventually <code>log4j2.properties</code> key.</p>
</div>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="kafka-logging-loggers-deployment-configuration-kafka-mirror-maker">Loggers</h5>
<div class="paragraph">
<p>Strimzi consists of several components. Each component has its own loggers and is configurable.
This section provides information about loggers of various components.</p>
</div>
<div class="paragraph">
<p>Components and their loggers are listed below.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka</p>
<div class="ulist">
<ul>
<li>
<p><code>kafka.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient.ZkClient</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.kafka</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.request.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.Processor</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.server.KafkaApis</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.network.RequestChannel$</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.controller</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.log.LogCleaner</code></p>
</li>
<li>
<p><code>log4j.logger.state.change.logger</code></p>
</li>
<li>
<p><code>log4j.logger.kafka.authorizer.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Zookeeper</p>
<div class="ulist">
<ul>
<li>
<p><code>zookeeper.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Connect and Kafka Connect with Source2Image support</p>
<div class="ulist">
<ul>
<li>
<p><code>connect.root.logger.level</code></p>
</li>
<li>
<p><code>log4j.logger.org.apache.zookeeper</code></p>
</li>
<li>
<p><code>log4j.logger.org.I0Itec.zkclient</code></p>
</li>
<li>
<p><code>log4j.logger.org.reflections</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Kafka Mirror Maker</p>
<div class="ulist">
<ul>
<li>
<p><code>mirrormaker.root.logger</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Topic Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>User Operator</p>
<div class="ulist">
<ul>
<li>
<p><code>rootLogger.level</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-metrics-deployment-configuration-kafka-mirror-maker">3.4.11. Prometheus metrics</h4>
<div class="paragraph">
<p>Strimzi supports Prometheus metrics using <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a> to convert the JMX metrics supported by Apache Kafka and Zookeeper to Prometheus metrics.
When metrics are enabled, they are exposed on port 9404.</p>
</div>
<div class="paragraph">
<p>For more information about configuring Prometheus and Grafana, see <a href="#metrics-str">Metrics</a>.</p>
</div>
<div class="sect4">
<h5 id="ref-metrics-deployment-configuration-kafka-mirror-maker">Metrics configuration</h5>
<div class="paragraph">
<p>Prometheus metrics can be enabled by configuring the <code>metrics</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When the <code>metrics</code> property is not defined in the resource, the Prometheus metrics will be disabled.
To enable Prometheus metrics export without any further configuration, you can set it to an empty object (<code>{}</code>).</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics without any further configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics: {}
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>metrics</code> property might contain additional configuration for the <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">Prometheus JMX exporter</a>.</p>
</div>
<div class="listingblock">
<div class="title">Example of enabling metrics with additional Prometheus JMX Exporter configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    metrics:
      lowercaseOutputName: true
      rules:
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
        - pattern: "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count"
          name: "kafka_server_$1_$2_total"
          labels:
            topic: "$3"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-metrics-deployment-configuration-kafka-mirror-maker">Configuring Prometheus metrics</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>metrics</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
  zookeeper:
    # ...
    metrics:
      lowercaseOutputName: true
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-jvm-options-deployment-configuration-kafka-mirror-maker">3.4.12. JVM Options</h4>
<div class="paragraph">
<p>Apache Kafka and Apache Zookeeper are running inside of a Java Virtual Machine (JVM).
JVM has many configuration options to optimize the performance for different platforms and architectures.
Strimzi allows configuring some of these options.</p>
</div>
<div class="sect4">
<h5 id="ref-jvm-options-deployment-configuration-kafka-mirror-maker">JVM configuration</h5>
<div class="paragraph">
<p>JVM options can be configured using the <code>jvmOptions</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Only a selected subset of available JVM options can be configured.
The following options are supported:</p>
</div>
<div class="paragraph">
<div class="title">-Xms and -Xmx</div>
<p><code>-Xms</code> configures the minimum initial allocation heap size when the JVM starts.
<code>-Xmx</code> configures the maximum heap size.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The units accepted by JVM settings such as <code>-Xmx</code> and <code>-Xms</code> are those accepted by the JDK <code>java</code> binary in the corresponding image.
Accordingly, <code>1g</code> or <code>1G</code> means 1,073,741,824 bytes, and <code>Gi</code> is not a valid unit suffix.
This is in contrast to the units used for <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">memory requests and limits</a>, which follow the OpenShift or Kubernetes convention where <code>1G</code> means 1,000,000,000 bytes, and <code>1Gi</code> means 1,073,741,824 bytes
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default values used for <code>-Xms</code> and <code>-Xmx</code> depends on whether there is a <a href="#assembly-resource-limits-and-requests-deployment-configuration-kafka-mirror-maker">memory request</a> limit configured for the container:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If there is a memory limit then the JVM&#8217;s minimum and maximum memory will be set to a value corresponding to the limit.</p>
</li>
<li>
<p>If there is no memory limit then the JVM&#8217;s minimum memory will be set to <code>128M</code> and the JVM&#8217;s maximum memory will not be defined.  This allows for the JVM&#8217;s memory to grow as-needed, which is ideal for single node environments in test and development.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
<div class="paragraph">
<p>Setting <code>-Xmx</code> explicitly requires some care:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The JVM&#8217;s overall memory usage will be approximately 4 × the maximum heap, as configured by <code>-Xmx</code>.</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory limit, it is possible that the container will be killed should the OpenShift or Kubernetes node experience memory pressure (from other Pods running on it).</p>
</li>
<li>
<p>If <code>-Xmx</code> is set without also setting an appropriate OpenShift or Kubernetes memory request, it is possible that the container will be scheduled to a node with insufficient memory.
In this case, the container will not start but crash (immediately if <code>-Xms</code> is set to <code>-Xmx</code>, or some later time if not).</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When setting <code>-Xmx</code> explicitly, it is recommended to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set the memory request and the memory limit to the same value,</p>
</li>
<li>
<p>use a memory request that is at least 4.5 × the <code>-Xmx</code>,</p>
</li>
<li>
<p>consider setting <code>-Xms</code> to the same value as <code>-Xms</code>.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available for use as operating system page cache.
On such containers, the requested memory should be significantly higher than the memory used by the JVM.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-Xmx</code> and <code>-Xms</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-Xmx": "2g"
  "-Xms": "2g"
# ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.</p>
</div>
<div class="paragraph">
<p>Setting the same value for initial (<code>-Xms</code>) and maximum (<code>-Xmx</code>) heap sizes avoids the JVM having to allocate memory after startup, at the cost of possibly allocating more heap than is really needed.
For Kafka and Zookeeper pods such allocation could cause unwanted latency.
For Kafka Connect avoiding over allocation may be the most important concern, especially in distributed mode where the effects of over-allocation will be multiplied by the number of consumers.</p>
</div>
<div class="paragraph">
<div class="title">-server</div>
<p><code>-server</code> enables the server JVM. This option can be set to true or false.</p>
</div>
<div class="listingblock">
<div class="title">Example fragment configuring <code>-server</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml"># ...
jvmOptions:
  "-server": true
# ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<div class="title">-XX</div>
<p><code>-XX</code> object can be used for configuring advanced runtime options of a JVM.
The <code>-server</code> and <code>-XX</code> options are used to configure the <code>KAFKA_JVM_PERFORMANCE_OPTS</code> option of Apache Kafka.</p>
</div>
<div class="listingblock">
<div class="title">Example showing the use of the <code>-XX</code> object</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">jvmOptions:
  "-XX":
    "UseG1GC": true,
    "MaxGCPauseMillis": 20,
    "InitiatingHeapOccupancyPercent": 35,
    "ExplicitGCInvokesConcurrent": true,
    "UseParNewGC": false</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example configuration above will result in the following JVM options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
When neither of the two options (<code>-server</code> and <code>-XX</code>) is specified, the default Apache Kafka configuration of <code>KAFKA_JVM_PERFORMANCE_OPTS</code> will be used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-jvm-options-deployment-configuration-kafka-mirror-maker">Configuring JVM options</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>jvmOptions</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "8g"
      "-Xms": "8g"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-configuring-container-images-deployment-configuration-kafka-mirror-maker">3.4.13. Container images</h4>
<div class="paragraph">
<p>Strimzi allows you to configure container images which will be used for its components.
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such a case, you should either copy the Strimzi images or build them from the source.
If the configured image is not compatible with Strimzi images, it might not work properly.</p>
</div>
<div class="sect4">
<h5 id="ref-configuring-container-images-deployment-configuration-kafka-mirror-maker">Container image configurations</h5>
<div class="paragraph">
<p>Container image which should be used for given components can be specified using the <code>image</code> property in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.kafka.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper.tlsSidecar</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.topicOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.userOperator</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator.tlsSidecar</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>image</code> specified in the component-specific custom resource will be used during deployment. If the <code>image</code> field is missing, the <code>image</code> specified in the Cluster Operator configuration will be used. If the <code>image</code> name is not defined in the Cluster Operator configuration, then the default value will be used.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For Kafka brokers:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka broker TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper nodes:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Zookeeper node TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/zookeeper-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Topic Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.
.** <code>strimzi/topic-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For User Operator:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/user-operator:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Entity Operator TLS sidecar:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/entity-operator-stunnel:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
<li>
<p>For Kafka Connect with Source2image support:</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Container image specified in the <code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code> environment variable from the Cluster Operator configuration.</p>
</li>
<li>
<p><code>strimzi/kafka-connect-s2i:latest</code> container image.</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
Overriding container images is recommended only in special situations, where you need to use a different container registry.
For example, because your network does not allow access to the container repository used by Strimzi.
In such case, you should either copy the Strimzi images or build them from source.
In case the configured image is not compatible with Strimzi images, it might not work properly.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example of container image configuration</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="proc-configuring-container-images-deployment-configuration-kafka-mirror-maker">Configuring container images</h5>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>image</code> property in the <code>Kafka</code>, <code>KafkaConnect</code> or <code>KafkaConnectS2I</code> resource.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    image: my-org/my-image:latest
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assembly-scheduling-deployment-configuration-kafka-mirror-maker">3.4.14. Configuring pod scheduling</h4>
<div id="con-scheduling-deployment-configuration-kafka-mirror-maker" class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
When two application are scheduled to the same OpenShift or Kubernetes node, both applications might use the same resources like disk I/O and impact performance.
That can lead to performance degradation.
Scheduling Kafka pods in a way that avoids sharing nodes with other critical workloads, using the right nodes or dedicated a set of nodes only for Kafka are the best ways how to avoid such problems.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="assembly-scheduling-pods-based-on-other-applications-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Scheduling pods based on other applications</h5>
<div class="sect5">
<h6 id="con-scheduling-based-on-other-pods-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Avoid critical applications to share the node</h6>
<div class="paragraph">
<p>Pod anti-affinity can be used to ensure that critical applications are never scheduled on the same disk.
When running Kafka cluster, it is recommended to use pod anti-affinity to ensure that the Kafka brokers do not share the nodes with other workloads like databases.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="configuring-pod-anti-affinity-in-kafka-components-deployment-configuration-kafka-mirror-maker-scheduling-based-on-pods">Configuring pod anti-affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
Use labels to specify the pods which should not be scheduled on the same nodes.
The <code>topologyKey</code> should be set to <code>kubernetes.io/hostname</code> to specify that the selected pods should not be scheduled on nodes with the same hostname.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: application
                  operator: In
                  values:
                    - postgresql
                    - mongodb
            topologyKey: "kubernetes.io/hostname"
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-node-scheduling-deployment-configuration-kafka-mirror-maker-node-scheduling">Scheduling pods to specific nodes</h5>
<div class="sect5">
<h6 id="con-scheduling-to-specific-nodes-deployment-configuration-kafka-mirror-maker-node-scheduling">Node scheduling</h6>
<div class="paragraph">
<p>The OpenShift or Kubernetes cluster usually consists of many different types of worker nodes.
Some are optimized for CPU heavy workloads, some for memory, while other might be optimized for storage (fast local SSDs) or network.
Using different nodes helps to optimize both costs and performance.
To achieve the best possible performance, it is important to allow scheduling of Strimzi components to use the right nodes.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes uses node affinity to schedule workloads onto specific nodes.
Node affinity allows you to create a scheduling constraint for the node on which the pod will be scheduled.
The constraint is specified as a label selector.
You can specify the label using either the built-in node label like <code>beta.kubernetes.io/instance-type</code> or custom labels to select the right node.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-node-scheduling">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-configuring-node-affinity-deployment-configuration-kafka-mirror-maker-node-scheduling">Configuring node affinity in Kafka components</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Label the nodes where Strimzi components should be scheduled.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> node-type=fast-network</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, some of the existing labels might be reused.</p>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> property in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - fast-network
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="assembly-dedidcated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Using dedicated nodes</h5>
<div class="sect5">
<h6 id="con-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Dedicated nodes</h6>
<div class="paragraph">
<p>Cluster administrators can mark selected OpenShift or Kubernetes nodes as tainted.
Nodes with taints are excluded from regular scheduling and normal pods will not be scheduled to run on them.
Only services which can tolerate the taint set on the node can be scheduled on it.
The only other services running on such nodes will be system services such as log collectors or software defined networks.</p>
</div>
<div class="paragraph">
<p>Taints can be used to create dedicated nodes.
Running Kafka and its components on dedicated nodes can have many advantages.
There will be no other applications running on the same nodes which could cause disturbance or consume the resources needed for Kafka.
That can lead to improved performance and stability.</p>
</div>
<div class="paragraph">
<p>To schedule Kafka pods on the dedicated nodes, configure <a href="#affinity-deployment-configuration-kafka-mirror-maker-dedicated-nodes">node affinity</a> and <a href="#tolerations-deployment-configuration-kafka-mirror-maker-dedicated-nodes">tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="affinity-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Affinity</h6>
<div class="paragraph">
<p>Affinity can be configured using the <code>affinity</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The affinity configuration can include different types of affinity:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Pod affinity and anti-affinity</p>
</li>
<li>
<p>Node affinity</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>affinity</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes node and pod affinity documentation</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="tolerations-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Tolerations</h6>
<div class="paragraph">
<p>Tolerations ca be configured using the <code>tolerations</code> property in following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Kafka.spec.kafka</code></p>
</li>
<li>
<p><code>Kafka.spec.zookeeper</code></p>
</li>
<li>
<p><code>Kafka.spec.entityOperator</code></p>
</li>
<li>
<p><code>KafkaConnect.spec</code></p>
</li>
<li>
<p><code>KafkaConnectS2I.spec</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the <code>tolerations</code> property follows the OpenShift or Kubernetes specification.
For more details, see the <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Kubernetes taints and tolerations</a>.</p>
</div>
</div>
<div class="sect5">
<h6 id="proc-dedicated-nodes-deployment-configuration-kafka-mirror-maker-dedicated-nodes">Setting up dedicated nodes and scheduling pods on them</h6>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An OpenShift or Kubernetes cluster</p>
</li>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Select the nodes which should be used as dedicated</p>
</li>
<li>
<p>Make sure there are no workloads scheduled on these nodes</p>
</li>
<li>
<p>Set the taints on the selected nodes</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc adm taint</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc adm taint node <em>your-node</em> dedicated=Kafka:NoSchedule</code></pre>
</div>
</div>
</li>
<li>
<p>Additionally, add a label to the selected nodes as well.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc label</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc label node <em>your-node</em> dedicated=Kafka</code></pre>
</div>
</div>
</li>
<li>
<p>Edit the <code>affinity</code> and <code>tolerations</code> properties in the resource specifying the cluster deployment.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  kafka:
    # ...
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "Kafka"
        effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: dedicated
              operator: In
              values:
              - Kafka
    # ...
  zookeeper:
    # ...</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="ref-list-of-kafka-mirror-maker-resources-deployment-configuration-kafka-mirror-maker">3.4.15. List of resources created as part of Kafka Mirror Maker</h4>
<div class="paragraph">
<p>The following resources will created by the Cluster Operator in the OpenShift or Kubernetes cluster:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><em>&lt;mirror-maker-name&gt;</em>-mirror-maker</dt>
<dd>
<p>Deployment which is in charge to create the Kafka Mirror Maker pods.</p>
</dd>
<dt class="hdlist1"><em>&lt;mirror-maker-name&gt;</em>-config</dt>
<dd>
<p>ConfigMap which contains the Kafka Mirror Maker ancillary configuration and is mounted as a volume by the Kafka broker pods.</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-operators-str">4. Operators</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="assembly-operators-cluster-operator-str">4.1. Cluster Operator</h3>
<div class="sect3">
<h4 id="con-what-the-cluster-operator-does-deploying-co">4.1.1. Overview of the Cluster Operator component</h4>
<div class="paragraph">
<p>The Cluster Operator is in charge of deploying a Kafka cluster alongside a Zookeeper ensemble.
As part of the Kafka cluster, it can also deploy the topic operator which provides operator-style topic management via <code>KafkaTopic</code> custom resources.
The Cluster Operator is also able to deploy a Kafka Connect cluster which connects to an existing Kafka cluster.
On OpenShift such a cluster can be deployed using the Source2Image feature, providing an easy way of including more connectors.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cluster_operator.png" alt="Cluster Operator">
</div>
<div class="title">Figure 2. Example Architecture diagram of the Cluster Operator.</div>
</div>
<div class="paragraph">
<p>When the Cluster Operator is up, it starts to <em>watch</em> for certain OpenShift or Kubernetes resources containing the desired Kafka or Kafka Connect cluster configuration.
By default, it watches only in the same namespace or project where it is installed.
The Cluster Operator can be configured to watch for more OpenShift projects or Kubernetes namespaces.
Cluster Operator watches the following resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>Kafka</code> resource for the Kafka cluster.</p>
</li>
<li>
<p>A <code>KafkaConnect</code> resource for the Kafka Connect cluster.</p>
</li>
<li>
<p>A <code>KafkaConnectS2I</code> resource for the Kafka Connect cluster with Source2Image support.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When a new <code>Kafka</code>, <code>KafkaConnect</code>, or <code>KafkaConnectS2I</code> resource is created in the OpenShift or Kubernetes cluster, the operator gets the cluster description from the desired resource and starts creating a new Kafka or Kafka Connect cluster by creating the necessary other OpenShift or Kubernetes resources, such as StatefulSets, Services, ConfigMaps, and so on.</p>
</div>
<div class="paragraph">
<p>Every time the desired resource is updated by the user, the operator performs corresponding updates on the OpenShift or Kubernetes resources which make up the Kafka or Kafka Connect cluster.
Resources are either patched or deleted and then re-created in order to make the Kafka or Kafka Connect cluster reflect the state of the desired cluster resource.
This might cause a rolling update which might lead to service disruption.</p>
</div>
<div class="paragraph">
<p>Finally, when the desired resource is deleted, the operator starts to undeploy the cluster and delete all the related OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-deploying-co">4.1.2. Deploying the Cluster Operator to Kubernetes</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>kubectl apply -f install/cluster-operator -n _my-namespace_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-openshift-deploying-co">4.1.3. Deploying the Cluster Operator to OpenShift</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A user with <code>cluster-admin</code> role needs to be used, for example, <code>system:admin</code>.</p>
</li>
<li>
<p>Modify the installation files according to the namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-project</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Deploy the Cluster Operator</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>oc apply -f install/cluster-operator -n _my-project_
oc apply -f examples/templates/cluster-operator -n _my-project_</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-kubernetes-to-watch-multiple-namespacesdeploying-co">4.1.4. Deploying the Cluster Operator to watch multiple namespaces</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Edit the installation files according to the OpenShift project or Kubernetes namespace the Cluster Operator is going to be installed in.</p>
<div class="paragraph">
<p>On Linux, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>On MacOS, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>sed -i '' 's/namespace: .*/namespace: <em>my-namespace</em>/' install/cluster-operator/*RoleBinding*.yaml</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the file <code>install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml</code> and in the environment variable <code>STRIMZI_NAMESPACE</code> list all the OpenShift projects or Kubernetes namespaces where Cluster Operator should watch for resources.
For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
spec:
  template:
    spec:
      serviceAccountName: strimzi-cluster-operator
      containers:
      - name: strimzi-cluster-operator
        image: strimzi/cluster-operator:latest
        imagePullPolicy: IfNotPresent
        env:
        - name: STRIMZI_NAMESPACE
          value: myproject,myproject2,myproject3</code></pre>
</div>
</div>
</li>
<li>
<p>For all namespaces or projects which should be watched by the Cluster Operator, install the <code>RoleBindings</code>.
Replace the <code><em>my-namespace</em></code> or <code><em>my-project</em></code> with the OpenShift project or Kubernetes namespace used in the previous step.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-namespace</em>
kubectl apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml -n <em>my-project</em>
oc apply -f install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml -n <em>my-project</em></code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/cluster-operator -n <em>my-namespace</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/cluster-operator -n <em>my-project</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="deploying-cluster-operator-helm-chart-deploying-co">4.1.5. Deploying the Cluster Operator using Helm Chart</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>Helm client has to be installed on the local machine.</p>
</li>
<li>
<p>Helm has to be installed in the OpenShift or Kubernetes cluster.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Add the Strimzi Helm Chart repository:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm repo add strimzi https://strimzi.io/charts/</code></pre>
</div>
</div>
</li>
<li>
<p>Deploy the Cluster Operator using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm install strimzi/strimzi-kafka-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify whether the Cluster Operator has been deployed successfully using the Helm command line tool:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">helm ls</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about Helm, see the <a href="https://helm.sh/" target="_blank" rel="noopener">Helm website</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-reconciliation-deploying-co">4.1.6. Reconciliation</h4>
<div class="paragraph">
<p>Although the operator reacts to all notifications about the desired cluster resources received from the OpenShift or Kubernetes cluster,
if the operator is not running, or if a notification is not received for any reason, the desired resources will get out of sync with the state of the running OpenShift or Kubernetes cluster.</p>
</div>
<div class="paragraph">
<p>In order to handle failovers properly, a periodic reconciliation process is executed by the Cluster Operator so that it can compare the state of the desired resources with the current cluster deployments in order to have a consistent state across all of them.
You can set the time interval for the periodic reconciliations using the <a href="#STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></a> variable.</p>
</div>
</div>
<div class="sect3">
<h4 id="ref-operators-cluster-operator-configuration-deploying-co">4.1.7. Cluster Operator Configuration</h4>
<div class="paragraph">
<p>The Cluster Operator can be configured through the following supported environment variables:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_NAMESPACE</code></dt>
<dd>
<p>Required. A comma-separated list of namespaces that the operator should
operate in. The Cluster Operator deployment might use the <a href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api" target="_blank" rel="noopener">Kubernetes Downward API</a>
to set this automatically to the namespace the Cluster Operator is deployed in. See the example below:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">env:
  - name: STRIMZI_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1"><a id="STRIMZI_FULL_RECONCILIATION_INTERVAL_MS"></a> <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>Optional, default: 120000 ms. The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>Optional, default <code>INFO</code>.
The level for printing logging messages. The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_OPERATION_TIMEOUT_MS</code></dt>
<dd>
<p>Optional, default: 300000 ms. The timeout for internal operations, in milliseconds. This value should be
increased when using Strimzi on clusters where regular OpenShift or Kubernetes operations take longer than usual (because of slow downloading of Docker images, for example).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka:latest</code>.
The image name to use as the default when deploying Kafka, if
no image is specified as the <code>Kafka.spec.kafka.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_INIT_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-init:latest</code>.
The image name to use as default for the init container started before the broker for initial configuration work (that is, rack support), if no image is specified as the <code>kafka-init-image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Kafka,
if no image is specified as the <code>Kafka.spec.kafka.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper:latest</code>.
The image name to use as the default when deploying Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/zookeeper-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for Zookeeper, if
no image is specified as the <code>Kafka.spec.zookeeper.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-connect:latest</code>.
The image name to use as the default when deploying Kafka Connect,
if no image is specified as the <code>image</code> in the Kafka Connect cluster ConfigMap</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/kafka-connect-s2i:latest</code>.
The image name to use as the default when deploying Kafka Connect S2I,
if no image is specified as the <code>image</code> in the cluster ConfigMap.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/topic-operator:latest</code>.
The image name to use as the default when deploying the topic operator,
if no image is specified as the <code>Kafka.spec.entityOperator.topicOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_USER_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/user-operator:latest</code>.
The image name to use as the default when deploying the user operator,
if no image is specified as the <code>Kafka.spec.entityOperator.userOperator.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a> of the <code>Kafka</code> resource.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE</code></dt>
<dd>
<p>Optional, default <code>strimzi/entity-operator-stunnel:latest</code>.
The image name to use as the default when deploying the sidecar container which provides TLS support for the Entity Operator, if
no image is specified as the <code>Kafka.spec.entityOperator.tlsSidecar.image</code> in the <a href="#assembly-configuring-container-images-deployment-configuration-kafka">Container images</a>.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="con-cluster-operator-rbac-deploying-co">4.1.8. Role-Based Access Control (RBAC)</h4>
<div class="sect4">
<h5 id="provisioning_role_based_access_control_rbac_for_the_cluster_operator">Provisioning Role-Based Access Control (RBAC) for the Cluster Operator</h5>
<div class="paragraph">
<p>For the Cluster Operator to function it needs permission within the OpenShift or Kubernetes cluster to interact with resources such as <code>Kafka</code>, <code>KafkaConnect</code>, and so on, as well as the managed resources, such as <code>ConfigMaps</code>, <code>Pods</code>, <code>Deployments</code>, <code>StatefulSets</code>, <code>Services</code>, and so on.
Such permission is described in terms of OpenShift or Kubernetes role-based access control (RBAC) resources:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ServiceAccount</code>,</p>
</li>
<li>
<p><code>Role</code> and <code>ClusterRole</code>,</p>
</li>
<li>
<p><code>RoleBinding</code> and <code>ClusterRoleBinding</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In addition to running under its own <code>ServiceAccount</code> with a <code>ClusterRoleBinding</code>, the Cluster Operator manages some RBAC resources for the components that need access to OpenShift or Kubernetes resources.</p>
</div>
<div class="paragraph">
<p>OpenShift or Kubernetes also includes privilege escalation protections that prevent components operating under one <code>ServiceAccount</code> from granting other <code>ServiceAccounts</code> privileges that the granting <code>ServiceAccount</code> does not have.
Because the Cluster Operator must be able to create the <code>ClusterRoleBindings</code>, and <code>RoleBindings</code> needed by resources it manages, the Cluster Operator must also have those same privileges.</p>
</div>
</div>
<div class="sect4">
<h5 id="delegated-privileges-deploying-co">Delegated privileges</h5>
<div class="paragraph">
<p>When the Cluster Operator deploys resources for a desired <code>Kafka</code> resource it also creates <code>ServiceAccounts</code>, <code>RoleBindings</code>, and <code>ClusterRoleBindings</code>, as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The Kafka broker pods use a <code>ServiceAccount</code> called <code><em>cluster-name</em>-kafka</code></p>
<div class="ulist">
<ul>
<li>
<p>When the rack feature is used, the <code>strimzi-<em>cluster-name</em>-kafka-init</code> <code>ClusterRoleBinding</code> is used to grant this <code>ServiceAccount</code> access to the nodes within the cluster via a <code>ClusterRole</code> called <code>strimzi-kafka-broker</code></p>
</li>
<li>
<p>When the rack feature is not used no binding is created.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The Zookeeper pods use the default <code>ServiceAccount</code>, as they do not need access to the OpenShift or Kubernetes resources.</p>
</li>
<li>
<p>The Topic Operator pod uses a <code>ServiceAccount</code> called <code><em>cluster-name</em>-topic-operator</code></p>
<div class="ulist">
<ul>
<li>
<p>The Topic Operator produces OpenShift or Kubernetes events with status information, so the <code>ServiceAccount</code> is bound to a <code>ClusterRole</code> called <code>strimzi-topic-operator</code> which grants this access via the <code>strimzi-topic-operator-role-binding</code> <code>RoleBinding</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The pods for <code>KafkaConnect</code> and <code>KafkaConnectS2I</code> resources use the default <code>ServiceAccount</code>, as they do not require access to the OpenShift or Kubernetes resources.</p>
</div>
</div>
<div class="sect4">
<h5 id="serviceaccount"><code>ServiceAccount</code></h5>
<div class="paragraph">
<p>The Cluster Operator is best run using a <code>ServiceAccount</code>:</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ServiceAccount</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Deployment</code> of the operator then needs to specify this in its <code>spec.template.spec.serviceAccountName</code>:</p>
</div>
<div class="listingblock">
<div class="title">Partial example of <code>Deployment</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
    spec:
      # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note line 12, where the the <code>strimzi-cluster-operator</code> <code>ServiceAccount</code> is specified as the <code>serviceAccountName</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="clusterroles"><code>ClusterRoles</code></h5>
<div class="paragraph">
<p>The Cluster Operator needs to operate using <code>ClusterRoles</code> that gives access to the necessary resources.
Depending on the OpenShift or Kubernetes cluster setup, a cluster administrator might be needed to create the <code>ClusterRoles</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Cluster administrator rights are only needed for the creation of the <code>ClusterRoles</code>.
The Cluster Operator will not run under the cluster admin account.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <code>ClusterRoles</code> follow the <em>principle of least privilege</em> and contain only those privileges needed by the Cluster Operator to operate Kafka, Kafka Connect, and Zookeeper clusters. The first set of assigned privileges allow the Cluster Operator to manage OpenShift or Kubernetes resources such as <code>StatefulSets</code>, <code>Deployments</code>, <code>Pods</code>, and <code>ConfigMaps</code>.</p>
</div>
<div class="paragraph">
<p>Cluster Operator uses ClusterRoles to grant permission at the namespace-scoped resources level and cluster-scoped resources level:</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with namespaced resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - serviceaccounts
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - rolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkas
  - kafkaconnects
  - kafkaconnects2is
  - kafkamirrormakers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
  - delete
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - deployments
  - deployments/scale
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps
  resources:
  - deployments
  - deployments/scale
  - deployments/status
  - statefulsets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - extensions
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - apps.openshift.io
  resources:
  - deploymentconfigs
  - deploymentconfigs/scale
  - deploymentconfigs/status
  - deploymentconfigs/finalizers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - build.openshift.io
  resources:
  - buildconfigs
  - builds
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - watch
  - update
- apiGroups:
  - image.openshift.io
  resources:
  - imagestreams
  - imagestreams/status
  verbs:
  - create
  - delete
  - get
  - list
  - watch
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - replicationcontrollers
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - extensions
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
  - routes
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The second includes the permissions needed for cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> with cluster-scoped resources for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
rules:
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - clusterrolebindings
  verbs:
  - get
  - create
  - delete
  - patch
  - update</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-kafka-broker</code> <code>ClusterRole</code> represents the access needed by the init container in Kafka pods that is used for the rack feature. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to OpenShift or Kubernetes nodes to the Kafka broker pods</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>strimzi-topic-operator</code> <code>ClusterRole</code> represents the access needed by the Topic Operator. As described in the <a href="#delegated-privileges-deploying-co">Delegated privileges</a> section, this role is also needed by the Cluster Operator in order to be able to delegate this access.</p>
</div>
<div class="listingblock">
<div class="title"><code>ClusterRole</code> for the Cluster Operator allowing it to delegate access to events to the Topic Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
rules:
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkatopics
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
- apiGroups:
  - kafka.strimzi.io
  resources:
  - kafkausers
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - create
  - patch
  - update
  - delete</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="clusterrolebindings"><code>ClusterRoleBindings</code></h5>
<div class="paragraph">
<p>The operator needs <code>ClusterRoleBindings</code> and <code>RoleBindings</code> which associates its <code>ClusterRole</code> with its <code>ServiceAccount</code>:
<code>ClusterRoleBindings</code> are needed for <code>ClusterRoles</code> containing cluster-scoped resources.</p>
</div>
<div class="listingblock">
<div class="title">Example <code>ClusterRoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoleBindings</code> are also needed for the <code>ClusterRoles</code> needed for delegation:</p>
</div>
<div class="listingblock">
<div class="title">Examples <code>RoleBinding</code> for the Cluster Operator</div>
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ClusterRoles</code> containing only namespaced resources are bound using <code>RoleBindings</code> only.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight nowrap"><code class="language-yaml hljs" data-lang="yaml">apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  labels:
    app: strimzi
subjects:
- kind: ServiceAccount
  name: strimzi-cluster-operator
  namespace: myproject
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="deploying-the-topic-operator-str">4.2. Topic Operator</h3>
<div class="sect3">
<h4 id="what-the-topic-operator-does-deploying">4.2.1. Overview of the Topic Operator component</h4>
<div class="paragraph">
<p>The Topic Operator provides a way of managing topics in a Kafka cluster via OpenShift or Kubernetes resources.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/topic_operator.png" alt="Topic Operator">
</div>
</div>
<div class="paragraph">
<p>The role of the Topic Operator is to keep a set of <code>KafkaTopic</code> OpenShift or Kubernetes resources describing Kafka topics in-sync with corresponding Kafka topics.</p>
</div>
<div class="paragraph">
<p>Specifically:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaTopic</code> is created, the operator will create the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is deleted, the operator will delete the topic it describes</p>
</li>
<li>
<p>if a <code>KafkaTopic</code> is changed, the operator will update the topic it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And also, in the other direction:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a topic is created within the Kafka cluster, the operator will create a <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic is deleted from the Kafka cluster, the operator will create the <code>KafkaTopic</code> describing it</p>
</li>
<li>
<p>if a topic in the Kafka cluster is changed, the operator will update the <code>KafkaTopic</code> describing it</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This allows you to declare a <code>KafkaTopic</code> as part of your application&#8217;s deployment and the Topic Operator will take care of creating the topic for you.
Your application just needs to deal with producing or consuming from the necessary topics.</p>
</div>
<div class="paragraph">
<p>If the topic be reconfigured or reassigned to different Kafka nodes, the <code>KafkaTopic</code> will always be up to date.</p>
</div>
<div class="paragraph">
<p>For more details about creating, modifying and deleting topics, see <a href="#using-the-topic-operator-str">Using the Topic Operator</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="how-the-topic-operator-works-deploying">4.2.2. Understanding the Topic Operator</h4>
<div class="paragraph">
<p>A fundamental problem that the operator has to solve is that there is no single source of truth:
Both the <code>KafkaTopic</code> resource and the topic within Kafka can be modified independently of the operator.
Complicating this, the Topic Operator might not always be able to observe changes at each end in real time (for example, the operator might be down).</p>
</div>
<div class="paragraph">
<p>To resolve this, the operator maintains its own private copy of the information about each topic.
When a change happens either in the Kafka cluster, or in OpenShift or Kubernetes, it looks at both the state of the other system and at its private copy in order to determine what needs to change to keep everything in sync.
The same thing happens whenever the operator starts, and periodically while it is running.</p>
</div>
<div class="paragraph">
<p>For example, suppose the Topic Operator is not running, and a <code>KafkaTopic</code> <code>my-topic</code> gets created.
When the operator starts it will lack a private copy of "my-topic", so it can infer that the <code>KafkaTopic</code> has been created since it was last running.
The operator will create the topic corresponding to "my-topic" and also store a private copy of the metadata for "my-topic".</p>
</div>
<div class="paragraph">
<p>The private copy allows the operator to cope with scenarios where the topic configuration gets changed both in Kafka and in OpenShift or Kubernetes, so long as the changes are not incompatible (for example, both changing the same topic config key, but to different values).
In the case of incompatible changes, the Kafka configuration wins, and the <code>KafkaTopic</code> will be updated to reflect that.</p>
</div>
<div class="paragraph">
<p>The private copy is held in the same ZooKeeper ensemble used by Kafka itself.
This mitigates availability concerns, because if ZooKeeper is not running then Kafka itself cannot run, so the operator will be no less available than it would even if it was stateless.</p>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-using-the-cluster-operator-deploying">4.2.3. Deploying the Topic Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Topic Operator can be included in the Entity Operator.
Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator</code> object that configures the Entity Operator.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the Topic Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-topic-operator-with-resource-requests-limits-deploying">4.2.4. Configuring the Topic Operator with resource requests and limits</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource specifying in the <code>Kafka.spec.entityOperator.topicOperator.resources</code> property the resource requests and limits you want the Topic Operator to have.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
spec:
  # kafka and zookeeper sections...
  topicOperator:
    resources:
      request:
        cpu: "1"
        memory: 500Mi
      limit:
        cpu: "1"
        memory: 500Mi</code></pre>
</div>
</div>
</li>
<li>
<p>Create or update the <code>Kafka</code> resource.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema of the resources object, see <a href="#type-Resources-reference"><code>Resources</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="deploying-the-topic-operator-standalone-deploying">4.2.5. Deploying the standalone Topic Operator</h4>
<div class="paragraph">
<p>Deploying the Topic Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance is can operate <em>with</em> any Kafka cluster, not necessarily one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the Topic Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>install/topic-operator/05-Deployment-strimzi-topic-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of bootstrap brokers in your Kafka cluster, given as a comma-separated list of <code><em>hostname</em>:‍<em>port</em></code> pairs.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>hostname</em>:‍<em>port</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaTopic</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/topic-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the Topic Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-topic-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The Topic Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the environment variables used to configure the Topic Operator, see <a href="#topic-operator-environment-deploying">Topic Operator environment</a>.</p>
</li>
<li>
<p>For more information about getting the Cluster Operator to deploy the Topic Operator for you, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="topic-operator-environment-deploying">4.2.6. Topic Operator environment</h4>
<div class="paragraph">
<p>When deployed standalone the Topic Operator can be configured using environment variables.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The Topic Operator should be configured using the <code>Kafka.spec.entityOperator.topicOperator</code> property when deployed by the Cluster Operator.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>STRIMZI_RESOURCE_LABELS</code></dt>
<dd>
<p>The label selector used to identify <code>KafkaTopics</code> to be managed by the operator.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_SESSION_TIMEOUT_MS</code></dt>
<dd>
<p>The Zookeeper session timeout, in milliseconds.
For example, <code>10000</code>.
Default: <code>20000</code> (20 seconds).</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KAFKA_BOOTSTRAP_SERVERS</code></dt>
<dd>
<p>The list of Kafka bootstrap servers.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_ZOOKEEPER_CONNECT</code></dt>
<dd>
<p>The Zookeeper connection information.
This variable is mandatory.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code></dt>
<dd>
<p>The interval between periodic reconciliations, in milliseconds.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TOPIC_METADATA_MAX_ATTEMPTS</code></dt>
<dd>
<p>The number of attempts for getting topics metadata from Kafka.
The time between each attempt is defined as an exponential back-off.
You might want to increase this value when topic creation could take more time due to its larger size (that is, many partitions/replicas).
Default <code>6</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_LOG_LEVEL</code></dt>
<dd>
<p>The level for printing logging messages.
The value can be set to: <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.
Default <code>INFO</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TLS_ENABLED</code></dt>
<dd>
<p>For enabling the TLS support so encrypting the communication with Kafka brokers.
Default <code>true</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_LOCATION</code></dt>
<dd>
<p>The path to the truststore containing certificates for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_TRUSTSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the truststore defined by <code>STRIMZI_TRUSTSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_LOCATION</code></dt>
<dd>
<p>The path to the keystore containing private keys for enabling TLS based communication.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
<dt class="hdlist1"><code>STRIMZI_KEYSTORE_PASSWORD</code></dt>
<dd>
<p>The password for accessing the keystore defined by <code>STRIMZI_KEYSTORE_LOCATION</code>.
This variable is mandatory only if TLS is enabled through <code>STRIMZI_TLS_ENABLED</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="assembly-user-operator-str">4.3. User Operator</h3>
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect3">
<h4 id="con-what-the-user-operator-does-deploying-uo">4.3.1. Overview of the User Operator component</h4>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-using-the-cluster-operator-deploying-uo">4.3.2. Deploying the User Operator using the Cluster Operator</h4>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Cluster Operator</p>
</li>
<li>
<p>A <code>Kafka</code> resource to be created or updated.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource ensuring it has a <code>Kafka.spec.entityOperator.userOperator</code> object that configures the User Operator how you want.</p>
</li>
<li>
<p>Create or update the Kafka resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>Kafka.spec.entityOperator</code> object used to configure the User Operator when deployed by the Cluster Operator, see <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="proc-deploying-the-user-operator-standalone-deploying-uo">4.3.3. Deploying the standalone User Operator</h4>
<div class="paragraph">
<p>Deploying the User Operator as a standalone component is more complicated than installing it using the Cluster Operator, but is more flexible.
For instance it can operate <em>with</em> any Kafka cluster, not only the one deployed by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>An existing Kafka cluster for the User Operator to connect to.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>install/user-operator/05-Deployment-strimzi-user-operator.yaml</code> resource. You will need to change the following</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>The <code>STRIMZI_CA_NAME</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to point to an OpenShift or Kubernetes <code>Secret</code> which should contain the Certificate Authority for signing new user certificates for TLS Client Authentication.
The <code>Secret</code> should contain the public key of the Certificate Authority under the key <code>clients-ca.crt</code> and the private key under <code>clients-ca.key</code>.</p>
</li>
<li>
<p>The <code>STRIMZI_ZOOKEEPER_CONNECT</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to a list of the Zookeeper nodes, given as a comma-separated list of <code><em>hostname</em>:‍<em>port</em></code> pairs. This should be the same Zookeeper cluster that your Kafka cluster is using.</p>
</li>
<li>
<p>The <code>STRIMZI_NAMESPACE</code> environment variable in <code>Deployment.spec.template.spec.containers[0].env</code> should be set to the OpenShift or Kubernetes namespace in which you want the operator to watch for  <code>KafkaUser</code> resources.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Deploy the Cluster Operator.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f install/user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f install/user-operator</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the User Operator has been deployed successfully.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc describe</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe deployment strimzi-user-operator</code></pre>
</div>
</div>
<div class="paragraph">
<p>The User Operator is deployed once the <code>Replicas:</code> entry shows <code>1 available</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
This could take some time if you have a slow connection to the OpenShift or Kubernetes and the images have not been downloaded before.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about getting the Cluster Operator to deploy the User Operator for you, see <a href="#proc-deploying-the-user-operator-using-the-cluster-operator-str">Deploying the User Operator using the Cluster Operator</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-the-topic-operator-str">5. Using the Topic Operator</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="topic-operator-usage-recommendations-str">5.1. Topic Operator usage recommendations</h3>
<div class="ulist">
<ul>
<li>
<p>Be consistent and always operate on <code>KafkaTopic</code> resources or always operate on topics directly. Avoid routinely using both methods for a given topic.</p>
</li>
<li>
<p>When creating a <code>KafkaTopic</code> resource:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>Choose a name for the <code>KafkaTopic</code> resource that reflects the name of the topic it describes.</p>
</li>
<li>
<p>Ideally the <code>KafkaTopic.metadata.name</code> should be the same as its <code>spec.topicName</code>. To do this, the topic name will have to be a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>When creating a topic:</p>
<div class="ulist">
<ul>
<li>
<p>Remember that the name cannot be changed later.</p>
</li>
<li>
<p>It is best to use a name that is a <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md" target="_blank" rel="noopener">valid Kubernetes resource name</a>, otherwise the operator will have to modify the name when creating the corresponding <code>KafkaTopic</code>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="creating-a-topic-str">5.2. Creating a topic</h3>
<div class="paragraph">
<p>This procedure describes how to create a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the <code>KafkaTopic</code> to be created</p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 10
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
It is recommended to use a topic name that is a valid OpenShift or Kubernetes resource name. Doing this means that it is not necessary to set the <code>KafkaTopic.spec.topicName</code> property. In any case the <code>KafkaTopic.spec.topicName</code> cannot be changed after creation.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The <code>KafkaTopic.spec.partitions</code> cannot be decreased.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Create the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the standalone Topic Operator, see <a href="#deploying-the-topic-operator-standalone-deploying">Deploying the standalone Topic Operator</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="changing-a-topic-str">5.3. Changing a topic</h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka topic by using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be changed.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a file containing the desired <code>KafkaTopic</code></p>
<div class="listingblock">
<div class="title">An example <code>KafkaTopic</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: orders
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 16
  replicas: 2</code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<div class="title">Tip</div>
</td>
<td class="content">
You can get the current version of the resource using <code>oc get kafkatopic orders -o yaml</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Changing topic names using the <code>KafkaTopic.spec.topicName</code> variable and decreasing partition size using the <code>KafkaTopic.spec.partitions</code> variable is not supported by Kafka.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<div class="title">Caution</div>
</td>
<td class="content">
Increasing <code>spec.partitions</code> for topics with keys will change how records are partitioned, which can be particularly problematic when the topic uses <em>semantic partitioning</em>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Update the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about the schema for <code>KafkaTopics</code>, see <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about deploying a Kafka cluster, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-a-topic-str">5.4. Deleting a topic</h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka topic using a <code>KafkaTopic</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running Topic Operator.</p>
</li>
<li>
<p>An existing <code>KafkaTopic</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaTopic</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkatopic <em>your-topic-name</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkatopic <em>your-topic-name</em></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Whether the topic can actually be deleted depends on the value of the <code>delete.topic.enable</code> Kafka broker configuration, specified in the <code>Kafka.spec.kafka.config</code> property.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying a Kafka cluster using the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Topic Operator using the Cluster Operator, see <a href="#deploying-the-topic-operator-using-the-cluster-operator-str">Deploying the Topic Operator using the Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about creating a topic using the Topic Operator, see <a href="#creating-a-topic-str">Creating a topic</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="assembly-using-the-user-operator-str">6. Using the User Operator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The User Operator provides a way of managing Kafka users via OpenShift or Kubernetes resources.</p>
</div>
<div class="sect2">
<h3 id="con-what-the-user-operator-does-using-uo">6.1. Overview of the User Operator component</h3>
<div class="paragraph">
<p>The User Operator manages Kafka users for a Kafka cluster by watching for <code>KafkaUser</code> OpenShift or Kubernetes resources that describe Kafka users and ensuring that they are configured properly in the Kafka cluster.
For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>if a <code>KafkaUser</code> is created, the User Operator will create the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is deleted, the User Operator will delete the user it describes</p>
</li>
<li>
<p>if a <code>KafkaUser</code> is changed, the User Operator will update the user it describes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Unlike the <a href="#what-the-topic-operator-does-str">Topic Operator</a>, the User Operator does not sync any changes from the Kafka cluster with the OpenShift or Kubernetes resources.
Unlike the Kafka topics which might be created by applications directly in Kafka, it is not expected that the users will be managed directly in the Kafka cluster in parallel with the User Operator, so this should not be needed.</p>
</div>
<div class="paragraph">
<p>The User Operator allows you to declare a <code>KafkaUser</code> as part of your application&#8217;s deployment.
When the user is created, the credentials will be created in a <code>Secret</code>.
Your application needs to use the user and its credentials for authentication and to produce or consume messages.</p>
</div>
<div class="paragraph">
<p>In addition to managing credentials for authentication, the User Operator also manages authorization rules by including a description of the user&#8217;s rights in the <code>KafkaUser</code> declaration.</p>
</div>
</div>
<div class="sect2">
<h3 id="con-mutual-tls-authentication-using-uo">6.2. Mutual TLS authentication for clients</h3>
<div class="sect3">
<h4 id="mutual_tls_authentication_2">6.2.1. Mutual TLS authentication</h4>
<div class="paragraph">
<p>Mutual authentication or two-way authentication is when both the server and the client present certificates. Strimzi can configure Kafka to use TLS (Transport Layer Security) to provide encrypted communication between Kafka brokers and clients either with or without mutual authentication. When you configure mutual authentication, the broker authenticates the client and the client authenticates the broker. Mutual TLS authentication is always used for the communication between Kafka brokers and Zookeeper pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
In many common uses of TLS (such as the HTTPS protocol used between a web browser and a web server) the authentication is not mutual: Only one party to the communication gets proof of the identity of the other party.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>TLS authentication is more commonly one-way, where only one party authenticates to another. For example, when the HTTPS protocol is used between a web browser and a web server, the authentication is not usually mutual and only the server  gets proof of the identity of the browser.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_mutual_tls_authentication_for_clients_2">6.2.2. When to use mutual TLS authentication for clients</h4>
<div class="paragraph">
<p>Mutual TLS authentication is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using mutual TLS authentication</p>
</li>
<li>
<p>It is necessary to use the TLS certificates rather than passwords</p>
</li>
<li>
<p>You can reconfigure and restart client applications periodically so that they do not use expired certificates.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-tls-using-uo">6.3. Creating a Kafka user with mutual TLS authentication</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using TLS authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using TLS see <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">Kafka broker listeners</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="con-scram-sha-authentication-using-uo">6.4. SCRAM-SHA authentication</h3>
<div class="paragraph">
<p>SCRAM (Salted Challenge Response Authentication Mechanism) is an authentication protocol that can establish mutual authentication using passwords. Strimzi can configure Kafka to use SASL SCRMA-SHA-512 to provide authentication on both unencrypted and TLS-encrypted client connections. TLS authentication is always used internally between Kafka brokers and Zookeeper nodes. When used with a TLS client connection, the TLS protocol provides encryption, but is not used for authentication.</p>
</div>
<div class="paragraph">
<p>The following properties of SCRAM make it safe to use SCRAM-SHA even on unencrypted connections:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The passwords are not sent in the clear over the communication channel.
Instead the client and the server are each challenged by the other to offer proof that they know the password of the authenticating user.</p>
</li>
<li>
<p>The server and client each generate a new challenge one each authentication exchange.
This means that the exchange is resilient against replay attacks.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="supported_scram_credentials_2">6.4.1. Supported SCRAM credentials</h4>
<div class="paragraph">
<p>Strimzi supports SCRMA-SHA-512 only.
When a <code>KafkaUser.spec.authentication.type</code> is configured with <code>scram-sha-512</code> the User Operator will generate a random 12 character password consisting of upper and lowercase ASCII letters and numbers.</p>
</div>
</div>
<div class="sect3">
<h4 id="when_to_use_scram_sha_authentication_for_clients_2">6.4.2. When to use SCRAM-SHA authentication for clients</h4>
<div class="paragraph">
<p>SCRAM-SHA is recommended for authenticating Kafka clients when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The client supports authentication using SCRAM-SHA-512</p>
</li>
<li>
<p>It is necessary to use passwords rather than the TLS certificates</p>
</li>
<li>
<p>When you want to have authentication for unencrypted communication</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="proc-creating-kafka-user-scram-using-uo">6.5. Creating a Kafka user with SCRAM SHA authentication</h3>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster configured with a listener using SCRAM SHA authentication.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the <code>KafkaUser</code> to be created.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Create the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the credentials from the secret <code>my-user</code> in your application</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about configuring a listener that authenticates using SCRAM SHA see <a href="#assembly-configuring-kafka-broker-listeners-deployment-configuration-kafka">Kafka broker listeners</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="proc-changing-kafka-user-using-uo">6.6. Editing a Kafka user</h3>
<div class="paragraph">
<p>This procedure describes how to change the configuration of an existing Kafka user by using a <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be changed</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Prepare a YAML file containing the desired <code>KafkaUser</code>.</p>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: literal
        operation: Read</code></pre>
</div>
</div>
</li>
<li>
<p>Update the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f <em>your-file</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc apply</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f <em>your-file</em></code></pre>
</div>
</div>
</li>
<li>
<p>Use the updated credentials from the <code>my-user</code> secret in your application.</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about deploying the Entity Operator, see <a href="#assembly-kafka-entity-operator-deployment-configuration-kafka">Entity Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="deleting-kafka-user-using-uo">6.7. Deleting a Kafka user</h3>
<div class="paragraph">
<p>This procedure describes how to delete a Kafka user created with <code>KafkaUser</code> OpenShift or Kubernetes resource.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>A running Kafka cluster.</p>
</li>
<li>
<p>A running User Operator.</p>
</li>
<li>
<p>An existing <code>KafkaUser</code> to be deleted.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Delete the <code>KafkaUser</code> resource in OpenShift or Kubernetes.</p>
<div class="paragraph">
<p>On Kubernetes this can be done using <code>kubectl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl delete kafkauser <em>your-user-name</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using <code>oc</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc delete kafkauser <em>your-user-name</em></code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For more information about deploying the Cluster Operator, see <a href="#cluster-operator-str">Cluster Operator</a>.</p>
</li>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="ref-kafka-user-using-uo">6.8. Kafka User resource</h3>
<div class="paragraph">
<p>The <code>KafkaUser</code> resource is used to declare a user with its authentication mechanism, authorization mechanism, and access rights.</p>
</div>
<div class="sect3">
<h4 id="authentication">6.8.1. Authentication</h4>
<div class="paragraph">
<p>Authentication is configured using the <code>authentication</code> property in <code>KafkaUser.spec</code>.
The authentication mechanism enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authentication mechanisms are the TLS Client Authentication mechanism and the SCRAM-SHA-512 mechanism.</p>
</div>
<div class="paragraph">
<p>When no authentication mechanism is specified, User Operator will not create the user or its credentials.</p>
</div>
<div class="sect4">
<h5 id="tls_client_authentication_5">TLS Client Authentication</h5>
<div class="paragraph">
<p>To use TLS client authentication, set the <code>type</code> field to <code>tls</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>KafkaUser</code> with enabled TLS Client Authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: tls
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the user is created by the User Operator, it will create a new secret with the same name as the <code>KafkaUser</code> resource.
The secret will contain a public and private key which should be used for the TLS Client Authentication.
Bundled with them will be the public key of the client certification authority which was used to sign the user certificate.
All keys will be in X509 format.</p>
</div>
<div class="listingblock">
<div class="title">An example of the <code>Secret</code> with user credentials</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: my-user
  labels:
    strimzi.io/kind: KafkaUser
    strimzi.io/cluster: my-cluster
type: Opaque
data:
  ca.crt: # Public key of the Clients CA
  user.crt: # Public key of the user
  user.key: # Private key of the user</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="scram_sha_512_authentication_4">SCRAM-SHA-512 Authentication</h5>
<div class="paragraph">
<p>To use SCRAM-SHA-512 authentication mechanism, set the <code>type</code> field to <code>scram-sha-512</code>.</p>
</div>
<div class="listingblock">
<div class="title">An example of <code>KafkaUser</code> with enabled SCRAM-SHA-512 authentication</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  authentication:
    type: scram-sha-512
  # ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the user is created by the User Operator, the User Operator will create a new secret with the same name as the <code>KafkaUser</code> resource.
The secret will contain the generated password.</p>
</div>
<div class="listingblock">
<div class="title">An example of the <code>Secret</code> with user credentials</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: my-user
  labels:
    strimzi.io/kind: KafkaUser
    strimzi.io/cluster: my-cluster
type: Opaque
data:
  password: # Generated password</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="authorization">6.8.2. Authorization</h4>
<div class="paragraph">
<p>Authorization is configured using the <code>authorization</code> property in <code>KafkaUser.spec</code>.
The authorization type enabled for this user will be specified using the <code>type</code> field.
Currently, the only supported authorization type is the Simple authorization.</p>
</div>
<div class="paragraph">
<p>When no authorization is specified, the User Operator will not provision any access rights for the user.</p>
</div>
<div class="sect4">
<h5 id="simple_authorization_2">Simple Authorization</h5>
<div class="paragraph">
<p>To use Simple Authorization, set the <code>type</code> property to <code>simple</code>.
Simple authorization is using the <code>SimpleAclAuthorizer</code> plugin.
<code>SimpleAclAuthorizer</code> is the default authorization plugin which is part of Apache Kafka.
Simple Authorization allows you to specify list of ACL rules in the <code>acls</code> property.</p>
</div>
<div class="paragraph">
<p>The <code>acls</code> property should contain a list of <code>AclRule</code> objects.
<code>AclRule</code> specifies the access rights whcih will be granted to the user.
The <code>AclRule</code> object contains following properties:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>type</code></dt>
<dd>
<p>Specifies the type of the ACL rule.
The type can be either <code>allow</code> or <code>deny</code>.
The <code>type</code> field is optional and when not specified, the ACL rule will be treated as <code>allow</code> rule.</p>
</dd>
<dt class="hdlist1"><code>operation</code></dt>
<dd>
<p>Specifies the operation which will be allowed or denied.
Following operations are supported:</p>
<div class="ulist">
<ul>
<li>
<p>Read</p>
</li>
<li>
<p>Write</p>
</li>
<li>
<p>Delete</p>
</li>
<li>
<p>Alter</p>
</li>
<li>
<p>Describe</p>
</li>
<li>
<p>All</p>
</li>
<li>
<p>IdempotentWrite</p>
</li>
<li>
<p>ClusterAction</p>
</li>
<li>
<p>Create</p>
</li>
<li>
<p>AlterConfigs</p>
</li>
<li>
<p>DescribeConfigs</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Not every operation can be combined with every resource.
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1"><code>host</code></dt>
<dd>
<p>Specifies a remote host from which is the rule allowed or denied.
Use <code>*</code> to allow or deny the operation from all hosts.
The <code>host</code> field is optional and when not specified, the value <code>*</code> will be used as default.</p>
</dd>
<dt class="hdlist1"><code>resource</code></dt>
<dd>
<p>Specifies the resource for which does the rule apply.
Simple Authorization supports 3 different resource types:</p>
<div class="ulist">
<ul>
<li>
<p>Topics</p>
</li>
<li>
<p>Consumer Groups</p>
</li>
<li>
<p>Clusters</p>
<div class="paragraph">
<p>The resource type can be specified in the <code>type</code> property.
Use <code>topic</code> for Topics, <code>group</code> for Consumer Groups and <code>cluster</code> for clusters.</p>
</div>
<div class="paragraph">
<p>Topic and Group resources additionally allow to specify the name of the resource for which the rule applies.
The name can be specified in the <code>name</code> property.
The name can be either specified as literal or as a prefix.
To specify the name as literal, set the <code>patternType</code> property to the value <code>literal</code>.
Literal names will be taken exactly as they are specified in the <code>name</code> field.
To specify the name as a prefix, set the <code>patternType</code> property to the value <code>prefix</code>.
Prefix type names will use the value from the <code>name</code> only a prefix and will apply the rule to all resources with names starting with the value.
The cluster type resources have no name.</p>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>For more details about <code>SimpleAclAuthorizer</code>, its ACL rules and the allowed combinations of resources and operations, see <a href="http://kafka.apache.org/documentation/#security_authz" target="_blank" rel="noopener">Authorization and ACLs</a>.</p>
</div>
<div class="paragraph">
<p>For more information about the <code>AclRule</code> object, see <a href="#type-AclRule-reference"><code>AclRule</code> schema reference</a>.</p>
</div>
<div class="listingblock">
<div class="title">An example <code>KafkaUser</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: my-user
  labels:
    strimzi.io/cluster: my-cluster
spec:
  # ...
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Read
      - resource:
          type: topic
          name: my-topic
          patternType: literal
        operation: Describe
      - resource:
          type: group
          name: my-group
          patternType: prefix
        operation: Read</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="additional_resources_5">6.8.3. Additional resources</h4>
<div class="ulist">
<ul>
<li>
<p>For more information about the <code>KafkaUser</code> object, see <a href="#type-KafkaUser-reference"><code>KafkaUser</code> schema reference</a>.</p>
</li>
<li>
<p>For more information about the TLS Client Authentication, see <a href="#con-mutual-tls-authentication-using-uo">Mutual TLS authentication for clients</a>.</p>
</li>
<li>
<p>For more information about the SASL SCRAM-SHA-512 authentication, see <a href="#con-scram-sha-authentication-using-uo">SCRAM-SHA authentication</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="security-str">7. Security</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Strimzi supports encrypted communication between the Kafka and Strimzi components using the TLS protocol.
Communication between Kafka brokers (interbroker communication), between Zookeeper nodes (internodal communication), and between these and the Strimzi operators is always encrypted.
Communication between Kafka clients and Kafka brokers is encrypted according to how the cluster is configured.
For the Kafka and Strimzi components, TLS certificates are also used for authentication.</p>
</div>
<div class="paragraph">
<p>The Cluster Operator automatically sets up TLS certificates to enable encryption and authentication within your cluster.
It also sets up other TLS certificates if you want to enable encryption or TLS authentication between Kafka brokers and clients.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/secure_communication.png" alt="Secure Communication">
</div>
<div class="title">Figure 3. Example architecture diagram of the communication secured by TLS.</div>
</div>
<div class="sect2">
<h3 id="certificate-authorities-str">7.1. Certificate Authorities</h3>
<div class="paragraph">
<p>To support encryption, each {ProductName] component needs its own private keys and public key certificates.
All component certificates are signed by a Certificate Authority (CA) called the <em>cluster CA</em>.</p>
</div>
<div class="paragraph">
<p>Similarly, each Kafka client application connecting using TLS client authentication needs private keys and certificates.
The <em>clients CA</em> is used to sign the certificates for the Kafka clients.</p>
</div>
<div class="sect3">
<h4 id="ca_certificates">7.1.1. CA certificates</h4>
<div class="paragraph">
<p>Each CA has a self-signed public key certificate.</p>
</div>
<div class="paragraph">
<p>Kafka brokers are configured to trust certificates signed by either the clients CA or the cluster CA. Components to which clients do not need to connect, such as Zookeeper, only trust certificates signed by the cluster CA. Client applications that perform mutual TLS authentication have to trust the certificates signed by the cluster CA.</p>
</div>
<div class="paragraph">
<p>By default, Strimzi generates and renews CA certificates automatically. You can configure the management of CA certificates in the <code>Kafka.spec.clusterCa</code> and <code>Kafka.spec.clientsCa</code> objects.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="certificates-and-secrets-str">7.2. Certificates and <code>Secrets</code></h3>
<div class="paragraph">
<p>Strimzi stores CA, component and Kafka client private keys and certificates in <code>Secrets</code>.
All keys are 2048 bits in size.</p>
</div>
<div class="paragraph">
<p>CA certificate validity periods, expressed as a number of days after certificate generation, can be configured in <code>Kafka.spec.clusterCa.validityDays</code>
and <code>Kafka.spec.clusterCa.validityDays</code>.</p>
</div>
<div class="sect3">
<h4 id="cluster_ca_secrets">7.2.1. Cluster CA <code>Secrets</code></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Cluster CA <code>Secrets</code> managed by the Cluster Operator in <em>&lt;cluster&gt;</em></caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-cluster-ca</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current private key for the cluster CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current certificate for the cluster CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca-<em>&lt;date&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Former (but not yet expired) certificate for the cluster CA. <code><em>&lt;date&gt;</em></code> is the date the certificate will expire.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-brokers</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-<em>&lt;num&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for Kafka broker pod <em>&lt;num&gt;</em>. Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-kafka-<em>&lt;num&gt;</em>.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for Kafka broker pod <em>&lt;num&gt;</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-nodes</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-<em>&lt;num&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for Zookeeper node <em>&lt;num&gt;</em>. Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-zookeeper-<em>&lt;num&gt;</em>.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for Zookeeper pod <em>&lt;num&gt;</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-entity-operator-certs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>entity-operator_.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for TLS communication between the Entity Operator and Kafka or Zookeeper.
                                   Signed by a current or former cluster CA private key in <code><em>&lt;cluster&gt;</em>-cluster-ca</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>entity-operator.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for TLS communication between the Entity Operator and Kafka or Zookeeper</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The CA certificates in <code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> must be trusted by Kafka client applications so that they validate the Kafka broker certificates when connecting to Kafka brokers over TLS.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
Only <code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> needs to be used by clients.
All other <code>Secrets</code> in the table above only need to be accessed by the
 Strimzi components.
 You can enforce this using OpenShift or Kubernetes role-based access controls if necessary.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="client_ca_secrets">7.2.2. Client CA <code>Secrets</code></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Clients CA <code>Secrets</code> managed by the Cluster Operator in <em>&lt;cluster&gt;</em></caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-clients-ca</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current private key for the clients CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;cluster&gt;</em>-clients-ca-cert</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The current certificate for the clients CA.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ca-<em>&lt;date&gt;</em>.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Former (but not yet expired) certificate for the clients CA. <code><em>&lt;date&gt;</em></code> is the date the certificate will expire.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The certificates in <code><em>&lt;cluster&gt;</em>-clients-ca-cert</code> are those which the Kafka brokers trust.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<code><em>&lt;cluster&gt;</em>-cluster-ca</code> is used to sign certificates of client applications.
It needs to be accessible to the Strimzi components and for administrative access if you are intending to issue application certificates without using the User Operator.
You can enforce this using OpenShift or Kubernetes role-based access controls if necessary.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="user_secrets">7.2.3. User <code>Secrets</code></h4>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. <code>Secrets</code> managed by the User Operator</caption>
<colgroup>
<col style="width: 30%;">
<col style="width: 20%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><code>Secret</code> name</th>
<th class="tableblock halign-left valign-top">Field within <code>Secret</code></th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock"><code><em>&lt;user&gt;</em></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>user.crt</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Certificate for the user, signed by the clients CA</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>user.key</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Private key for the user</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="installing-your-own-ca-certificates-str">7.3. Installing your own CA certificates</h3>
<div class="paragraph">
<p>This procedure describes how to install your own CA certificates and private keys instead of using CA certificates and private keys generated by the Cluster Operator.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource within OpenShift or Kubernetes</p>
</li>
<li>
<p>Your own X.509 certificates and keys in PEM format for the cluster CA or clisters CA. For example, these could be generated by <code>openssl</code>, using a command such as:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">openssl req -x509 -new -days <em>&lt;validity&gt;</em> --nodes -out ca.crt -keyout ca.key</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Edit the <code>Kafka</code> resource for your cluster, configuring either the <code>Kafka.spec.clusterCa</code> or the <code>Kafka.spec.clientsCa</code> object to <em>not</em> use generated CAs:</p>
<div class="listingblock">
<div class="title">Example fragment <code>Kafka</code> resource configuring the cluster CA to use certificates you supply for yourself</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kind: Kafka
version: v1alpha1
spec:
  # ...
  clusterCa:
    generateCertificateAuthority: false</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will prevent the Cluster Operator from generating a new CA. It will not disable an existing generated CA.</p>
</div>
</li>
<li>
<p>Put your CA certificate in the corresponding <code>Secret</code> (<code><em>&lt;cluster&gt;</em>-cluster-ca-cert</code> for the cluster CA or <code><em>&lt;cluster&gt;</em>-client-ca-cert</code> for the clients CA):</p>
<div class="paragraph">
<p>On Kubernetes, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete any existing secret (ignore "Not Exists" errors)
kubectl delete secret <em>&lt;ca-cert-secret&gt;</em>
# Create the new one
kubectl create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=ca.crt=<em>&lt;ca-cert-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete any existing secret (ignore "Not Exists" errors)
oc delete secret <em>&lt;ca-cert-secret&gt;</em>
# Create the new one
oc create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=ca.crt=<em>&lt;ca-cert-file&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Put your CA key in the corresponding <code>Secret</code> (<code><em>&lt;cluster&gt;</em>-cluster-ca</code> for the cluster CA or <code><em>&lt;cluster&gt;</em>-client-ca</code> for the clients CA)</p>
<div class="paragraph">
<p>On Kubernetes, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
kubectl delete secret <em>&lt;ca-key-secret&gt;</em>
# Create the new one
kubectl create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
oc delete secret <em>&lt;ca-key-secret&gt;</em>
# Create the new one
oc create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For the procedure for renewing CA certificates you have previousy installed, see <a href="#renewing-your-own-ca-certificates-str">Renewing your own CA certificates</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="con-certificate-renewal-str">7.4. Certificate renewal</h3>
<div class="paragraph">
<p>The cluster CA and clients CA certificates are only valid for a limited time period, known as the validity period.
This is usually defined as a number of days since the certificate was generated.
For auto-generated CA certificates, you can configure the validity period in <code>Kafka.spec.clusterCa.validityDays</code> and <code>Kafka.spec.clientsCa.validityDays</code>.
The default validity period for both certificates is 365 days.
Manually-installed CA certificates should have their own validity period defined.</p>
</div>
<div class="paragraph">
<p>When a CA certificate expires, the certificates that it has signed will fail validation, even if they were previously valid.
This means that, when replacing a CA certificate, you must also replace all other certificates signed by it.
When the replacement of a CA certificate is in progress, it is necessary for peers to trust certificates signed by either the old or the new CA.
This ensures the continued operation of the cluster.</p>
</div>
<div class="paragraph">
<p>To allow the renewal of CA certificates without a loss of service, the Cluster Operator will initiate certificate renewal before the old CA certificates expire.
You can configure the renewal period in <code>Kafka.spec.clusterCa.renewalDays</code> and <code>Kafka.spec.clientsCa.renewalDays</code> (both default to 30 days).
The renewal period is measured backwards, from the expiry date of the current certificate.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Not Before                                     Not After
    |                                              |
    |&lt;--------------- validityDays ---------------&gt;|
                              &lt;--- renewalDays ---&gt;|</code></pre>
</div>
</div>
<div class="paragraph">
<p>The behavior of the Cluster Operator during the renewal period depends on whether the relevant setting is enabled, in either <code>Kafka.spec.clusterCa.generateCertificateAuthority</code> or <code>Kafka.spec.clientsCa.generateCertificateAuthority</code>.</p>
</div>
<div class="sect3">
<h4 id="renewal_process_with_generated_cas">7.4.1. Renewal process with generated CAs</h4>
<div class="paragraph">
<p>The Cluster Operator performs the following process to renew CA certificates:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Generate a new CA key and certificate. The new private key replaces the old private key in the corresponding <code>Secret</code>. The new certificate is given the name <code>ca.crt</code> within the corresponding <code>Secret</code> and the old certificate is renamed <code>ca-<em>&lt;expiry-date&gt;</em>.crt</code>.</p>
</li>
<li>
<p>Restart Zookeeper nodes so that they will trust the new CA certificate.</p>
</li>
<li>
<p>Restart Kafka brokers so that they will trust the new CA certificate.</p>
</li>
<li>
<p>Restart the Topic and User Operators so that they will trust the new CA certificate.</p>
</li>
<li>
<p>Generate new client certificates (for Zookeeper nodes, Kafka brokers, and the entity operator) signed by the new CA.</p>
</li>
<li>
<p>Perform the same restarts so that clients are using certificates signed by the new CA certificate.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>At the end of the renewal period the Cluster Operator will remove the now expired CA certificates (those named <code>ca-<em>&lt;expiry-date&gt;</em>.crt</code>) from the corresponding <code>Secret</code> and perform a further round of restarts.</p>
</div>
</div>
<div class="sect3">
<h4 id="renewal_process_with_your_own_ca_certificates">7.4.2. Renewal process with your own CA certificates</h4>
<div class="paragraph">
<p>At the start of the renewal period the Cluster Operator will start logging at the <code>WARN</code> level that new CA certificates and keys are needed.
Once you have provided the new certificates and keys, the Cluster Operator performs a further set of restarts within the Kafka cluster for which the warning was issued.</p>
</div>
</div>
<div class="sect3">
<h4 id="client_applications">7.4.3. Client applications</h4>
<div class="paragraph">
<p>The Cluster Operator is not aware of all the client applications using the Kafka cluster.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
Depending on how your applications are configured, you might need take action to ensure they continue working after certificate renewal.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Consider the following important points to ensure that client applications continue working.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>When they connect to the cluster, client applications must trust <em>all</em> the cluster CA certificates published in <em>&lt;cluster&gt;</em>-cluster-ca-certs.</p>
</li>
<li>
<p>When using the User Operator to provision client certificates, client applications must use the current <code>user.crt</code> and <code>user.key</code> published in their <code><em>&lt;user&gt;</em></code> <code>Secret</code> when they connect to the cluster.
For workloads running inside the same OpenShift or Kubernetes cluster this can be achieved by mounting the secrets as a volume and having the client Pods construct their key- and truststores from the current state of the <code>Secrets</code>.
For more details on this procedure, see <a href="#configuring-internal-clients-to-trust-cluster-ca-str">Configuring internal clients to trust the cluster CA</a>.</p>
</li>
<li>
<p>When renewing client certificates, if you are provisioning client certificates and keys manually, you must generate new client certificates and ensure the new certificates are used by clients within the renewal period. Failure to do this by the end of the renewal period could result in client applications being unable to connect.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="renewing-your-own-ca-certificates-str">7.5. Renewing your own CA certificates</h3>
<div class="paragraph">
<p>This procedure describes how to renew CA certificates and private keys that you previously installed.
You will need to follow this procedure during the renewal period in order to replace CA certificates which will soon expire.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A Kafka cluster in which you previously installed your own CA certificates and private keys.</p>
</li>
<li>
<p>New cluster and clients X.509 certificates and keys in PEM format. These could be generated using <code>openssl</code> using a command such as:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">openssl req -x509 -new -days <em>&lt;validity&gt;</em> --nodes -out ca.crt -keyout ca.key</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Establish what CA certificates already exist in the <code>Secret</code>:</p>
<div class="paragraph">
<p>On Kubernetes this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl describe secret <em>&lt;ca-cert-secret&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc describe secret <em>&lt;ca-cert-secret&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Prepare a directory containing the existing CA certificates in the secret.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">mkdir new-ca-cert-secret
cd new-ca-cert-secret</code></pre>
</div>
</div>
<div class="paragraph">
<p>On Kubernetes for each certificate <em>&lt;ca-certificate&gt;</em> from the previous step, run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Fetch the existing secret
kubectl get secret <em>&lt;ca-cert-secret&gt;</em> -o 'jsonpath={.data.<em>&lt;ca-certificate&gt;</em>}' | base64 -d &gt; <em>&lt;ca-certificate&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift for each certificate <em>&lt;ca-certificate&gt;</em> from the previous step, run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Fetch the existing secret
oc get secret <em>&lt;ca-cert-secret&gt;</em> -o 'jsonpath={.data.<em>&lt;ca-certificate&gt;</em>}' | base64 -d &gt; <em>&lt;ca-certificate&gt;</em></code></pre>
</div>
</div>
</li>
<li>
<p>Rename the old <code>ca.crt</code> file to <code>ca_&lt;date&gt;_.crt</code>, where <em>&lt;date&gt;</em> is the certificate expiry date in the format <em>&lt;year&gt;</em>-<em>&lt;month&gt;</em>-<em>&lt;day&gt;_T</em>&lt;hour&gt;_-<em>&lt;minute&gt;</em>-_&lt;second&gt;_Z, for example <code>ca-2018-09-27T17-32-00Z.crt</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">mv ca.crt ca-$(date -u -d$(openssl x509 -enddate -noout -in ca.crt | sed 's/.*=//') +'%Y-%m-%dT%H-%M-%SZ').crt</code></pre>
</div>
</div>
</li>
<li>
<p>Copy the new CA certificate into the directory, naming it <code>ca.crt</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cp <em>&lt;path-to-new-cert&gt;</em> ca.crt</code></pre>
</div>
</div>
</li>
<li>
<p>Replace the CA certificate <code>Secret</code>  (<code><em>&lt;cluster&gt;</em>-cluster-ca</code> or <code><em>&lt;cluster&gt;</em>-clients-ca</code>).</p>
<div class="paragraph">
<p>On OpenShift this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
kubectl delete secret <em>&lt;ca-cert-secret&gt;</em>
# Re-create the secret with the new private key
kubectl create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=.</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
oc delete secret <em>&lt;ca-cert-secret&gt;</em>
# Re-create the secret with the new private key
oc create secret generic <em>&lt;ca-cert-secret&gt;</em> --from-file=.</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can now delete the directory you created:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">cd ..
rm -r new-ca-cert-secret</code></pre>
</div>
</div>
</li>
<li>
<p>Replace the CA key <code>Secret</code> (<code><em>&lt;cluster&gt;</em>-cluster-ca</code> or <code><em>&lt;cluster&gt;</em>-clients-ca</code>).</p>
<div class="paragraph">
<p>On Kubernetes this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
kubectl delete secret <em>&lt;ca-key-secret&gt;</em>
# Re-create the secret with the new private key
kubectl create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift this can be done using the following commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Delete the existing secret
oc delete secret <em>&lt;ca-key-secret&gt;</em>
# Re-create the secret with the new private key
oc create secret generic <em>&lt;ca-key-secret&gt;</em> --from-file=ca.key=<em>&lt;ca-key-file&gt;</em></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="tls-connections-str">7.6. TLS connections</h3>
<div class="sect3">
<h4 id="zookeeper_communication">7.6.1. Zookeeper communication</h4>
<div class="paragraph">
<p>Zookeeper does not support TLS itself.
By deploying an <code>stunnel</code> sidecar within every Zookeeper pod, the Cluster Operator is able to provide data encryption and authentication between Zookeeper nodes in a cluster.
Zookeeper communicates only with the <code>stunnel</code> sidecar over the loopback interface.
The <code>stunnel</code> sidecar then proxies all Zookeeper traffic, TLS decrypting data upon entry into a Zookeeper pod and TLS encrypting data upon departure from a Zookeeper pod.</p>
</div>
<div class="paragraph">
<p>This TLS encrypting <code>stunnel</code> proxy is instantiated from the <code>spec.zookeeper.stunnelImage</code> specified in the Kafka resource.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka_interbroker_communication">7.6.2. Kafka interbroker communication</h4>
<div class="paragraph">
<p>Communication between Kafka brokers is done through the <code>REPLICATION</code> listener on port 9091, which is encrypted by default.</p>
</div>
<div class="paragraph">
<p>Communication between Kafka brokers and Zookeeper nodes uses an <code>stunnel</code> sidecar, as described above.</p>
</div>
</div>
<div class="sect3">
<h4 id="topic_and_user_operators">7.6.3. Topic and User Operators</h4>
<div class="literalblock">
<div class="content">
<pre>Like the Cluster Operator, the Topic and User Operators each use an `stunnel` sidecar when communicating with Zookeeper.
The Topic Operator connects to Kafka brokers on port 9091.</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="kafka_client_connections">7.6.4. Kafka Client connections</h4>
<div class="paragraph">
<p>Encrypted communication between Kafka brokers and clients running within the same OpenShift or Kubernetes cluster is provided through the <code>CLIENTTLS</code> listener on port 9093.</p>
</div>
<div class="paragraph">
<p>Encrypted communication between Kafka brokers and clients running outside the same OpenShift or Kubernetes cluster is provided through the <code>EXTERNAL</code> listener on port 9094.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
You can use the <code>CLIENT</code> listener on port 9092 for unencrypted communication with brokers.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="configuring-internal-clients-to-trust-cluster-ca-str">7.7. Configuring internal clients to trust the cluster CA</h3>
<div class="paragraph">
<p>This procedure describes how to configure a Kafka client that resides inside the OpenShift or Kubernetes cluster — connecting to the <code>tls</code> listener on port 9093 — to trust the cluster CA certificate.</p>
</div>
<div class="paragraph">
<p>The easiest way to achieve this for an internal client is to use a volume mount to access the <code>Secrets</code> containing the necessary certificates and keys.</p>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource within the OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>A Kafka client application inside the OpenShift or Kubernetes cluster which will connect using TLS and needs to trust the cluster CA certificate.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>When defining the client <code>Pod</code></p>
</li>
<li>
<p>The Kafka client has to be configured to trust certificates signed by this CA.
For the Java-based Kafka Producer, Consumer, and Streams APIs, you can do this by importing the CA certificate into the JVM&#8217;s truststore using the following <code>keytool</code> command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">keytool -keystore client.truststore.jks -alias CARoot -import -file ca.crt</code></pre>
</div>
</div>
</li>
<li>
<p>To configure the Kafka client, specify the following properties:</p>
<div class="ulist">
<ul>
<li>
<p><code>security.protocol: SSL</code> when using TLS for encryption (with or without TLS authentication), or <code>security.protocol: SASL_SSL</code> when using SCRAM-SHA authentication over TLS.</p>
</li>
<li>
<p><code>ssl.truststore.location</code>: the truststore location where the certificates were imported.</p>
</li>
<li>
<p><code>ssl.truststore.password</code>: the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For the procedure for configuring external clients to trust the cluster CA, see <a href="#configuring-external-clients-to-trust-cluster-ca-str">Configuring external clients to trust the cluster CA</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="configuring-external-clients-to-trust-cluster-ca-str">7.8. Configuring external clients to trust the cluster CA</h3>
<div class="paragraph">
<p>This procedure describes how to configure a Kafka client that resides outside the OpenShift or Kubernetes cluster – connecting to the <code>external</code> listener on port 9094 – to trust the cluster CA certificate.</p>
</div>
<div class="paragraph">
<p>You can use the same procedure to configure clients inside OpenShift or Kubernetes, which connect to the <code>tls</code> listener on port 9093, but it is usually more convenient to access the <code>Secrets</code> using a volume mount in the client <code>Pod</code>.</p>
</div>
<div class="paragraph">
<p>Follow this procedure when setting up the client and during the renewal period, when the old clients CA certificate is replaced.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<div class="title">Important</div>
</td>
<td class="content">
The <code><em>&lt;cluster-name&gt;</em>-cluster-ca-cert</code> <code>Secret</code> will contain more than one CA certificate during CA certificate renewal. Clients must add <em>all</em> of them to their truststores.
</td>
</tr>
</table>
</div>
<div class="ulist">
<div class="title">Prerequisites</div>
<ul>
<li>
<p>The Cluster Operator is running.</p>
</li>
<li>
<p>A <code>Kafka</code> resource within the OpenShift or Kubernetes cluster.</p>
</li>
<li>
<p>A Kafka client application outside the OpenShift or Kubernetes cluster which will connect using TLS and needs to trust the cluster CA certificate.</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">Procedure</div>
<ol class="arabic">
<li>
<p>Extract the cluster CA certificates from the generated <code><em>&lt;cluster-name&gt;</em>-cluster-ca-cert</code> <code>Secret</code>.</p>
<div class="paragraph">
<p>On Kubernetes, run the following command to extract the certificates:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl get secret <em>&lt;cluster-name&gt;</em>-cluster-ca-cert -o jsonpath='{.data.ca\.crt}' | base64 -d &gt; ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>On OpenShift, run the following command to extract the certificates:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc extract secret/<em>&lt;cluster-name&gt;</em>-cluster-ca-cert --keys ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Execute the same command for every <code>.crt</code> file contained in the <code>Secret</code>.</p>
</div>
</li>
<li>
<p>The Kafka client has to be configured to trust certificates signed by this CA.
For the Java-based Kafka Producer, Consumer, and Streams APIs, you can do this by importing the CA certificates into the JVM&#8217;s truststore using the following <code>keytool</code> command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">keytool -keystore client.truststore.jks -alias CARoot -import -file ca.crt</code></pre>
</div>
</div>
<div class="paragraph">
<p>The same command should be executed for each of the <code>.crt</code> files extracted in the first step.</p>
</div>
</li>
<li>
<p>To configure the Kafka client, specify the following properties:</p>
<div class="ulist">
<ul>
<li>
<p><code>security.protocol: SSL</code> when using TLS for encryption (with or without TLS authentication), or <code>security.protocol: SASL_SSL</code> when using SCRAM-SHA authentication over TLS.</p>
</li>
<li>
<p><code>ssl.truststore.location</code>: the truststore location where the certificates were imported.</p>
</li>
<li>
<p><code>ssl.truststore.password</code>: the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">Additional resources</div>
<ul>
<li>
<p>For the procedure for configuring internal clients to trust the cluster CA, see <a href="#configuring-internal-clients-to-trust-cluster-ca-str">Configuring internal clients to trust the cluster CA</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="frequently_asked_questions">Appendix A: Frequently Asked Questions</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="cluster_operator">A.1. Cluster Operator</h3>
<div class="sect3">
<h4 id="log_contains_warnings_about_failing_to_acquire_lock">A.1.1. Log contains warnings about failing to acquire lock</h4>
<div class="paragraph">
<p>For each cluster, the Cluster Operator always executes only one operation at a time. The Cluster Operator uses locks
to make sure that there are never two parallel operations running for the same cluster. In case an operation requires
more time to complete, other operations will wait until it is completed and the lock is released.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">INFO</dt>
<dd>
<p>Examples of cluster operations are <em>cluster creation</em>, <em>rolling update</em>, <em>scale down</em> or <em>scale up</em> and so on.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>If the wait for the lock takes too long, the operation times out and the following warning message will be printed to
the log:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">2018-03-04 17:09:24 WARNING AbstractClusterOperations:290 - Failed to acquire lock for kafka cluster lock::kafka::myproject::my-cluster</code></pre>
</div>
</div>
<div class="paragraph">
<p>Depending on the exact configuration of <code>STRIMZI_FULL_RECONCILIATION_INTERVAL_MS</code> and <code>STRIMZI_OPERATION_TIMEOUT_MS</code>, this
warning message may appear regularly without indicating any problems. The operations which time out will be picked up by
the next periodic reconciliation. It will try to acquire the lock again and execute.</p>
</div>
<div class="paragraph">
<p>Should this message appear periodically even in situations when there should be no other operations running for a given
cluster, it might indicate that due to some error the lock was not properly released. In such cases it is recommended to
restart the cluster operator.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installing_kubernetes_and_openshift_cluster">Appendix B: Installing OpenShift or Kubernetes cluster</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The easiest way to get started with OpenShift or Kubernetes is using the <code>Minikube</code>, <code>Minishift</code> or <code>oc cluster up</code>
utilities. This section provides basic guidance on how to use them. More details are provided on the websites of
the tools themselves.</p>
</div>
<div class="sect2">
<h3 id="kubernetes">B.1. Kubernetes</h3>
<div class="paragraph">
<p>In order to interact with a Kubernetes cluster the <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"><code>kubectl</code></a>
utility needs to be installed.</p>
</div>
<div class="paragraph">
<p>The easiest way to get a running Kubernetes cluster is using <code>Minikube</code>. <code>Minikube</code> can be downloaded and installed
from the <a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Kubernetes website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minikube</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, it can be started using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minikube start --memory 4096</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="openshift">B.2. OpenShift</h3>
<div class="paragraph">
<p>In order to interact with an OpenShift cluster, the <a href="https://github.com/openshift/origin/releases"><code>oc</code></a> utility is needed.</p>
</div>
<div class="paragraph">
<p>An OpenShift cluster can be started in two different ways. The <code>oc</code> utility can start a cluster locally using the
command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc cluster up</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command requires Docker to be installed. More information about this way can be found
<a href="https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md">here</a>.</p>
</div>
<div class="paragraph">
<p>Another option is to use <code>Minishift</code>. <code>Minishift</code> is an OpenShift installation within a VM. It can be downloaded and
installed from the <a href="https://docs.openshift.org/latest/minishift/index.html">Minishift website</a>. Depending on the number of brokers
you want to deploy inside the cluster and if you need Kafka Connect running as well, it could be worth running <code>Minishift</code>
at least with 4 GB of RAM instead of the default 2 GB.
Once installed, <code>Minishift</code> can be started using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">minishift start --memory 4GB</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="api_reference-str">Appendix C: Custom Resource API Reference</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="type-Kafka-reference">C.1. <code>Kafka</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka and Zookeeper clusters, and Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaSpec-reference">C.2. <code>KafkaSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-Kafka-reference"><code>Kafka</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kafka</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Zookeeper cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">clientsCa</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the clients certificate authority.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertificateAuthority-reference"><code>CertificateAuthority</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">clusterCa</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the cluster certificate authority.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertificateAuthority-reference"><code>CertificateAuthority</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">entityOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Entity Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaClusterSpec-reference">C.3. <code>KafkaClusterSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">listeners</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures listeners of Kafka brokers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization configuration for Kafka brokers. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaAuthorizationSimple-reference"><code>KafkaAuthorizationSimple</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The kafka broker config. Properties with the following prefixes cannot be set: listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer., super.user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rack</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the <code>broker.rack</code> broker config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Rack-reference"><code>Rack</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">brokerRackInitImage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image of the init container used for initializing the <code>broker.rack</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EphemeralStorage-reference">C.4. <code>EphemeralStorage</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>EphemeralStorage</code> from <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a>.
It must have the value <code>ephemeral</code> for the type <code>EphemeralStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>ephemeral</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PersistentClaimStorage-reference">C.5. <code>PersistentClaimStorage</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>PersistentClaimStorage</code> from <a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>.
It must have the value <code>persistent-claim</code> for the type <code>PersistentClaimStorage</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>persistent-claim</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">selector</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies a specific persistent volume to use. It contains a matchLabels field which defines an inner JSON object with key:value representing labels for selecting such a volume.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteClaim</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">class</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The storage class to use for dynamic volume allocation.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListeners-reference">C.6. <code>KafkaListeners</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">plain</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures plain listener on port 9092.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures TLS listener on port 9093.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">external</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configures external listener on port 9094. The type depends on the value of the <code>external.type</code> property within the given object, which must be one of [route, loadbalancer, nodeport].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerPlain-reference">C.7. <code>KafkaListenerPlain</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with <code>type: tls</code>. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationTls-reference">C.8. <code>KafkaListenerAuthenticationTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationTls</code> from <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaListenerAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerAuthenticationScramSha512-reference">C.9. <code>KafkaListenerAuthenticationScramSha512</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>, <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerPlain-reference"><code>KafkaListenerPlain</code></a>, <a href="#type-KafkaListenerTls-reference"><code>KafkaListenerTls</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerAuthenticationScramSha512</code> from <a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaListenerAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerTls-reference">C.10. <code>KafkaListenerTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for this listener. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalRoute-reference">C.11. <code>KafkaListenerExternalRoute</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalRoute</code> from <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>route</code> for the type <code>KafkaListenerExternalRoute</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>route</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalLoadBalancer-reference">C.12. <code>KafkaListenerExternalLoadBalancer</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalLoadBalancer</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalNodePort-reference"><code>KafkaListenerExternalNodePort</code></a>.
It must have the value <code>loadbalancer</code> for the type <code>KafkaListenerExternalLoadBalancer</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>loadbalancer</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Enables TLS encryption on the listener. By default set to <code>true</code> for enabled TLS encryption.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaListenerExternalNodePort-reference">C.13. <code>KafkaListenerExternalNodePort</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaListeners-reference"><code>KafkaListeners</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaListenerExternalNodePort</code> from <a href="#type-KafkaListenerExternalRoute-reference"><code>KafkaListenerExternalRoute</code></a>, <a href="#type-KafkaListenerExternalLoadBalancer-reference"><code>KafkaListenerExternalLoadBalancer</code></a>.
It must have the value <code>nodeport</code> for the type <code>KafkaListenerExternalNodePort</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>nodeport</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka brokers. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaListenerAuthenticationTls-reference"><code>KafkaListenerAuthenticationTls</code></a>, <a href="#type-KafkaListenerAuthenticationScramSha512-reference"><code>KafkaListenerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Enables TLS encryption on the listener. By default set to <code>true</code> for enabled TLS encryption.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaAuthorizationSimple-reference">C.14. <code>KafkaAuthorizationSimple</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">superUsers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of super users. Should contain list of user principals which should get unlimited access rights.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Rack-reference">C.15. <code>Rack</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topologyKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A key that matches labels assigned to the OpenShift or Kubernetes cluster nodes. The value of the label is used to set the broker&#8217;s <code>broker.rack</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Probe-reference">C.16. <code>Probe</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">initialDelaySeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The initial delay before first the health is first checked.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">timeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The timeout for each attempted health check.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-JvmOptions-reference">C.17. <code>JvmOptions</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-XX</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A map of -XX options to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xms</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xms option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">-Xmx</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">-Xmx option to to the JVM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-Resources-reference">C.18. <code>Resources</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">limits</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource limits applied at runtime.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">requests</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource requests applied during pod scheduling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CpuMemory-reference"><code>CpuMemory</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CpuMemory-reference">C.19. <code>CpuMemory</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-Resources-reference"><code>Resources</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">cpu</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">CPU.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">memory</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Memory.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-InlineLogging-reference">C.20. <code>InlineLogging</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>InlineLogging</code> from <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a>.
It must have the value <code>inline</code> for the type <code>InlineLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>inline</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">loggers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A Map from logger name to logger level.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ExternalLogging-reference">C.21. <code>ExternalLogging</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a>, <a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a>, <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>ExternalLogging</code> from <a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>.
It must have the value <code>external</code> for the type <code>ExternalLogging</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>external</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the <code>ConfigMap</code> from which to get the logging configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-TlsSidecar-reference">C.22. <code>TlsSidecar</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a>, <a href="#type-KafkaClusterSpec-reference"><code>KafkaClusterSpec</code></a>, <a href="#type-TopicOperatorSpec-reference"><code>TopicOperatorSpec</code></a>, <a href="#type-ZookeeperClusterSpec-reference"><code>ZookeeperClusterSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the container.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logLevel</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The log level for the TLS sidecar.Default value is <code>notice</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [emerg, debug, crit, err, alert, warning, notice, info])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-ZookeeperClusterSpec-reference">C.23. <code>ZookeeperClusterSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">storage</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Storage configuration (disk). Cannot be updated. The type depends on the value of the <code>storage.type</code> property within the given object, which must be one of [ephemeral, persistent-claim].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EphemeralStorage-reference"><code>EphemeralStorage</code></a>, <a href="#type-PersistentClaimStorage-reference"><code>PersistentClaimStorage</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The zookeeper broker config. Properties with the following prefixes cannot be set: server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Zookeeper. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-TopicOperatorSpec-reference">C.24. <code>TopicOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertificateAuthority-reference">C.25. <code>CertificateAuthority</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<div class="paragraph">
<p>Configuration of how TLS certificates are used within the cluster.This applies to certificates used for both internal communication within the cluster and to certificates used for client access via <code>Kafka.spec.kafka.listeners.tls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">generateCertificateAuthority</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">validityDays</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of days generated certificates should be valid for. Default is 365.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">renewalDays</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed.When <code>generateCertificateAuthority</code> is true, this will cause the generation of a new certificate. When <code>generateCertificateAuthority</code> is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityOperatorSpec-reference">C.26. <code>EntityOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaSpec-reference"><code>KafkaSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityTopicOperatorSpec-reference"><code>EntityTopicOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">userOperator</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-EntityUserOperatorSpec-reference"><code>EntityUserOperatorSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tlsSidecar</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS sidecar configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-TlsSidecar-reference"><code>TlsSidecar</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityTopicOperatorSpec-reference">C.27. <code>EntityTopicOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the Topic Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the Topic Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicMetadataMaxAttempts</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of attempts at getting topic metadata.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-EntityUserOperatorSpec-reference">C.28. <code>EntityUserOperatorSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-EntityOperatorSpec-reference"><code>EntityOperatorSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">watchedNamespace</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The namespace the User Operator should watch.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The image to use for the User Operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reconciliationIntervalSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Interval between periodic reconciliations.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeperSessionTimeoutSeconds</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Timeout for the Zookeeper session.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnect-reference">C.29. <code>KafkaConnect</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectSpec-reference">C.30. <code>KafkaConnectSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnect-reference"><code>KafkaConnect</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationTls-reference">C.31. <code>KafkaConnectAuthenticationTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationTls</code> from <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaConnectAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateAndKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Certificate and private key pair for TLS authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertAndKeySecretSource-reference"><code>CertAndKeySecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertAndKeySecretSource-reference">C.32. <code>CertAndKeySecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">key</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the private key in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectAuthenticationScramSha512-reference">C.33. <code>KafkaConnectAuthenticationScramSha512</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaConnectAuthenticationScramSha512</code> from <a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaConnectAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">passwordSecret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Password used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PasswordSecretSource-reference"><code>PasswordSecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">username</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Username used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-PasswordSecretSource-reference">C.34. <code>PasswordSecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">password</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the key in the Secret under which the password is stored.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the password.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectTls-reference">C.35. <code>KafkaConnectTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a>, <a href="#type-KafkaConnectSpec-reference"><code>KafkaConnectSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">trustedCertificates</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Trusted certificates for TLS connection.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertSecretSource-reference"><code>CertSecretSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-CertSecretSource-reference">C.36. <code>CertSecretSource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a>, <a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificate</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the file certificate in the Secret.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">secretName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the Secret containing the certificate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2I-reference">C.37. <code>KafkaConnectS2I</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the Kafka Connect deployment.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectS2ISpec-reference"><code>KafkaConnectS2ISpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaConnectS2ISpec-reference">C.38. <code>KafkaConnectS2ISpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaConnectS2I-reference"><code>KafkaConnectS2I</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the Kafka Connect group.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">livenessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod liveness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">readinessProbe</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod readiness checking.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Probe-reference"><code>Probe</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" class="bare">https://github.com/prometheus/jmx_exporter</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for Kafka Connect. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectAuthenticationTls-reference"><code>KafkaConnectAuthenticationTls</code></a>, <a href="#type-KafkaConnectAuthenticationScramSha512-reference"><code>KafkaConnectAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Bootstrap servers to connect to. This should be given as a comma separated list of <em>&lt;hostname&gt;</em>:‍<em>&lt;port&gt;</em> pairs.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">insecureSourceRepository</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">When true this configures the source repository with the 'Local' reference policy and an import policy that accepts insecure source tags.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Kafka Connect. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaConnectTls-reference"><code>KafkaConnectTls</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopic-reference">C.39. <code>KafkaTopic</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the topic.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaTopicSpec-reference"><code>KafkaTopicSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaTopicSpec-reference">C.40. <code>KafkaTopicSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaTopic-reference"><code>KafkaTopic</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">partitions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of partitions the topic should have. This cannot be decreased after topic creation. It can be increased after topic creation, but it is important to understand the consequences that has, especially for topics with semantic partitioning. If unspecified this will default to the broker&#8217;s <code>num.partitions</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of replicas the topic should have. If unspecified this will default to the broker&#8217;s <code>default.replication.factor</code> config.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The topic configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">topicName</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The name of the topic. When absent this will default to the metadata.name of the topic. It is recommended to not set this unless the topic name is not a valid Kubernetes resource name.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUser-reference">C.41. <code>KafkaUser</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserSpec-reference">C.42. <code>KafkaUserSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUser-reference"><code>KafkaUser</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication mechanism enabled for this Kafka user. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>, <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authorization</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authorization rules for this Kafka user. The type depends on the value of the <code>authorization.type</code> property within the given object, which must be one of [simple].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserTlsClientAuthentication-reference">C.43. <code>KafkaUserTlsClientAuthentication</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserTlsClientAuthentication</code> from <a href="#type-KafkaUserScramSha512ClientAuthentication-reference"><code>KafkaUserScramSha512ClientAuthentication</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaUserTlsClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserScramSha512ClientAuthentication-reference">C.44. <code>KafkaUserScramSha512ClientAuthentication</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserScramSha512ClientAuthentication</code> from <a href="#type-KafkaUserTlsClientAuthentication-reference"><code>KafkaUserTlsClientAuthentication</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaUserScramSha512ClientAuthentication</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaUserAuthorizationSimple-reference">C.45. <code>KafkaUserAuthorizationSimple</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserSpec-reference"><code>KafkaUserSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaUserAuthorizationSimple</code> from other subtypes which may be added in the future.
It must have the value <code>simple</code> for the type <code>KafkaUserAuthorizationSimple</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>simple</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">acls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of ACL rules which should be applied to this user.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRule-reference"><code>AclRule</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRule-reference">C.46. <code>AclRule</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaUserAuthorizationSimple-reference"><code>KafkaUserAuthorizationSimple</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">host</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The host from which the action described in the ACL rule is allowed or denied.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">operation</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Operation which will be allowed or denied. Supported operations are: Read, Write, Create, Delete, Alter, Describe, ClusterAction, AlterConfigs, DescribeConfigs, IdempotentWrite and All.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [Read, Write, Delete, Alter, Describe, All, IdempotentWrite, ClusterAction, Create, AlterConfigs, DescribeConfigs])</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resource</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Indicates the resource for which given ACL rule applies. The type depends on the value of the <code>resource.type</code> property within the given object, which must be one of [topic, group, cluster].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The type of the rule.Currently the only supported type is <code>allow</code>.ACL rules with type <code>allow</code> are used to allow user to execute the specified operations. Default value is <code>allow</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [allow, deny])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleTopicResource-reference">C.47. <code>AclRuleTopicResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleTopicResource</code> from <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>.
It must have the value <code>topic</code> for the type <code>AclRuleTopicResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>topic</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleGroupResource-reference">C.48. <code>AclRuleGroupResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleGroupResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleClusterResource-reference"><code>AclRuleClusterResource</code></a>.
It must have the value <code>group</code> for the type <code>AclRuleGroupResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>group</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Name of resource for which given ACL rule applies. Can be combined with <code>patternType</code> field to use prefix pattern.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">patternType</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Describes the pattern used in the resource field. The supported types are <code>literal</code> and <code>prefix</code>. With <code>literal</code> pattern type, the resource field will be used as a definition of a full topic name. With <code>prefix</code> pattern type, the resource name will be used only as a prefix. Default value is <code>literal</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string (one of [prefix, literal])</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-AclRuleClusterResource-reference">C.49. <code>AclRuleClusterResource</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-AclRule-reference"><code>AclRule</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>AclRuleClusterResource</code> from <a href="#type-AclRuleTopicResource-reference"><code>AclRuleTopicResource</code></a>, <a href="#type-AclRuleGroupResource-reference"><code>AclRuleGroupResource</code></a>.
It must have the value <code>cluster</code> for the type <code>AclRuleClusterResource</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>cluster</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMaker-reference">C.50. <code>KafkaMirrorMaker</code> schema reference</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">spec</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The specification of the mirror maker.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerSpec-reference">C.51. <code>KafkaMirrorMakerSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMaker-reference"><code>KafkaMirrorMaker</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">replicas</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The number of pods in the <code>Deployment</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The docker image for the pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">whitelist</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions.Mirroring two topics named A and B can be achieved by using the whitelist <code>'A|B'</code>. Or, as a special case, you can mirror all topics using the whitelist '*'. Multiple regular expressions separated by commas can be specified as well.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">consumer</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of source cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">producer</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Configuration of target cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">resources</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Resource constraints (limits and requests).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-Resources-reference"><code>Resources</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">affinity</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod affinity rules.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">core/v1 affinity</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#affinity-v1-core">Affinity</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tolerations</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Pod&#8217;s tolerations.See external documentation of <a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">core/v1 tolerations</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#tolerations-v1-core">Toleration</a> array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">jvmOptions</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">JVM Options for pods.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-JvmOptions-reference"><code>JvmOptions</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">logging</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Logging configuration for Mirror Maker. The type depends on the value of the <code>logging.type</code> property within the given object, which must be one of [inline, external].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-InlineLogging-reference"><code>InlineLogging</code></a>, <a href="#type-ExternalLogging-reference"><code>ExternalLogging</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metrics</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The Prometheus JMX Exporter configuration. See <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">JMX Exporter documentation</a> for details of the structure of this configuration.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerConsumerSpec-reference">C.52. <code>KafkaMirrorMakerConsumerSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">numStreams</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Specifies the number of consumer stream threads to create.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">integer</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">groupId</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A unique string that identifies the consumer group this consumer belongs to.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for connecting to the cluster. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The mirror maker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration for connecting to the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerAuthenticationTls-reference">C.53. <code>KafkaMirrorMakerAuthenticationTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaMirrorMakerAuthenticationTls</code> from <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a>.
It must have the value <code>tls</code> for the type <code>KafkaMirrorMakerAuthenticationTls</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">certificateAndKey</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to the <code>Secret</code> which holds the certificate and private key pair.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertAndKeySecretSource-reference"><code>CertAndKeySecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>tls</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerAuthenticationScramSha512-reference">C.54. <code>KafkaMirrorMakerAuthenticationScramSha512</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<div class="paragraph">
<p>The <code>type</code> property is a discriminator that distinguishes the use of the type <code>KafkaMirrorMakerAuthenticationScramSha512</code> from <a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>.
It must have the value <code>scram-sha-512</code> for the type <code>KafkaMirrorMakerAuthenticationScramSha512</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">passwordSecret</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Reference to the <code>Secret</code> which holds the password.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-PasswordSecretSource-reference"><code>PasswordSecretSource</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Must be <code>scram-sha-512</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">username</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Username used for the authentication.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerTls-reference">C.55. <code>KafkaMirrorMakerTls</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerConsumerSpec-reference"><code>KafkaMirrorMakerConsumerSpec</code></a>, <a href="#type-KafkaMirrorMakerProducerSpec-reference"><code>KafkaMirrorMakerProducerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">trustedCertificates</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Trusted certificates for TLS connection.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-CertSecretSource-reference"><code>CertSecretSource</code></a> array</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="type-KafkaMirrorMakerProducerSpec-reference">C.56. <code>KafkaMirrorMakerProducerSpec</code> schema reference</h3>
<div class="paragraph">
<p>Used in: <a href="#type-KafkaMirrorMakerSpec-reference"><code>KafkaMirrorMakerSpec</code></a></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Field</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bootstrapServers</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">authentication</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">Authentication configuration for connecting to the cluster. The type depends on the value of the <code>authentication.type</code> property within the given object, which must be one of [tls, scram-sha-512].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerAuthenticationTls-reference"><code>KafkaMirrorMakerAuthenticationTls</code></a>, <a href="#type-KafkaMirrorMakerAuthenticationScramSha512-reference"><code>KafkaMirrorMakerAuthenticationScramSha512</code></a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">config</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">The mirror maker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">map</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tls</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">TLS configuration for connecting to the cluster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#type-KafkaMirrorMakerTls-reference"><code>KafkaMirrorMakerTls</code></a></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="metrics-str">Appendix D: Metrics</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section describes how to monitor Strimzi Kafka and ZooKeeper clusters using Grafana dashboards.
In order to run the example dashboards you must configure Prometheus server and add the appropriate <a href="https://github.com/prometheus/jmx_exporter">Prometheus JMX Exporter</a> rules to your Kafka cluster resource.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
The resources referenced in this section serve as a good starting point for setting up monitoring, but they are provided as an example only.
If you require further support on configuration and running Prometheus or Grafana in production then please reach out to their respective communities.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When adding Prometheus and Grafana servers to an Apache Kafka deployment using <code>minikube</code> or <code>minishift</code>, the memory available to the virtual machine should be increased (to 4 GB of RAM, for example, instead of the default 2 GB). Information on how to increase the default amount of memory can be found in the following section <a href="#installing_kubernetes_and_openshift_cluster">Installing OpenShift or Kubernetes cluster</a>.</p>
</div>
<div class="sect2">
<h3 id="kafka_metrics_configuration">D.1. Kafka Metrics Configuration</h3>
<div class="paragraph">
<p>Strimzi uses the <a href="https://github.com/prometheus/jmx_exporter">Prometheus JMX Exporter</a> to export JMX metrics from Kafka and ZooKeeper to a Prometheus HTTP metrics endpoint that is scraped by Prometheus server.
The Grafana dashboard relies on the Kafka and ZooKeeper Prometheus JMX Exporter relabeling rules defined in the example <code>Kafka</code> resource configuration in <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/kafka/kafka-metrics.yaml"><code>kafka-metrics.yaml</code></a>.
Copy this configuration to your own <code>Kafka</code> resource definition, or run this example, in order to use the provided Grafana dashboards.</p>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift">D.1.1. Deploying on OpenShift</h4>
<div class="paragraph">
<p>To deploy the example Kafka cluster the following command should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/kafka/kafka-metrics.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes">D.1.2. Deploying on Kubernetes</h4>
<div class="paragraph">
<p>To deploy the example Kafka cluster the following command should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/kafka/kafka-metrics.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="prometheus">D.2. Prometheus</h3>
<div class="paragraph">
<p>The provided Prometheus <a href="https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/prometheus/kubernetes.yaml"><code>kubernetes.yaml</code></a> YAML file describes all the resources required by Prometheus in order to effectively monitor a Strimzi Kafka &amp; ZooKeeper cluster.
These resources lack important production configuration to run a healthy and highly available Prometheus server.
They should only be used to demonstrate this Grafana dashboard example.</p>
</div>
<div class="paragraph">
<p>The following resources are defined:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>ClusterRole</code> that grants permissions to read Prometheus health endpoints of the Kubernetes system, including cAdvisor and kubelet for container metrics.  The Prometheus server configuration uses the Kubernetes service discovery feature in order to discover the pods in the cluster from which it gets metrics.  In order to have this feature working, it is necessary for the service account used for running the Prometheus service pod to have access to the API server to get the pod list.</p>
</li>
<li>
<p>A <code>ServiceAccount</code> for the Prometheus pods to run under.</p>
</li>
<li>
<p>A <code>ClusterRoleBinding</code> which binds the aforementioned <code>ClusterRole</code> to the <code>ServiceAccount</code>.</p>
</li>
<li>
<p>A <code>Deployment</code> to manage the actual Prometheus server pod.</p>
</li>
<li>
<p>A <code>ConfigMap</code> to manage the configuration of Prometheus Server.</p>
</li>
<li>
<p>A <code>Service</code> to provide an easy to reference hostname for other services to connect to Prometheus server (such as Grafana).</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift_2">D.2.1. Deploying on OpenShift</h4>
<div class="paragraph">
<p>To deploy all these resources you can run the following.  Note that this file creates a <code>ClusterRoleBinding</code> in the <code>myproject</code> namespace.  If you&#8217;re not using this namespace then download the resource file locally and update it.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc login -u system:admin
oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/prometheus/kubernetes.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes_2">D.2.2. Deploying on Kubernetes</h4>
<div class="paragraph">
<p>To deploy all these resources you can run the following.  Note that this file creates a <code>ClusterRoleBinding</code> in the <code>myproject</code> namespace.  If you&#8217;re not using this namespace then download the resource file locally and update it.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/prometheus/kubernetes.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="grafana">D.3. Grafana</h3>
<div class="paragraph">
<p>A Grafana server is necessary to get a visualisation of the Prometheus metrics.  The source for the Grafana docker image used can be found in the <code>./metrics/examples/grafana/grafana-openshift</code> directory.</p>
</div>
<div class="sect3">
<h4 id="deploying_on_openshift_3">D.3.1. Deploying on OpenShift</h4>
<div class="paragraph">
<p>To deploy Grafana the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">oc apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/grafana/kubernetes.yaml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="deploying_on_kubernetes_3">D.3.2. Deploying on Kubernetes</h4>
<div class="paragraph">
<p>To deploy Grafana the following commands should be executed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/0.8.0/metrics/examples/grafana/kubernetes.yaml</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="grafana_dashboard">D.4. Grafana dashboard</h3>
<div class="paragraph">
<p>As an example, and in order to visualize the exported metrics in Grafana, two sample dashboards are provided <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.8.0/metrics/examples/grafana/strimzi-kafka.json"><code>strimzi-kafka.json</code></a> and <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.8.0/metrics/examples/grafana/strimzi-zookeeper.json"><code>strimzi-zookeeper.json</code></a>.
These dashboards represent a good starting point for key metrics to monitor Kafka and ZooKeeper clusters, but depending on your infrastructure you may need to update or add to them.
Please note that they are not representative of all the metrics available.
No alerting rules are defined.</p>
</div>
<div class="paragraph">
<p>The Grafana Prometheus data source, and the above dashboards, can be set up in Grafana by following these steps.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
For accessing the dashboard, you can use the <code>port-forward</code> command for forwarding traffic from the Grafana pod to the host. For example, you can access the Grafana UI by running <code>oc port-forward grafana-1-fbl7s 3000:3000</code> (or using <code>kubectl</code> instead of <code>oc</code>) and then pointing a browser to <code><a href="http://localhost:3000" class="bare">http://localhost:3000</a></code>.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Access to the Grafana UI using <code>admin/admin</code> credentials.  On the following view you can choose to skip resetting the admin password, or set it to a password you desire.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_login.png" alt="Grafana login">
</div>
</div>
</li>
<li>
<p>Click on the "Add data source" button from the Grafana home in order to add Prometheus as data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_home.png" alt="Grafana home">
</div>
</div>
</li>
<li>
<p>Fill in the information about the Prometheus data source, specifying a name and "Prometheus" as type. In the URL field, the connection string to the Prometheus server (that is, <code><a href="http://prometheus:9090" class="bare">http://prometheus:9090</a></code>) should be specified. After "Add" is clicked, Grafana will test the connection to the data source.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_prometheus_data_source.png" alt="Add Prometheus data source">
</div>
</div>
</li>
<li>
<p>From the top left menu, click on "Dashboards" and then "Import" to open the "Import Dashboard" window where the provided <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.8.0/metrics/examples/grafana/strimzi-kafka.json"><code>strimzi-kafka.json</code></a> and <a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.8.0/metrics/examples/grafana/strimzi-zookeeper.json"><code>strimzi-zookeeper.json</code></a> files can be imported or their content pasted.</p>
<div class="imageblock">
<div class="content">
<img src="images/grafana_import_dashboard.png" alt="Add Grafana dashboard">
</div>
</div>
</li>
<li>
<p>After importing the dashboards, the Grafana dashboard homepage will now list two dashboards for you to choose from.  After your Prometheus server has been collecting metrics for a Strimzi cluster for some time you should see a populated dashboard such as the examples list below.</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="kafka_dashboard">D.4.1. Kafka Dashboard</h4>
<div class="imageblock">
<div class="content">
<img src="images/grafana_kafka_dashboard.png" alt="Kafka dashboard">
</div>
</div>
</div>
<div class="sect3">
<h4 id="zookeeper_dashboard">D.4.2. ZooKeeper Dashboard</h4>
<div class="imageblock">
<div class="content">
<img src="images/grafana_zookeeper_dashboard.png" alt="ZooKeeper dashboard">
</div>
</div>
</div>
<div class="sect3">
<h4 id="metrics_references">D.4.3. Metrics References</h4>
<div class="paragraph">
<p>To learn more about what metrics are available to monitor for Kafka, ZooKeeper, and Kubernetes in general, please review the following resources.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://kafka.apache.org/documentation/#monitoring">Apache Kafka Monitoring</a> - A list of JMX metrics exposed by Apache Kafka.
It includes a description, JMX mbean name, and in some cases a suggestion on what is a normal value returned.</p>
</li>
<li>
<p><a href="https://zookeeper.apache.org/doc/current/zookeeperJMX.html">ZooKeeper JMX</a> - A list of JMX metrics exposed by Apache ZooKeeper.</p>
</li>
<li>
<p><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">Prometheus - Monitoring Docker Container Metrics using cAdvisor</a> - cAdvisor (short for container Advisor) analyzes and exposes resource usage (such as CPU, Memory, and Disk) and performance data from running containers within pods on Kubernetes.
cAdvisor is bundled along with the kubelet binary so that it is automatically available within Kubernetes clusters.
This reference describes how to monitor cAdvisor metrics in various ways using Prometheus.</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">cAdvisor Metrics</a> - A full list of cAdvisor metrics as exposed through Prometheus.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>